{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capstone Project - Machine Learning Engineer at Udacity\n",
    "**Author**: Ewa Nowacka <br>\n",
    "**Title**: Comparision of algorithms' performance on lung CT scan dataset: CNN vs. SVM. <br>\n",
    "**Key Words**: Neural Networks, Convolutional Neural Networks, Image Classification, Support Vector Machines, Data Augmentation <br>\n",
    "**Day submitted**: <br>\n",
    "\n",
    "The project consists of 6 steps:<br>\n",
    "**1. Read-in lung CT scan data and data preprocessing:** <br>\n",
    "    1.1. Import image data <br>\n",
    "    1.2. Create labels (positive/negative for cancer) <br>\n",
    "    1.3. Divide the image data into train, validation and test sets. <br>\n",
    "    1.4. Convert image data to tensors. <br>\n",
    "    1.5. Data augmentation <br>\n",
    "<br>\n",
    "**2. Testing different CNN architectures.** <br>\n",
    "    2.1. Model 1 - 3 convolutional layers and 2 fully connected layers. <br>\n",
    "    2.2. Model 2 - Model 1 with dropout layers, batch normalization and Global Average Pooling  Layer. <br>\n",
    "    2.3. Model 3 - Model 2 but more filters and higher dropout probability.<br>\n",
    "    2.4. Model 4 - Model 2 with 2 extra layers and additional dropout layer. <br>\n",
    "<br>\n",
    "**3. Testing different CNN architectures on augmented data.** <br>\n",
    "    3.1. Model 1 with augmented data. <br>\n",
    "    3.2. Model 2 - Model 1 with more layers. <br>\n",
    "<br>\n",
    "\n",
    "**4. Improving Model 1 performance with non-augmented data.** <br>\n",
    "    4.1. Model 5 - Model 1 with Global Average Pooling layer. <br>\n",
    "    4.2. Model 6 - Model 1 with batch normalization. <br>\n",
    "    4.3. Model 7 - Model 6 with extra layers. <br>\n",
    "    4.4: Model 8 - Model 7 with increased droput rate, change in filter dimensions and one extra layer.\n",
    "    4.5. Model training analysis. <br>\n",
    "<br>\n",
    "**5. Training benchmark SVM model.** <br>\n",
    "    5.1. Convert data to required format - 1D numpy array. <br>\n",
    "    5.2. Use grid search alogrithm to define best SVM classifier. <br>\n",
    "<br>\n",
    "**6: Compare CNN and SVM performance.**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, it is necessary to import all modules to be used in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "\n",
    "# MATPLOTLIB IMPORTS\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt  \n",
    "%matplotlib inline\n",
    "\n",
    "#KERAS IMPORTS\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from keras.preprocessing import image    \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical  \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense,BatchNormalization,Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "# SKLEARN IMPORTS\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Read-in lung CT scan data and data preprocessing\n",
    "**STEP 1.1: Import Image Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2948 nodules in total.\n",
      "There are 1474 cancer nodules and 1474 non-cancer nodules.\n"
     ]
    }
   ],
   "source": [
    "# Read in snippets data\n",
    "nodules= glob(\"/luna16/images/*.png\")\n",
    "#path=\"C:/Users/Ewa/Documents/Machine Learning Nanodegree/Capstone Project/Data/\"\n",
    "#nodules= glob(path+\"/LUNA2016/images/*.png\")\n",
    "nodule_files=np.array(nodules)\n",
    "print(\"There are {} nodules in total.\".format(len(nodule_files)))\n",
    "\n",
    "sum_pos=0\n",
    "sum_neg=0\n",
    "for file in nodule_files:\n",
    "    if file[-7:-4]==\"pos\":\n",
    "        sum_pos+=1\n",
    "    else:\n",
    "        sum_neg+=1\n",
    "\n",
    "print(\"There are {} cancer nodules and {} non-cancer nodules.\".format(sum_pos,sum_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.2: Create labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are some examples of cancer nodules:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are some examples of non-cancer nodules:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Create Labels\n",
    "labels=list()\n",
    "for file in nodule_files:\n",
    "    label=file[-7:-4]\n",
    "    labels.append(label)\n",
    "\n",
    "#Examples of cancer nodules\n",
    "cancer_ex= [i for i,x in enumerate(labels) if x == 'pos'][1:5]\n",
    "noncancer_ex=[i for i,x in enumerate(labels) if x == 'neg'][1:5]\n",
    "\n",
    "print(\"There are some examples of cancer nodules:\")\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "columns=4\n",
    "rows=1\n",
    "j=1\n",
    "for i in cancer_ex:\n",
    "    img=mpimg.imread(nodule_files[i])\n",
    "    fig.add_subplot(rows,columns,j)\n",
    "    plt.imshow(img,cmap=plt.cm.binary)\n",
    "    j+=1\n",
    "plt.show()\n",
    "\n",
    "print(\"There are some examples of non-cancer nodules:\")\n",
    "fig2=plt.figure(figsize=(8,8))\n",
    "columns=4\n",
    "rows=1\n",
    "j=1\n",
    "for i in noncancer_ex:\n",
    "    img=mpimg.imread(nodule_files[i])\n",
    "    fig2.add_subplot(rows,columns,j)\n",
    "    plt.imshow(img,cmap=plt.cm.binary)\n",
    "    j+=1\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.3: Divide the image data into train, validation and test sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set consists of 1768 CT scans, validaiton set of 590 CT scans and test set consists of 590 CT scans.\n"
     ]
    }
   ],
   "source": [
    "# divide data to train validation and test sets\n",
    "labels_01=[1 if x==\"pos\" else 0 for x in labels]\n",
    "categorical_labels=to_categorical(labels_01)\n",
    "\n",
    "train_nodules, test_nodules, train_labels, test_labels = train_test_split(nodule_files,categorical_labels,test_size=0.2,train_size=0.8,stratify=categorical_labels)\n",
    "train_nodules, val_nodules, train_labels, val_labels = train_test_split(train_nodules,train_labels,test_size = 0.25,train_size =0.75,stratify=train_labels)\n",
    "\n",
    "print('Training set consists of {} CT scans, validaiton set of {} CT scans and test set consists of {} CT scans.'.format(len(train_nodules),len(val_nodules),len(test_nodules)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAACDCAYAAAC+9HPWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztfV2MXMeZ3anuGQ7JGVKkKImiKVIkJVHWL0lbVhJLWBjeNbCIANsPgbEOECiADb8kQBbJg419C+AAzssmAQwkEGDDWmARr5HdwEa8RiTYkp01/CNZWlnWnylRokSKIilRY1IcipyZrjxwzu1zaw5v95DNaU7zO4DAUd3bVXXrq7q3vlPfT8o5IxAIBAKBwPDQGnYHAoFAIBC42hEf40AgEAgEhoz4GAcCgUAgMGTExzgQCAQCgSEjPsaBQCAQCAwZ8TEOBAKBQGDIiI9xIBAIBAJDxiV9jFNKf5pSeiWl9GpK6WuD6lRgeAiZjhZCnqOHkOloIl1s0I+UUhvA7wF8BsAhAE8B+GLO+cXBdS+wnAiZjhZCnqOHkOnoYuwSfns/gFdzzgcAIKX0XQCfA3DBSTE1NZU3bdqENWvWVGWrVq0CALTb7aqMG4SU0qKyTqezqKzVWqzg85rWS8zNzTXW4drndZbpJsaVEdrf8n6H+fn56u/x8fFF97PvWq9rY2xsrFYH+/fmm2/i3XffvVAHliTTa665Jm/evBknT56syqanpwEAZ8+eXdSXa665pirbsGEDgK78FXweN8asC2iWrZsnWsb6WIeTibZPuah8muad6yP/1t+xXW2/aX5o/TlnHDp0CCdOnBiIPAFgYmIir127FrOzs1UZn9mNnxsDNzedTJsUATcGTeOi9bl6m9aoq2OpcO8Pd93JuZwPs7OzmJubG4hMU0o5pWTldIH77d9lGdfh2rVrq2vr168HAExMTFRlbLfXWmkas6a+uW9Er/cw3xH8rb6DuEZ1nfNv9z7SPrIN/W3OGUeOHMH09HTz5MWlfYy3AnhL/v8QgH9S3pRS+gqArwDApk2b8PWvfx0333xzdX379u0A6i9qvgjOnTtXlZWLGugOKj/u69atq6598MEHtbq0vnfeeacq42+vu+66qoyTSScVf9v0AdAPBT+CKmh+tPS5Vq9eXatLn0/rK+vQDQUXhH543ccLAD796U8vqlPQU6Yqz4985CP40Y9+hDfffLO6/pvf/AYA8Mwzz1Rlx48fBwBs27ZtUT/27t1blV177bUAuh/yP/zhD4ueZ2pqqiqjvHWRvP/++wCAEydOLGr/1KlTVRnr2bp1KwBg48aN1TUnY8rszJkzVRll8OGHH1ZlvM7+qnw5n1ROvK4vNZapjN1cOHv2LB566KFF5YIlr9GJiQns27cP7733XnWda0nHWdcGwWefmZmp9RHwH3S3YXZj78Dx0D6V7wgdM5bpJrFflC9ofdlyHPSlzLmiHwre58pU9mNjYzh48GBTd5a0RlNKmJycbNz0At05rPOV60tlMjk5CaC7lv/oj/6ouvbAAw8A6K5joDvXdb64j5vbFJcbZlXi3DMQKne2oe8SvhvYp82bN1fX2IauPf7t+qttcd6/++67Vdn09DS+/OUvL+qjw2U34Mo5P5Jzvi/nfJ9+LAMrEypPXXSBlQuVqXtpB1YWVJ692ITAlYNL+RgfBrBN/v+mhbLAykXIdLQQ8hw9hExHFJdCUz8F4LaU0k6cnwx/BuBfNjY2NoZNmzZV54VAl2ZQqo/UhtJ5pJuVKiC1TKpA6SPuCJUyOHr0KIA6VXXTTTfV6tC2lOLmdWoOSi2xDaXnSHcoxcMy7Wd5lqbPTHpE6VVHs5VUN9B9fr3/1KlTNfrFYEkybbfb2LhxY20seOywb9++qmz//v215wG6VJaOO/8mFaZHFxxHlT/pQB1P9kXnE9tV+ZCiKs+PAD//SGsrTU0qV9ti/3h+pvWyfXecoGWcJ476VM111apVvc5Rl7xG5+bmMD09XXtOPpOj//TZOU/1GEbXUNl/d4buzt0oI6e1u3NH1qcUJvukZbzPUeOO/iz7rW3qM7O/pb1GU9+1T4OWac655zmqa5PPpPQw1ybX+e23315d43ud9wDddabvIXeM4M6U2Sfef/r06eoaZaDPwDmj70O24c6Web/O9ZIaB7rzzs0JV6bjde7cub7P6y/6Y5xznksp/VsA/xdAG8C3c84vXGx9geEjZDpaCHmOHkKmo4tL0YyRc/57AH/f7/3tdhvr16+vGeG4XayzZuZuR7Ub7rp5Fu0MftRwgPdt2rSpKuNuTndp3Nk6DZbXdDfFZ3BarVoaOyOOUlN1hgO6I2Q/dQy5E9XdJ3/by8qzxFJkSitN3YmyL6rFUEvU/vE+lQ93lBxHp3Eq+Gyl9aLWD3TZD9Xg9RmA+rjzefS52JZqQDQEfO655xY9w9133w2gbhzC59K2nCborDx5Xdufn5/vxzp4SWu00+ksYlDYb51LlKXKyFlMN1nElr8Dus+pGrWzhHYGYeVY9rqfa8lpiE1eG/pMKjfCGfc4UL4q516/WehP3zLNOaPT6dTGgjLTucR3osqH7zi3vnft2gUA2LFjR3WN71K9n2Oh8nTzieOo71D+zb7r+4P3O0ZLtVq2oePK/jlWlm3pe4n39+tBo1iKdX5E4AoEAoFAYMiIj3EgEAgEAkPGJdHUS0VKCRMTEzZwg6PA9D5SOUpjKH0LeBqBFCnQpSmVgnDtO2qD9DjpEWcIpfTMhRz6gbo/NJ+BlInS3/Tv1DL6w6qRANtVyoy0UBlEZJCuDp1OBzMzMzWZONqO1JbSRxzbpqAYzoBP63d0ICknvY/jrdR1Kb9yLgGeJtajkNdeew0A8OSTT1ZlH/nIRwCg8qW/5ZZbqmucf5Qr4A24aAilfeIcKH193XhfCkhr6rM7ip7jrNShG3vKyBngOTq5KeCOu8/RgC5wg6NGHa1e1qH3OTQZCDmfWX33sE/OMG5QaLfbKF1K+Tz6DnF+43yvqCEl6Wz6GeuRH9txc0KfsTSeBDxNzXcu+6vrtzw2LNso79Nr/Ca4OeSOvrjmVZ7ue+To9JmZmcb5owjNOBAIBAKBIWPZNeN2u20No5p2NUBXM3BatXN7cu4FvF93/dylud28c4NwWjOh9brdEPvnNC5CIx+9/vrrtTaB7u5Td7UcG9WkqIXpbq7T6QxUM845Y35+vqYxlRGXgMXuLVqmBm7lDlif0TENlK2LyuYMgJQl4XVG42HkLgB4++23F7VPqJvZgQMHAACHD3fdPOmyRQM7bZP1Oa1Pn8tFEaN7mO66d+3aZcf2UtBqtRa5EDnjMf7tGCKn/TW59jS5JwGeAXGGbyVUu3UGN86lyUXZYltu7TstnHDaYOmapvWyn4NcoykljI+P19g1zkPVeN37inNYo9PddtttAICdO3cC8Nqqc1fUZ2piuZQ14jp0c8iVUZN2hr867vytM+ojnCuWzhf3DGxf2bO5ubm+2Y7QjAOBQCAQGDLiYxwIBAKBwJCxrDQ1I3Ap/eeMMxzt7Hwv+bejabVNgjSCUhCkHpTO5nVtvzywd1F4tC3SF+rDxvbVV5q/cXGeSVlv2bKlKiONo3Qp69C2SFOrP/Ls7OzADbhOnTqFV155pVYGdH17tS8Kytj5jTcZ1ji/aaW2WJ/ex/FRuXOuMMsUjbEAVIH6HfWoc4w0taNZ2Sel4V2mGz6z0r2ORqQclVKbnZ0duMEPDbicv7tS4o66cwZJzkiLaMqUpfU6/3xnLFYaTpVHNPos2oYz6lKUNLmjv13EJl17/K22RQrVxTgYFObn53Hq1KlaGy4WAMfTyV0NU2m45d5X7ijRvZscnUzZ6TFd+T5Q+pdrw0Vlc8cPTRmi9H53zMZ+6jPwPeC+JXpMMzk52ZfvOBCacSAQCAQCQ8eyasbtdhsbNmzoGaeV2oSWMbqLMxZy6RVdDGnu9NQwhmVqpMCdoIsr7KJzcbfrjGl0V0SNR/vJ3ZRLu8bdn2qZ1D50l0h3Gk0D6cakn4hNS8GHH36Il19+GT/72c+qMkac6pWWrHR5ARa7Bihbwd2mS/um2rXTrJyxGMePu3knO6c5UJMGunNAtQTW++yzzwKou7GxT2rU5VzlOAfUbeT+++8HUJ//pVvZoJBzrvWH8tC2m9x3dCxLQxftr4u+V9al18voY/qv1udiAbs0eE4zd6kZ+8l9XWpDgDfUdL/Vsf7www8HznZ0Op0aG0kZqJxcHnD2Wd8r119/fe0+lYljGvgsWq+L/c56lE1gu/3KjuPtNG6XjpdlzihUx8vJwxl/se9q1LZq1arQjAOBQCAQWCmIj3EgEAgEAkPGstLUQNc3lWD6QaUnSBG41FaOpnTGSu4gnlS30g6kFd1BvFLcrJuGUy6QvNbhIiuR/tbnIgXDpANqjESqVykT0ukuQL+jVcvUlIM04Jqfn8cHH3xQG6cbbrhhUV+0/fJvF33IGfA5/1MX1J1/6xjzWELHgqBc9+zZU5Xt3bsXQJ3q5jyhnICuP/Bbb71VlT311FO1f++4447qGqNxaT9ctDGOSS/f+8tBUzvfcY6lO17pFVGLcAZM/SSWABYb8ihc5CjCJeRwtLorc8cGLlWrozU593sZrTk/60GuT9Y3NjZmU8T2MpDk2tBjMh6d8T6XUMQ9jxqBcW7p+uLRjb7DyzgSvRJFuFgE/K0aXvK3vE/nkKO6nU8xf6PHmy7uwVIQmnEgEAgEAkPGsmrG8/PzmJ6etjtLPfR2u1PVdIjS6MBF7NK2uIuh9qbtq0EUNR7d9dBwgQY5qjk07bC1/dLgDOjuztRViaAbgdMeVRtlfU4zv5y77vHxcdxwww21caIxmYvM47Q/7V/pLuPc3VxCcr2PO2CNqMW5oMZU1GS4E1Y3Il5z9Woydcr2+eefr8oYNc1p4bxf5cTncbGgnYtQGbVo0DKlu5quN7bpjO16td8Um5pwbmha5tx93DuCfzelQXSxhHv1iVqdc4OkhqTalRsT1uEiApbtXw72SsF10CtuPtOA3nnnnVUZ3SxptNgrHahz+3RsTj9ubi5/gDP0U7nzvX706NGqjH3hO93F1nfvGS2jBq8av5unZfrKJvTUjFNK304pHUsp/U7Krk0pPZ5S2r/w78amOgJXFkKmo4WQ5+ghZHr1oR/N+DsAvgngr6TsawB+nHP+Rkrpawv//9V+Gix3QNyJ6a6DWqJzN3G7I+6E9FyAu8FeZxXU4Jwmoy4zdEbn/S4xtmrL3Ck7h3LVOlifc23iOYruuNz5BbUql2lGd+znzp1j/d/BAGQ6NjaGzZs318aYGrvbHeu5mtMSy747VygXf1zl7nandJFQl6Iy4IKrV7VV/lbHmDJTbYKxeylHfWbOaz0XK58P8AE1KEedY6dPn+a938GA1min08GZM2caMy8B/WvG5f29xrm0GwD8HCF0PAh37uc0KcesECo3/u2Cfjh3Kic/x4A4WxNxP/wOBiDTdruNqamp2vuVY+aYKg0wRDsKasgAsGPHjtpzqNZNmekYN9kRlAFs9H6tx533s32937kJ8t2g/SQzyneVm5NO49b3XBObcrFsZE/NOOf8MwAniuLPAXh04e9HAXy+7xYDQ0fIdLQQ8hw9hEyvPlysAdfmnPORhb/fAbD5QjemlL6SUno6pfS0BtsIXHHoS6YqTz2XDVxxuKg1OuiAE4GBYslr9GItewPLj0s24Mo555TSBVdwzvkRAI8AwJ49e/LExIRV9x3V6CaSUiukGUhxOFpboy4xepJSUKQw1SCKlKDS1OyfS83Iv5Xq5t9lNBbtB9ClLlmvRnNy6cfKNgFPGTo3g34jcDXJVOV511135fHxcUu99YpqwzHQMS4jdel4OhcW0m06T1xcZ/bPxcwt3Se0fWfEozh27BiAekS37du31/qh483Ni44X54dzY3JuPqUbRj802FLWaKvVyiXV7yheUoI6bi6GdGlI6I4eeqWwa6LEHdXqIuKxzFHHWi+fQedqGXnLHZW5deXackaJpRHaINfo2NhYLucRx1afm+/B3bt3V2U03Lr11lurMh6xuLjVTZHJHJ3s3Idc/HPnuumO5ly0rwu5eOpvde05w0A3/3nd/bYpDnYTLlYzPppS2rLQgS0Ajl1kPYErByHT0ULIc/QQMh1hXKxm/AMADwP4xsK/3+/nRykltFqt2s7FGS45YxUX25b3UatVwyjuelTzeuONNwDUd73UoFxwDjXMaUrizrZ0l8idmP7OBXOgtsRn0HjEDi5IhNPkeF1dpk6cONGUjP2iZFqijOMLdOXkZKc7Vo4Vy1Q7cpqNq7dMBA94zbhsS0E56jxlX5RpYaYnHVO6Prn5x7Z0Xrs4vc6wx7EL7Xa7Ke7tJcnTZSZSOHenpmAlfJZeDIBzQXKug65vrLtpDiizwOuqcfG665PTcrj2XPYq15bT/MrnaWA7lizTVquFyclJ+y5VNpCBPTRIza5duwB4N0UyhU4LdEZYvbJROa22DDZTxvDW+gHPBrr49ZSBe29znFwwG2cs6Az3nEtdP+jHtel/AvgFgNtTSodSSl/C+cnwmZTSfgB/svD/gRWCkOloIeQ5egiZXn3oqRnnnL94gUt/POC+BJYJIdPRQshz9BAyvfqwrBG4cs6YnZ210U1cVCp3OO6MSByF56I+uehZzh+Z9ymNQ7qDtK+j0ZSycNS5i/Fb+uAqtUUaRelK0kMuTqqjVZWCW7NmzcAjNuWca1QMn8PRNy4mt+sP5a7PTYMvNcxi7G6l/lwkM0eplnNM++FS5TGSz8GDB6syHjEw5jkA3HjjjbW21VjPpWxzEX/c83P+lYZsg7Z+Tilh1apVPdOcsh+O4nVGSo6GvFD7gDdecykJXfSusi7tm95DObvoZ45q5W91vjX5m7p3laOL3bMOCq1WC2vXrq1RvBwL9bunf7HGoeZ70EXZctS9S6vojHH57tT3q4vrTLnw3azjxPegi9Gv64ZrVMvKaI4qa3cc2RQBTg2P+VudT0uJHR+xqQOBQCAQGDKWXTOem5ur7Ry4O3K7SGcAoQfx5U6sl5m5cyNxu1gX15o7MO6EtA7W6zQvbd/1k5okn0WfjzvXXtG+nKtAGTUIGHzWJqdFsS9Oi9FnowarZdwBczx1l0r3IbfT1Gd00Zfcjpl1OxbGaTvcYasBF2PbatQizmfuptUgj33SseFcUxnz+VVLcBpGu90euGZc9vVCZW59OVezMnuaY8C0XheBi+OlZZwHrk+832nNvaJyuShOTcnhncsW63UaYi9DJn2HDAI5Z5w7d64mJ7onMfY90DXcItsEeBdDjoVj4xzr4WJTO+bJGT8RzmiVWruyUqz3+PHjVZkz6jpw4ECtT1u3bl30fO6donVwXrtsUM6osR+EZhwIBAKBwJARH+NAIBAIBIaMZaWpgfPUhNINjtIhHeCoTk3uTqqT1IrShS6xACkDTZdICkaNCUifaHBxpSeBuvEDoTRaEx3sElW4ZBeE+jszQpdS6KQ6tV4+j9IkJ0+eHChNTYM8R0tqWkWVI1EGgQcW+2xqQgWOk6M0na+hQxMdqvQh56LKn4lCVO401lL58HnYXz1qYZtu/ukYsU+6Jvi31rd69eqBG/8wFoDCUYhNvu16X2mk5OSjc9kZXjp/4NKoSn/j2nCUdOmXrM/l1ol7ZpcowlH4Df79NfR7X78gTa0gtbtz586qjJHj1ECS4+iSvrj1S+j9HGPnR+8o+6YoW1ovx1uNdl1yFj6PrmWmUyRdrX7UPHrSvrn3DK/r2LKfukaDpg4EAoFAYAVh2TXjTqdTM6ThLkJdUqgZ6OE8dyWqoTKiFnckTGyv92tbruzdd98FUN8R0ujGaevcCWrfuGNTrda5ILGfunOjpkUNSXeQumMjuCNz5vjO4MxpE4NEp9OxqdBUTs6oimOhjATv4786FtS0lX2g8ZdqJW4X7YzKylSP1HyBrrGYarBsQw2yqLk77dAZjrh4tpSxatesz0Ug09/2G2t8qUgpWa3OabAKZ6RFmXM8nDGilrmoam7+lPXqb3nNuSc5dsRpN71iv5f3O8MwHUPnMkWUKVIHmdwhpYSJiYna89B9STVjvjt1HnLcHdNB6Bx1qQ5d7HdXlzNQZF+ci2dTSlXHfui3gbG2OSb6zI4tcfOffXFunfqeOXv2bN9rNDTjQCAQCASGjPgYBwKBQCAwZCw7Td1ut6F5cEkRKCXrDFhI87hUdqQMlApxNIYrI9Xp0h+6qDWkKjSykksFx74odc06yjR4Cn0G9kOpSWfgwt8o1U+DBaVgBu2Xyug+CkdHlT69gDfSo2ydDykpYR1Pyt0linDGHgrWzTHjcQXQlbvOSZduzaXbY70udRv7ofWyPp3Xjs52RnDHjx/v6bd6Mcg5W5rf0a7O0MrRlC7lnfOP55jqeDjfW7cOyvXt5rqjqZ1BlqJ8Lq3XJUZxBkrOf9kZD549e3agNHW73ca6detqNO2ePXsAdJOaAF1jRDWapCx0TZepZBUuepo7HnDvYZcIqDwadLEAnA+0zh2uNV2jNFbj/VqHo6RdGdt3ERNdQol+EJpxIBAIBAJDxrJqxu12G+vXr7epsHSHQW1Od4guZReNn3i/mq87baxMKA90d2y6m6Hhju6wSmMd3S1SS9a22DfdkfG5y9io+tsy0bj2W6GaEo3PnIFN6bIzaIOfVqtljW16uTxw/FxkHoemay7yWq8E8JQxo/Vo/TRwUdmRzXGasUud6YyT3DPwPpdazxkM6S7+zJkzA9Wi2PaFjE5c5Dqnseszc2ycNsR5028KQ9eGi/PuNGPngtTEmDRd61VGmarBkVv7/FvfPbOzswNlOxglb8eOHVUZo21pHGq+33TOu7STpZaoc4LP49wzFRxbZUj5zGpUxrnDcWwyoNO+6H38Nrj5VMZ5B7pMqYvH3SvNL+8rIzH2634YmnEgEAgEAkNGfIwDgUAgEBgyetLUKaVtAP4KwGYAGcAjOef/llK6FsDfANgB4A0AX8g5v3+heoBuNBilQtxhN+kOpRGcsQx9fRk1RX1AXWIJF9npyJEjAOqRvRjJyxlJOQrJRR4i1H+ZfVKfVj4rKRkXUUgpTN6v1B7HQY21SNmXfrnnzp1DSukJDEieZUpMF1S9Kd2dUjoupV15v7blDLicbzbngNJnNNxiPzX1IeeT1ku5Ozq5pBkB779MmotR1LS/zl/SUWs6/8THdWBrlG25qGbOn7qXUV6ZtEH772hqytel5tMyNx5lVC5HYbpxdnCJH9wxg/Mf5hpVmppzRGlqd1QzNTWFEydODGyNtlotTE5O1gy4+Le+m9y6LY9c9Hl5v0uGoXPC3cejoRdffLEq4/tdoyiWNLI70tK22IYzvG0y/nJJd1zSn15+9nyHl9H0BulnPAfgP+Sc7wTwTwH8m5TSnQC+BuDHOefbAPx44f8DKwMhz9FCrNHRQ8jzKkNPzTjnfATAkYW/T6WUXgKwFcDnAHxq4bZHATwJ4KtNdc3OzuLIkSM1gxfuzlTjdQZO3OFouiu61bjdj0vx5TQpGvKoxsPdmdOCnFEVjbV0R8YIVM7gTJ9fXaSAunbLnZga7ThXCufmwbFRo7a5uTmMj48j5/zMQt8uSZ7UjLVdF8HGuSY0RbohehnxsEw1EMdScIzV9Yt1c/45LUG1Q8pOjU6ocas8KT/OHR1/9kndwUqXOYXKmLt3nZNjY2OMljWwNcrY8c4or5exTPlM+lt3zc1l5z7U5KLUlA61l3bT5NrUlOpR++NcGClzXbfuveFi6m/fvh2PPfYYTpw4MZA1unr1auzevbtmwMVodhpnnfJ2MZkdXPQ7vsP1XU7mR8dn//79AOqpDtmnw4cPV2X8DnBNufjtzlXNudvps7Be/usMQF0UL4WbO6VbY3m9F5Z0ZpxS2gFgH4BfAdi88BIAgHdwnlJxv/lKSunplNLT+iILDB8hz9HDpcr0cuVHDlwcLlWe+mEIXNno27UppTQF4G8B/HnO+WSxI8kpJbuKc86PAHgEAO655548OTlpNR4XH9adJTUFiXDnPL2yZnCy6lkjd6zaVrkTdInqnbO53kdtWXdu5bmw7uZdMBO24bIB6Ri6387MzKiZ/iXL884778xlLF2OUy+XJRdEg31l33U83ZmfK6M8m9xrLtR+ec25MiioaTtbBdar18pMUUD3TFmfwcXm5tzReNlr164t40BfskzHx8fz5ORkbezdGb7TDNjffjPVNCWUdxqs3ufOhZvcvJxm7OTsNO7yeZS5o8bXlOEN6L4Pbr755qps7969AIA777yzKtuyZQt+/etfsy+XLM9t27bl3bt31xhFapr6XHx3unN09752702XLatc00CXGbr33nurMtq9uMxIjmViP1SebN8FjHGBPfj8bq452wItc+8UN/+aXDJL9KUZp5TGcX5S/HXO+e8Wio+mlLYsXN8C4FjfrQaGipDn6CFkOloIeV596PkxTue3Kt8C8FLO+S/l0g8APLzw98MAvj/47gUGjYXdXchzhBBrdLQQa/TqRD980gMA/hWA51NK/7hQ9hcAvgHgeymlLwE4COALvSpqtVqYmpqq0R5N7iFKC5DacIft7pyrTKcGdOkIdW0ifeLcjdTQpqTCtb88O1UjIOeqxHqVCiI9w2vqiuXiPPO3Srs0GauV5vgL9Q9EnmkhEb2LGkaDDMCnE3RGNo7mIlxcZz6vc19zNKujOZsiYCk1zetujDWuNY1XOA5qkMcyNWZxMnZUmZs77Xab4ziwNTo2NoYNGzb0XGdNdGaTW1IvQzVXr3NjaYqy5a4510RedzR10ztK6VJHUxN0kQO6caA//vGPV2WkqTUS1vj4ONsb2Dt33bp11qjOuR/qfHSUPdco3406Tu6ozaV35TtP3a1oTKYUf2n85HIPOAM+lTHfDfpb9t1FhXPx1QmXe8C5TLlvTj/ox5r6HwBcKBHuH/fdUuCKwNq1a5FzDnmOEGKNjhZijV6dWPasTRdytHduHLqrYNl1111XlXG3x4Aduqui1qL3ux0zoZomDXNUgy61O9WMqbWocQ13UdwFAt1dl7rYUJPiDku1JvZJd3XUtFycZ2fmfzljU5Pp0B2ji9dIhVRZAAAYy0lEQVTsdplaB0Gtl2VqKOMCtrjsXi6erjNmc1mHCLpCOaMtBZ9b3dMoM8cGODRpgjon2Xd1G5mYmGgc24sBXZuca1GTi5HCaRoueTx/6wxonDamcPGCnVsK4d4pTvNz64bzh/JQLdhpxDfccAMA4O67767K7r///kVlNBTVNXDy5MklaVO9MD4+js2bN9feQ86t0BnJNbnvOJc8l5mKc1kZIgfWp+/rkt1rcjfTdvV9QNbKvUNdRifHMjqDRLbl5pPO/w8++KBveUY4zEAgEAgEhoz4GAcCgUAgMGQsO02dUrK+V0o3uHimJ06cAFCnFGgwRepS6QCXxov0gdLJ/C2pJaBLXygFxXYdDetispKKdjSsGoaVvnTab46Tey4dL5e6i2OozzA9PT1QCoyJy5WWKWn3C/XPUWAcA2csxed1VJWOp/at7JNL3cnfqi8tr+n9LioX54AalfE+1qFUu6NbKQ+t18Vrd9GNGIFr0Gi1WtZn0hmmuOhZ7rjE0cocDy1zRy6ufTcfSuMrd835TCuaDPW4ltzxidKrd911FwDgYx/7WFVGX2JS09pPPbY6e/bsQNNijo2NYdOmTbU56ozUnKEV17CuAz67i+3Q9B5yMeUdxatlvM+lv2QbzvjPvY/0eItl/K2LAuj8hx0l7+ZkmSazX3mGZhwIBAKBwJCxrJoxE5erJuO0Fhpi6Y6R148ePVqVaVQXoO5axGt6j8v8Q+1GM+nQJUF3QtwVUzNVLYdm+VrmEoe7nRjhxoFtOQMXZ8DljA5K46rLoUk5DUSNn5zLC/92WWzcDtclM+ffLnOLy7DiIuhw3FV2TYZAumN2mcRKIyenYbn5p2258WJbpYvKUmLf9otWq9XTtYP9cO3rfaWBmjPsc1GxXH3OWMdpcg7uGuXhjLV03ZLl4DWVARm13bt3V2X79u1bVMb3i2OMdP5s3Lix0cVvqWi329iwYUNNTnxebYfPpswc32suEqKLaOZimLuoc7zu3hEuQ5SbJ3wG7ZszyKOLpd7HepxhGOWudfA+F+FQ4WLlr1+/vu8oXKEZBwKBQCAwZMTHOBAIBAKBIWNZaerZ2VkcPny4FpnGGRQ5v0ZHo5QGIEpFlKns9H6lykq/UO2TS+hAulqpDdankaCcH5yrlyCVoVS7MyQidaTpz3hd6RGOk0YWK5N0DAJjY2O1dmkcp3KlLFxkHpVnGZVL63Up2ziOLoWjM4hqovFdQnIXcccZLLn7nCGI8+Xk327uKvhbvW+Qhj6K+fl5uy6dv6mLqubK2G+tg204v2RFU6Q9Z0Dj7isNJYHF/sNAd545+ptr88Ybb6yuMTUhI2wBwK233gqgHoHLGTa699HU1NTAaeoy6iHfYbq+OAb6DmO/9FiR89kdJbnjIHfEQCjt61JMsn0Xfc4ZUDm5O/qbfWpKJtRrbXEMNcYAx0mN9JZy7BCacSAQCAQCQ8ayasatVguTk5O1HQw1Iy3jTkJjtjKSirrqlNqK7nC5S3G7Ot2RMcWd65NqIS4yEMEyFzHJJS7XnVLTTpPm+Fovjdu0H9SStcztfqempi6LAZeCz63R0Phs6l7A3a5qxmVUH2e4pvLneCpL4FzPnOFcGUfWxWJ2aTKdsY/2k+1Txmqcw/vUMNG1z366eVIakQxaO84549y5c9aoyrmVOaagKSpRr9jQ5e9cHdquc0Fxa8lFa2OZGhHyurITNL5iLGVNg7ht2zYAwC233LKoTFku50JHmZdGeUtJu9cLjKim64Hy0bXEsXNRB9260fpLuPemMhJNEbW0fsqiyahO++tcHN17mM/lXKZcrgTOJ32ncc6o7NgXHeucc99RD0MzDgQCgUBgyIiPcSAQCAQCQ8ay0tRjY2M1owbA0wjO2IKUj4t85YwEHJ3r6B9G9lKq6tix8zm7lfZghB2X+o99d4ZhzpDIGQsRzpeTVDoAHD58GADwxhtvVGU0GNAoYi4BwapVqwZKU3c6HZw6dapGozsDKo7x8ePHqzKXso10M8fd0bRKHZNmU1qUv9GIQ/yt0nKk0jivXLpEF3HHUU7OMIxzQe+ncYzzjdTxcmkgy36wrct17OCiHTkDLpfW0MHR6c7IsVfkr7ItF1XNzS3nU0zoO4KUtBppbd++HQCwc+dOAPXjM1LXWsY6dA46mrp8FuD8sw56jZ45c8ZGONSx5tzUdeDmH8fPHR1wHF18gF4JOghn/OfiCbijExe5jnNAx738rc4J937ne0NpalLSaqzlxnUpx0ihGQcCgUAgMGQsq2ZM4xA1juDuUXcuNBdXbZW7I9VWy52N7pzcrou7P9XQfvKTnwAAnn/++UX300UBAB544AEA3Z2QPoPTbtzOsSl6FvvrDEx0bLhzdUZdaszAsdDfbty4caDGIbOzszh27Fht90f56FiU0cvK6wTr4VioZuEM6BzTQKiRlDMYoUbDcVItykX3cRHNnAZP+Ti3J5cQnfepFsLn1vscg7R27drLEoGLRj9lv3ulVWyKe+6MZYheafsoDxcH2bnzscxFhnOR81S72bp1K4C6pkuDLBpuce4AXcaMkZ6ArvxUy3QpNV3kvAtFP7tYtFqtRa5yHB8dCxcBkOtL1yHnpHM1ZL/13eQ0Q7eW3JpzRnqESyXrYmOz7/qs7Dv/1f46I0um6FVDUc4TrZdruIze1e8a7XlXSml1SunXKaXnUkovpJT+40L5zpTSr1JKr6aU/ial1ByBPXDFIGQ6Wgh5jhY6nQ5Cnlcf+tGMzwL4dM75g5TSOIB/SCn9CMC/B/Bfcs7fTSn9DwBfAvDfmyrKOWNubq6m/blzBhf3lrs5py07FwGeBarGw53QCy+8UJU99thjAICf//znVRl3iZ/85CerMu6K1V2B4PNofGvumN5///2qjJqrC+rgdvqlc7o+q+5W2SeXJFvHZGJignUNRKadTgczMzPWfUvl5NwmKBfdgVLDd/GiXXxYp+24+cRAJC6IDHfFTlvVXTr/dmfALkuN0xLdNcpHd92luxtwYY1yoT8DW6Ns342HYyCctqwotTyXIcddd2fBTmtzsc05zroeuV5Ug6VGvGXLlqqMWrBqvzw/5v1qw8G1rOvMxcB3Lj6lzQtQk/NA5EmWw8VS1vcF/9b+OXewkvFzQY0Uzj3Knd+7DF7lOtQ6XCANF6/c2Rawfb6b9R196NAhAMCrr75alXH+MeY40J0T+o6gZly6+/XLdPTUjPN50PJlfOG/DODTAP7XQvmjAD7fV4uBoSNkOloIeY4WUkoIeV596IvMTim1U0r/COAYgMcBvAZgOufM7cYhAFsv8NuvpJSeTik9rTuQwHBxsTJVeWpe6MBwMag1Osh814GLx6DkqeFwA1c2+jLgyjnPA9ibUtoA4H8D+Gi/DeScHwHwCADs2bMnT05OWupYDbOo+iv1Q1WfkbiALqWzYcOG8w9jjLaUMuBvn3nmmars9ddfB1CnZ0hDMe4s0HVvcCm5aDii6R1dej1nOFG6Dzg60hn3KK1ZutMAPnbr+Pi40kwXJVOV5x133JEnJiZ6UpUcA+0zqS93PEE6Sl2R+onupGUqd84t/a0akwF1Ct25TbDvKk+XrrGkHnVesZ96TFEafOl9Lo1bacQkhlQDWaNr1qzJpdGJS67uaMImdycXH9wZgfH5ygTtgB9LXYekm3mkpK5+lB/fFUB3LasBF+ugYZb+hrS3zgFn3NZElzqDI+faNSh57t27NwPeCFTnkou9zr5qvGped7HGSec6g6tekes4110KRWfw1WQgq7S6OzY7cOAAgK7R7u9///vq2sGDBwF0j7aALiWtc4LfCF2jHJNyjfa7wV2SKWbOeRrAEwD+GYANKSX25CYAh5dSV+DKQMh0tBDyHC2EPK8e9NSMU0rXA5jNOU+nlNYA+AyA/4zzE+RfAPgugIcBfL/fRnvtut2OmTshp2lyV6c7ZwbHeOutt6qyxx9/HADwwx/+sCp7++23AdQNOx588EEAwEMPPVSV3XPPPQD8Lo19Uq2dhkm6E+d9ZaAPfRaX8FtN750RGHd9aqThMgSJC9ZAZNpqtTA1NVUbd6cduV0vd8+qvXBcnIEH63NsSS+XG2rGLjsQd9FK5zmNhX2iSwPQlYHuoqlxs37n2uSMfRROs3Da4aDlSeScrRZa3lP2xz1TqRGq1uI0Gc511WQIXftcVzS4AoDbbrsNQDc4hzIxnAO6bvi3rn1qv+4+bZ9oCgbTK3uRWyutVguzs7NIKW0YhDw7nQ5Onz5tY7XreuT8Vg3axR8vDa3cGtW2XKxnwgVAcfU5o0w33uynvkO5Nn/7299WZU888QQA4LnnngPQ/QYAXSNSF5hH7yObokaCnG9lP/uNTd0PTb0FwKMppTbOa9Lfyzn/n5TSiwC+m1L6OoBnAXyrrxYDVwJCpqOFkOcIYeGD9ETI8+pCz49xzvm3APaZ8gMA7r8cnQpcXoRMRwshz9HCmjVrkHMOeV5lWPYIXHNzczVqizSGGtQ4Yw9Se+rnyzJSjI4m/sUvflGVkaY+cuRIVcaD+Hvvvbcq++xnPwsA+MQnPlGVkaoi5VAaAAF1yoJtaLQv0mEurrWLdkPaQyk7WqSXade0LmBxNCtg8BGbWq0WVq9ebaPwOKpSwf43RdxxNLGCtKGLT6v3sx4Xf9oZk/Caypj0lVJwlKfeR/mwbzpfHT3oonI58Bl1vMbHxy9LBK52u20Nyly6RIWjrimPcrz1b0eJq6ycQSWNtJSm5hECx1zpSh7v6LGRM+pyMaRLH3NHtbujBRfbXOGOWS5XSkyt1/nDsn/6ruFYuGho/K1LW+iisulRG9tQo8kmKte9UwjtG+eRi7DIdz8AvPLKKwC63wjtm4sAR6qbPshAd/41rQNg8VpqQsSmDgQCgUBgyFhWzRg4v1PQ3Re1Ct09uMN+aoxqRMHf0vTeRfbS3fTtt9++qN69e/cCqEfbuv/++xe1Rc2IO0PddTs3HUJ3XS7GrsuIQzgDB46d28G6aDguktIgwQg/hNPI+Wz63C6zDu/juLv+6m6ebbjYsr2ydZUaTa9ob+wnDQOB7pzQbC7MUMVdv4ty5NxbesG5Z505c2bgmhTl2ZQ9R/uhY+s03XK+Oi3YZUfTCFi7du2q/Qt0XZDUSKuMDazrh9qyasH827kJOriIWY7FIZzLm2PFLifIXrk40G5d6HO4dcu/SzdEvV/ZD+YZ0Eh7LtoW54KL8+4YlzKKFtB1U3366aersieffBIA8NJLL1Vl/F40sRVuvHRNcO44A93ynRuacSAQCAQCKwTxMQ4EAoFAYMhYVpo6pVTRJoQzhCKl5KKxuGD1rE/pLvqBKTVNA6s33nijKmOaxFtuuaUqI72ltDfbJd3iUigqXco6lMYgddnkU+0oIaVHnM+uS2fmopidPHmy72gw/aDdbmPdunW1PpOOVGrG0e0c2zKRxYVQGtBpHW6eaJsuqQDbohGW1kuqzFHXOl9dujUaj3AuaBKCpmMKZ0zjjNt0jr333nt2PVwKUkoYGxuz9TojNx1TjrNGbCplpEY7NMyiMYz+rTQ1DbM0AhIpQZekg+8DZwyp69bRis4fuPSVdlSuzhXne+x8ii/kZzzI46SZmRk8++yz9j2kZY6edcdv5bvW+SrrsQ2j6Cn9zHZ1vbtxZ92sTw2o3nzzTQBdYyyg6zf82muvVWXletR63VFLUwIKTRDCOanHUM4vO2jqQCAQCARWEJZdM56YmKhpxtx16M7FJVenRqJuSU3aDXcjqi1/9KPnw7syQg/Q3em5yE5qMMD22U/VmrnT0+dybgvcOZXxooHuOLgdue6+uPvXyGLsmz6rG5NDhw7ZiEkXi1arhTVr1ljNVDUmZ/hCOM3GxfF16dycuxPnjN7HenQcy0hm2g/KUXfJfB5n2KHPStbFMQSMb+5SQ6rGyDFUWXF+qrZ3+vTpgRsBMfqW04y1jNqvMgXsr3NJZKS1m266qbpGgyxdj9Q+1CWMY+OiSKlMOf9dlDqX+N2lqnRpS100u/KaM05U2TcZESoGbWR57NgxfPOb36wxNBx3GqoCXU1P5xw1Up2vHBfOQ2eM6LRgZ8zmGLN33nmn+pvGkowXrVrw/v37F91PF1eNac+/3buCMtF3Bf9W+TM2tc5TlrnY3FrmNO0LITTjQCAQCASGjPgYBwKBQCAwZCwrTT0/P4/p6WnrS+ZoHFX3SUcpJUgKgpSWi+jiDu5dujxH3yp9QQrG0TP8W/0VHdVYBj4HFhtxKN1FmsilA3TGWkr7sF36vQLAs88+WzOuuVTMz89jZmbG0jLOqEupoibajr9VCpTXXKB9l75OZce2lPos6WlnOKfguCtVyfmnBlwvv/wygK4RiT4DaUGdJww+7yJD6bOSZtWxPn369MD9jDudDmZmZuyY6twpE2IA3bWhhi40xGKkLDXWKiNmAd7wkPXqe4Py0N+WsQgcvarjxXXbRD+Xf2td+lutwxkj9Yt+kwr0i9OnT+OXv/wlrr/++qqMKQTVkJVJNvQYhO8pl0iDctWjMd6v65xr360vZ/hI+hnopjY8duzYovvpv+yS4ziDLGc06wzoeJ+j2tWA0B2dEPrOn52d7XuNhmYcCAQCgcCQsewRuHLOVkPSXbeLtczdhmp/uosD6rtTZxzgosZwN9fLvYE7ILcTogarWqhzj2GZ7ty4c2T7eo27PzXW4k5UI4tpWj+C46kRo5577rmBasYpJbTbbZuk3GmwLvqSc/VwBl/OEMK5LDnZUVNyrkJlXfq39o1zR3fYlI8aFapBif4O6O6mnfahY0NDFNen0tjIGaZcCubn53Hq1Cnr4qIsE/uthkE0cFFDl9ItSbVmZagIykjHyEUz43Wto3xvOO2+fNbyPmesVWqrOrd4Xy+N1s33so6y7kGA+QBUdtRC1QXpxRdfBFB/v5E9Uq2aY0x56ruHa1Tr5bwuGR2g/m7inNeIWsw1wPt7pVB0aR1dNEfK3bkicV7rumVbmir16NGjAOrvFI6dvo/OnDnTt/thaMaBQCAQCAwZ8TEOBAKBQGDIWPYUip1Op0YJO/qR9J+CFIDSAiXF7CJmuegxSu2RvlGqgvSM9o10iwtyzj651JAKtuv8THm/9oO0nD4DKSCXxk3HhnT07373u6rs4MGDlra5VDgKytHPSoG5RBFlikF9HtanNDvniYus5VIX6m853m6Mm6gqpftoWMJoQEDX2OO+++4DADz44IPVNUaDc37jKnfnv1z6uQPnDcicIdyloNPp4PTp07X57Qx56Ge5e/fuqoxHJ+pLTDqTtLIa/DiDRq49NXLjb1zyEWdMVUZYUjg/fgf9LX/jKGQXO8AdlTQlkijp10EacbXbbaxfv75GlZKm1vntEqa4mAZlkglGOgS669sdR+m8ddHbOGauT+yHizug4H06T1w63jK2hJvrOg4cr5/+9KdVGcfhU5/6VFXGsSiP7fqVZ2jGgUAgEAgMGWnQpvSNjaV0HMBpAO8uW6OXB9dh5T7DzTnn63vf1hshzysCA5MnMDIyXcnyBGKNOqxkmfYlz2X9GANASunpnPN9y9rogDEKzzAojMJYjMIzDBIrfTxWev8HjVEYj1F4hl4ImjoQCAQCgSEjPsaBQCAQCAwZw/gYPzKENgeNUXiGQWEUxmIUnmGQWOnjsdL7P2iMwniMwjM0YtnPjAOBQCAQCNQRNHUgEAgEAkNGfIwDgUAgEBgylvVjnFL605TSKymlV1NKX1vOti8GKaVtKaUnUkovppReSCn9u4Xya1NKj6eU9i/8u7FXXaOIkOdoYaXJEwiZ9sJKk+nVLM9lOzNOKbUB/B7AZwAcAvAUgC/mnF9clg5cBFJKWwBsyTk/k1JaB+A3AD4P4F8DOJFz/sbCBN+Yc/7qELu67Ah5jhZWojyBkGkTVqJMr2Z5LqdmfD+AV3POB3LO5wB8F8DnlrH9JSPnfCTn/MzC36cAvARgK873+9GF2x7F+clytSHkOVpYcfIEQqY9sOJkejXLczk/xlsBvCX/f2ihbEUgpbQDwD4AvwKwOefMJLbvANh8gZ+NMkKeo4UVLU8gZGqwomV6tckzDLj6QEppCsDfAvjznPNJvZbP8/zhH7aCEPIcPYRMRwtXozyX82N8GMA2+f+bFsquaKSUxnF+Uvx1zvnvFoqPLpxt8Izj2LD6N0SEPEcLK1KeQMi0AStSplerPJfzY/wUgNtSSjtTSqsA/BmAHyxj+0tGOp/o8lsAXso5/6Vc+gGAhxf+fhjA95e7b1cAQp6jhRUnTyBk2gMrTqZXszyXO4XiPwfwXwG0AXw75/yflq3xi0BK6UEA/w/A8wCYnfovcP4M43sAtgM4COALOecTQ+nkEBHyHC2sNHkCIdNeWGkyvZrlGeEwA4FAIBAYMsKAKxAIBAKBISM+xoFAIBAIDBnxMQ4EAoFAYMiIj3EgEAgEAkNGfIwDgUAgEBgy4mMcCAQCgcCQER/jQCAQCASGjP8PRxGM/E1jOTcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors=[\"blue\",\"green\",\"red\",\"black\"]\n",
    "fig3=plt.figure(figsize=(8,8))\n",
    "columns3=4\n",
    "rows3=1\n",
    "j=1\n",
    "\n",
    "\n",
    "##### CANCER ######\n",
    "for n in cancer_ex:\n",
    "    fig3.add_subplot(rows3,columns3,j)\n",
    "    img=mpimg.imread(nodule_files[n])\n",
    "    plt.imshow(img,cmap=plt.cm.binary)\n",
    "    j=j+1\n",
    "plt.show()\n",
    "\n",
    "\n",
    "for i,n in enumerate(cancer_ex):  \n",
    "    img=cv2.imread(nodule_files[n])\n",
    "    histr=cv2.calcHist([img],[0], None, [40], [0,40])\n",
    "    plt.plot(histr,color = colors[i],label=\"Image # \"+str(i+1))\n",
    "    plt.xlim([0,40])\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "##### NON CANCER ######\n",
    "\n",
    "fig4=plt.figure(figsize=(8,8))\n",
    "columns4=4\n",
    "rows4=1\n",
    "j=1\n",
    "\n",
    "for n in noncancer_ex:\n",
    "    fig4.add_subplot(rows4,columns4,j)\n",
    "    img=mpimg.imread(nodule_files[n])\n",
    "    plt.imshow(img,cmap=plt.cm.binary)\n",
    "    j=j+1\n",
    "plt.show()\n",
    "\n",
    "for i,n in enumerate(noncancer_ex):  \n",
    "    img=cv2.imread(nodule_files[n])\n",
    "    histr=cv2.calcHist([img],[0], None, [40], [0,40])\n",
    "    plt.plot(histr,color = colors[i],label=\"Image # \"+str(i+1))\n",
    "    plt.xlim([0,40])\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.4: Convert image data to tensors.** <br>\n",
    "Required format for Keras is 4D tensor.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1768/1768 [00:00<00:00, 3982.97it/s]\n",
      "100%|| 590/590 [00:00<00:00, 4393.43it/s]\n",
      "100%|| 590/590 [00:00<00:00, 4413.51it/s]\n"
     ]
    }
   ],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (40, 40, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 40, 40, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "train_tensors = paths_to_tensor(train_nodules).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(val_nodules).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_nodules).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.5: Data Augmentation** <br>\n",
    "The following data augmentation techniques will be applied:\n",
    "- rescaling: to obtain vectors with values from 0 to 1: easier to handle by the model (stability, overflow, optimization etc.)\n",
    "- rotation (45 degrees): so the nodule is classified the same way even if the CT scan is rotated\n",
    "- vertical flip\n",
    "- horizontal flip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below step was used only to create folders train, validation and test for image data.\n",
    "In order to use keras augmentation functions, it is required that the images are already split into train, validation and test sets and they are in separate folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run only once on pc to create train validation and test \n",
    "folders_to_be_created = [\"train\",\"validation\",\"test\"]\n",
    "\n",
    "source = os.getcwd()\n",
    "\n",
    "for new_path in folders_to_be_created:\n",
    "    if not os.path.exists(path+\"/LUNA2016/images/\"+new_path):\n",
    "        os.makedirs(path+\"/LUNA2016/images/\"+new_path)\n",
    "\n",
    "folders_to_be_created2 = [\"pos\",\"neg\"]\n",
    "for folder in folders_to_be_created:\n",
    "    for new_path in folders_to_be_created2:\n",
    "        if not os.path.exists(path+\"/LUNA2016/images/\"+folder+ \"/\" + new_path):\n",
    "            os.makedirs(path+\"/LUNA2016/images/\" + folder + \"/\" +new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run only once on pc to create train validation and test \n",
    "for nodule in train_nodules:\n",
    "    index=np.where(train_nodules==nodule)\n",
    "    if train_labels[index][0,0]==0 and train_labels[index][0,1]==1:\n",
    "        shutil.copy(nodule, path+\"\\\\LUNA2016\\\\images\\\\train\\\\pos\")\n",
    "    else:\n",
    "        shutil.copy(nodule, path+\"\\\\LUNA2016\\\\images\\\\train\\\\neg\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run only once on pc to create train validation and test \n",
    "for nodule in test_nodules:\n",
    "    index=np.where(test_nodules==nodule)\n",
    "    if test_labels[index][0,0]==0 and test_labels[index][0,1]==1:\n",
    "        shutil.copy(nodule, path+\"\\\\LUNA2016\\\\images\\\\test\\\\pos\")\n",
    "    else:\n",
    "        shutil.copy(nodule, path+\"\\\\LUNA2016\\\\images\\\\test\\\\neg\")\n",
    "\n",
    "for nodule in val_nodules:\n",
    "    index=np.where(val_nodules==nodule)\n",
    "    if val_labels[index][0,0]==0 and val_labels[index][0,1]==1:\n",
    "        shutil.copy(nodule, path+\"\\\\LUNA2016\\\\images\\\\validation\\\\pos\")\n",
    "    else:\n",
    "        shutil.copy(nodule, path+\"\\\\LUNA2016\\\\images\\\\validation\\\\neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1768 images belonging to 2 classes.\n",
      "Found 590 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#train_tensors = paths_to_tensor(path+\"\\LUNA2016\\images\\train\").astype('float32')/255\n",
    "#valid_tensors = paths_to_tensor(path+\"\\\\LUNA2016\\\\images\\\\test\").astype('float32')/255\n",
    "#test_tensors = paths_to_tensor(path+\"\\\\LUNA2016\\\\images\\\\validate\").astype('float32')/255\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "#augmentation for training\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,rotation_range=45,\n",
    "        horizontal_flip=True, vertical_flip=True)\n",
    "#path+\"\\\\LUNA2016\\\\images\\\\train\\\\\", \n",
    "# generate batches of augmented image data from train directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/luna16/images/train',\n",
    "        target_size=(40, 40),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary') \n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        #path+\"\\\\LUNA2016\\\\images\\\\validation\\\\\", \n",
    "        \"/luna16/images/validation\",\n",
    "        target_size=(40, 40),\n",
    "        batch_size=batch_size,\n",
    "       class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Testing different CNN architectures.\n",
    "**Step 2.1. Model 1: 3 convolutional layers and 2 fully connected layers.** <br> \n",
    "\n",
    "First, we will train a simple CNN architecture with 3 convolutional layers and 2 fully connected layers. Then, we will compare the results obtained with augmented and non-augmented data. First, the original data with no augmentation techniques will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 84,546\n",
      "Trainable params: 84,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', input_shape=(40,40,3)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1768 samples, validate on 590 samples\n",
      "Epoch 1/80\n",
      "1768/1768 [==============================] - 1s 460us/step - loss: 9.2928e-04 - acc: 0.9994 - val_loss: 0.3132 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31316, saving model to weights.3CL.NOAUG.hdf5\n",
      "Epoch 2/80\n",
      "1768/1768 [==============================] - 1s 473us/step - loss: 6.9624e-04 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31316 to 0.30186, saving model to weights.3CL.NOAUG.hdf5\n",
      "Epoch 3/80\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 5.3889e-04 - acc: 1.0000 - val_loss: 0.3032 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30186\n",
      "Epoch 4/80\n",
      "1768/1768 [==============================] - 1s 468us/step - loss: 0.0057 - acc: 0.9977 - val_loss: 0.3225 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30186\n",
      "Epoch 5/80\n",
      "1768/1768 [==============================] - 1s 462us/step - loss: 0.0040 - acc: 0.9983 - val_loss: 0.2765 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.30186 to 0.27652, saving model to weights.3CL.NOAUG.hdf5\n",
      "Epoch 6/80\n",
      "1768/1768 [==============================] - 1s 463us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.3002 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27652\n",
      "Epoch 7/80\n",
      "1768/1768 [==============================] - 1s 461us/step - loss: 0.0108 - acc: 0.9983 - val_loss: 0.3581 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27652\n",
      "Epoch 8/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0077 - acc: 0.9972 - val_loss: 0.3116 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27652\n",
      "Epoch 9/80\n",
      "1768/1768 [==============================] - 1s 460us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.3293 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27652\n",
      "Epoch 10/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.3148 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27652\n",
      "Epoch 11/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0053 - acc: 0.9977 - val_loss: 0.2790 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.27652\n",
      "Epoch 12/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.3088 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.27652\n",
      "Epoch 13/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 4.8316e-04 - acc: 1.0000 - val_loss: 0.3318 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.27652\n",
      "Epoch 14/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0094 - acc: 0.9977 - val_loss: 0.2850 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.27652\n",
      "Epoch 15/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0090 - acc: 0.9960 - val_loss: 0.3343 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.27652\n",
      "Epoch 16/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0271 - acc: 0.9955 - val_loss: 0.2430 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27652 to 0.24301, saving model to weights.3CL.NOAUG.hdf5\n",
      "Epoch 17/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.2630 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.24301\n",
      "Epoch 18/80\n",
      "1768/1768 [==============================] - 1s 455us/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.2814 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.24301\n",
      "Epoch 19/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0038 - acc: 0.9994 - val_loss: 0.2646 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.24301\n",
      "Epoch 20/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0048 - acc: 0.9994 - val_loss: 0.2820 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.24301\n",
      "Epoch 21/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0078 - acc: 0.9972 - val_loss: 0.2984 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.24301\n",
      "Epoch 22/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0068 - acc: 0.9989 - val_loss: 0.2974 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.24301\n",
      "Epoch 23/80\n",
      "1768/1768 [==============================] - 1s 453us/step - loss: 0.0036 - acc: 0.9994 - val_loss: 0.2982 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.24301\n",
      "Epoch 24/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.2980 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.24301\n",
      "Epoch 25/80\n",
      "1768/1768 [==============================] - 1s 456us/step - loss: 0.0028 - acc: 0.9977 - val_loss: 0.2592 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.24301\n",
      "Epoch 26/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.2690 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.24301\n",
      "Epoch 27/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0055 - acc: 0.9994 - val_loss: 0.2663 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.24301\n",
      "Epoch 28/80\n",
      "1768/1768 [==============================] - 1s 454us/step - loss: 0.0242 - acc: 0.9949 - val_loss: 0.2812 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.24301\n",
      "Epoch 29/80\n",
      "1768/1768 [==============================] - 1s 465us/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.2629 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.24301\n",
      "Epoch 30/80\n",
      "1768/1768 [==============================] - 1s 469us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.2964 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.24301\n",
      "Epoch 31/80\n",
      "1768/1768 [==============================] - 1s 463us/step - loss: 0.0058 - acc: 0.9977 - val_loss: 0.3273 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.24301\n",
      "Epoch 32/80\n",
      "1768/1768 [==============================] - 1s 468us/step - loss: 0.0112 - acc: 0.9960 - val_loss: 0.2712 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.24301\n",
      "Epoch 33/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0071 - acc: 0.9972 - val_loss: 0.3132 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.24301\n",
      "Epoch 34/80\n",
      "1768/1768 [==============================] - 1s 454us/step - loss: 0.0033 - acc: 0.9994 - val_loss: 0.2781 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.24301\n",
      "Epoch 35/80\n",
      "1768/1768 [==============================] - 1s 456us/step - loss: 0.0012 - acc: 0.9994 - val_loss: 0.2978 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.24301\n",
      "Epoch 36/80\n",
      "1768/1768 [==============================] - 1s 462us/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.3018 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.24301\n",
      "Epoch 37/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0037 - acc: 0.9983 - val_loss: 0.3240 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.24301\n",
      "Epoch 38/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.3013 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.24301\n",
      "Epoch 39/80\n",
      "1768/1768 [==============================] - 1s 453us/step - loss: 4.1483e-04 - acc: 1.0000 - val_loss: 0.3088 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.24301\n",
      "Epoch 40/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.3224 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.24301\n",
      "Epoch 41/80\n",
      "1768/1768 [==============================] - 1s 456us/step - loss: 0.0049 - acc: 0.9994 - val_loss: 0.3194 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.24301\n",
      "Epoch 42/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.3771 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.24301\n",
      "Epoch 43/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0110 - acc: 0.9977 - val_loss: 0.3160 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.24301\n",
      "Epoch 44/80\n",
      "1768/1768 [==============================] - 1s 453us/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.3123 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.24301\n",
      "Epoch 45/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.3338 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.24301\n",
      "Epoch 46/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0083 - acc: 0.9977 - val_loss: 0.3094 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.24301\n",
      "Epoch 47/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0032 - acc: 0.9989 - val_loss: 0.2876 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.24301\n",
      "Epoch 48/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.2936 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.24301\n",
      "Epoch 49/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0088 - acc: 0.9989 - val_loss: 0.2948 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.24301\n",
      "Epoch 50/80\n",
      "1768/1768 [==============================] - 1s 454us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.3266 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.24301\n",
      "Epoch 51/80\n",
      "1768/1768 [==============================] - 1s 462us/step - loss: 3.1211e-04 - acc: 1.0000 - val_loss: 0.3208 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.24301\n",
      "Epoch 52/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 3.2049e-04 - acc: 1.0000 - val_loss: 0.3204 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.24301\n",
      "Epoch 53/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 3.5386e-04 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.24301\n",
      "Epoch 54/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.2740 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.24301\n",
      "Epoch 55/80\n",
      "1768/1768 [==============================] - 1s 455us/step - loss: 0.0046 - acc: 0.9983 - val_loss: 0.3166 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.24301\n",
      "Epoch 56/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0054 - acc: 0.9994 - val_loss: 0.2706 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.24301\n",
      "Epoch 57/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0085 - acc: 0.9960 - val_loss: 0.3780 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.24301\n",
      "Epoch 58/80\n",
      "1768/1768 [==============================] - 1s 462us/step - loss: 0.0048 - acc: 0.9977 - val_loss: 0.3245 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.24301\n",
      "Epoch 59/80\n",
      "1768/1768 [==============================] - 1s 456us/step - loss: 0.0110 - acc: 0.9966 - val_loss: 0.2971 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.24301\n",
      "Epoch 60/80\n",
      "1768/1768 [==============================] - 1s 467us/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.3532 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.24301\n",
      "Epoch 61/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.3453 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.24301\n",
      "Epoch 62/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0115 - acc: 0.9977 - val_loss: 0.2936 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.24301\n",
      "Epoch 63/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.4193 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.24301\n",
      "Epoch 64/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.2798 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.24301\n",
      "Epoch 65/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.2843 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.24301\n",
      "Epoch 66/80\n",
      "1768/1768 [==============================] - 1s 456us/step - loss: 0.0014 - acc: 0.9989 - val_loss: 0.2662 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.24301\n",
      "Epoch 67/80\n",
      "1768/1768 [==============================] - 1s 458us/step - loss: 0.0027 - acc: 0.9983 - val_loss: 0.3534 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.24301\n",
      "Epoch 68/80\n",
      "1768/1768 [==============================] - 1s 460us/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.2705 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.24301\n",
      "Epoch 69/80\n",
      "1768/1768 [==============================] - 1s 462us/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.2620 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.24301\n",
      "Epoch 70/80\n",
      "1768/1768 [==============================] - 1s 459us/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.2946 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.24301\n",
      "Epoch 71/80\n",
      "1768/1768 [==============================] - 1s 454us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.3153 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.24301\n",
      "Epoch 72/80\n",
      "1768/1768 [==============================] - 1s 457us/step - loss: 9.4717e-04 - acc: 1.0000 - val_loss: 0.2989 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.24301\n",
      "Epoch 73/80\n",
      "1768/1768 [==============================] - 1s 461us/step - loss: 0.0102 - acc: 0.9983 - val_loss: 0.3472 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.24301\n",
      "Epoch 74/80\n",
      "1768/1768 [==============================] - 1s 456us/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.3767 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.24301\n",
      "Epoch 75/80\n",
      "1768/1768 [==============================] - 1s 462us/step - loss: 0.0037 - acc: 0.9983 - val_loss: 0.3641 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.24301\n",
      "Epoch 76/80\n",
      "1768/1768 [==============================] - 1s 465us/step - loss: 0.0141 - acc: 0.9972 - val_loss: 0.2852 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.24301\n",
      "Epoch 77/80\n",
      "1768/1768 [==============================] - 1s 456us/step - loss: 0.0042 - acc: 0.9983 - val_loss: 0.3544 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.24301\n",
      "Epoch 78/80\n",
      "1768/1768 [==============================] - 1s 470us/step - loss: 0.0016 - acc: 0.9994 - val_loss: 0.3367 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.24301\n",
      "Epoch 79/80\n",
      "1768/1768 [==============================] - 1s 464us/step - loss: 0.0027 - acc: 0.9977 - val_loss: 0.3200 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.24301\n",
      "Epoch 80/80\n",
      "1768/1768 [==============================] - 1s 465us/step - loss: 0.0060 - acc: 0.9977 - val_loss: 0.3447 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.24301\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.3CL.NOAUG.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "#model.fit_generator(datagen, samples_per_epoch=len(train_tensors), \n",
    "          #validation_data=(valid_tensors, val_labels),\n",
    "          #epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
    "        \n",
    "history1=model.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, val_labels),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.7966%\n"
     ]
    }
   ],
   "source": [
    "model_pred = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy = 100*np.sum(np.array(model_pred)==np.argmax(test_labels, axis=1))/len(model_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.2: Model 2 - Model 1 with dropout layers, batch normalization and reGlobal Average Pooling Layer.** <br>\n",
    "This time, another droput layer was added: for the last epochs we do not see much improvement and it could be a sign of overfitting. Also, to speed up the learning process, batch normalization technique was used. Another change to the first model was having Global Average Pooling layer instead of Faltten layer: it reduces number of parameters and it is another way to reduce the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 19, 19, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 20,290\n",
      "Trainable params: 20,162\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization,Activation\n",
    "\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, (2, 2), input_shape=(40,40,3)))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(32, (3, 3)))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model2.add(Dropout(0.4))\n",
    " \n",
    "model2.add(GlobalAveragePooling2D())\n",
    "model2.add(Dense(32, activation='relu'))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reduced the number of parameters from 84,546 to 20,290."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1768 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "1768/1768 [==============================] - 2s 918us/step - loss: 0.6636 - acc: 0.5871 - val_loss: 0.6566 - val_acc: 0.6881\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65662, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 2/50\n",
      "1768/1768 [==============================] - 1s 472us/step - loss: 0.5898 - acc: 0.6895 - val_loss: 0.5844 - val_acc: 0.7254\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65662 to 0.58437, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 3/50\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.5331 - acc: 0.7517 - val_loss: 0.5247 - val_acc: 0.7864\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.58437 to 0.52466, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 4/50\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.4751 - acc: 0.7907 - val_loss: 0.4842 - val_acc: 0.8186\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.52466 to 0.48417, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 5/50\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.4328 - acc: 0.8037 - val_loss: 0.5011 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.48417\n",
      "Epoch 6/50\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.4241 - acc: 0.8094 - val_loss: 0.4720 - val_acc: 0.7932\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48417 to 0.47202, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 7/50\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.4040 - acc: 0.8196 - val_loss: 0.4475 - val_acc: 0.8051\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.47202 to 0.44751, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 8/50\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.3847 - acc: 0.8354 - val_loss: 0.3530 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44751 to 0.35297, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 9/50\n",
      "1768/1768 [==============================] - 1s 472us/step - loss: 0.3737 - acc: 0.8394 - val_loss: 0.3389 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35297 to 0.33895, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 10/50\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.3693 - acc: 0.8360 - val_loss: 0.3426 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.33895\n",
      "Epoch 11/50\n",
      "1768/1768 [==============================] - 1s 469us/step - loss: 0.3469 - acc: 0.8399 - val_loss: 0.3403 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.33895\n",
      "Epoch 12/50\n",
      "1768/1768 [==============================] - 1s 472us/step - loss: 0.3244 - acc: 0.8518 - val_loss: 0.3254 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.33895 to 0.32539, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 13/50\n",
      "1768/1768 [==============================] - 1s 473us/step - loss: 0.3204 - acc: 0.8546 - val_loss: 0.3201 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.32539 to 0.32006, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 14/50\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.3151 - acc: 0.8586 - val_loss: 0.2810 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.32006 to 0.28097, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 15/50\n",
      "1768/1768 [==============================] - 1s 471us/step - loss: 0.3114 - acc: 0.8631 - val_loss: 0.2772 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.28097 to 0.27716, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 16/50\n",
      "1768/1768 [==============================] - 1s 468us/step - loss: 0.3070 - acc: 0.8722 - val_loss: 0.2624 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.27716 to 0.26236, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 17/50\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.2796 - acc: 0.8835 - val_loss: 0.2883 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.26236\n",
      "Epoch 18/50\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.2645 - acc: 0.8886 - val_loss: 0.2747 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26236\n",
      "Epoch 19/50\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.2932 - acc: 0.8671 - val_loss: 0.2778 - val_acc: 0.8932\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26236\n",
      "Epoch 20/50\n",
      "1768/1768 [==============================] - 1s 469us/step - loss: 0.2701 - acc: 0.8835 - val_loss: 0.2650 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.26236\n",
      "Epoch 21/50\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.2638 - acc: 0.8874 - val_loss: 0.2561 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.26236 to 0.25608, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 22/50\n",
      "1768/1768 [==============================] - 1s 470us/step - loss: 0.2559 - acc: 0.8925 - val_loss: 0.2857 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.25608\n",
      "Epoch 23/50\n",
      "1768/1768 [==============================] - 1s 469us/step - loss: 0.2545 - acc: 0.8897 - val_loss: 0.2425 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.25608 to 0.24252, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 24/50\n",
      "1768/1768 [==============================] - 1s 471us/step - loss: 0.2715 - acc: 0.8869 - val_loss: 0.2593 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.24252\n",
      "Epoch 25/50\n",
      "1768/1768 [==============================] - 1s 472us/step - loss: 0.2508 - acc: 0.8903 - val_loss: 0.2320 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.24252 to 0.23201, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 26/50\n",
      "1768/1768 [==============================] - 1s 472us/step - loss: 0.2512 - acc: 0.8942 - val_loss: 0.2542 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.23201\n",
      "Epoch 27/50\n",
      "1768/1768 [==============================] - 1s 469us/step - loss: 0.2395 - acc: 0.9033 - val_loss: 0.2270 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.23201 to 0.22699, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 28/50\n",
      "1768/1768 [==============================] - 1s 471us/step - loss: 0.2258 - acc: 0.9038 - val_loss: 0.2268 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.22699 to 0.22685, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 29/50\n",
      "1768/1768 [==============================] - 1s 468us/step - loss: 0.2296 - acc: 0.9005 - val_loss: 0.2787 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.22685\n",
      "Epoch 30/50\n",
      "1768/1768 [==============================] - 1s 469us/step - loss: 0.2378 - acc: 0.9010 - val_loss: 0.2169 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.22685 to 0.21691, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 31/50\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.2147 - acc: 0.9140 - val_loss: 0.2264 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.21691\n",
      "Epoch 32/50\n",
      "1768/1768 [==============================] - 1s 470us/step - loss: 0.2240 - acc: 0.9050 - val_loss: 0.2794 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.21691\n",
      "Epoch 33/50\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.2331 - acc: 0.9033 - val_loss: 0.2109 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.21691 to 0.21089, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 34/50\n",
      "1768/1768 [==============================] - 1s 489us/step - loss: 0.2155 - acc: 0.9146 - val_loss: 0.2222 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.21089\n",
      "Epoch 35/50\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.2229 - acc: 0.9021 - val_loss: 0.1997 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.21089 to 0.19975, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 36/50\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.2211 - acc: 0.9016 - val_loss: 0.2172 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.19975\n",
      "Epoch 37/50\n",
      "1768/1768 [==============================] - 1s 469us/step - loss: 0.2081 - acc: 0.9129 - val_loss: 0.2112 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.19975\n",
      "Epoch 38/50\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.2150 - acc: 0.9101 - val_loss: 0.1948 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19975 to 0.19477, saving model to weights.3CL2.NOAUG.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "1768/1768 [==============================] - 1s 470us/step - loss: 0.2174 - acc: 0.9135 - val_loss: 0.1911 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.19477 to 0.19114, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 40/50\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.2134 - acc: 0.9072 - val_loss: 0.1927 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.19114\n",
      "Epoch 41/50\n",
      "1768/1768 [==============================] - 1s 472us/step - loss: 0.2055 - acc: 0.9140 - val_loss: 0.2201 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.19114\n",
      "Epoch 42/50\n",
      "1768/1768 [==============================] - 1s 473us/step - loss: 0.1925 - acc: 0.9152 - val_loss: 0.2326 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.19114\n",
      "Epoch 43/50\n",
      "1768/1768 [==============================] - 1s 470us/step - loss: 0.2108 - acc: 0.9089 - val_loss: 0.1879 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.19114 to 0.18792, saving model to weights.3CL2.NOAUG.hdf5\n",
      "Epoch 44/50\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.1930 - acc: 0.9163 - val_loss: 0.1931 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.18792\n",
      "Epoch 45/50\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.1924 - acc: 0.9169 - val_loss: 0.2370 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.18792\n",
      "Epoch 46/50\n",
      "1768/1768 [==============================] - 1s 471us/step - loss: 0.1992 - acc: 0.9157 - val_loss: 0.2168 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.18792\n",
      "Epoch 47/50\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.1915 - acc: 0.9191 - val_loss: 0.1918 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.18792\n",
      "Epoch 48/50\n",
      "1768/1768 [==============================] - 1s 471us/step - loss: 0.1773 - acc: 0.9242 - val_loss: 0.2400 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.18792\n",
      "Epoch 49/50\n",
      "1768/1768 [==============================] - 1s 471us/step - loss: 0.1957 - acc: 0.9157 - val_loss: 0.2024 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.18792\n",
      "Epoch 50/50\n",
      "1768/1768 [==============================] - 1s 471us/step - loss: 0.1901 - acc: 0.9219 - val_loss: 0.1903 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.18792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fc17eaf60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 50\n",
    "checkpointer = ModelCheckpoint(filepath='weights.3CL2.NOAUG.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model2.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, val_labels),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 92.2034%\n"
     ]
    }
   ],
   "source": [
    "model2_pred = [np.argmax(model2.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy2 = 100*np.sum(np.array(model2_pred)==np.argmax(test_labels, axis=1))/len(model2_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy on test data dropped from 96.9492% to 92.2034%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.3: Model 3 - Model 2 but more filters and higher dropout probability.** <br>\n",
    "For Model 3 the dropout probability was increased to 0.5 and more filters were used: 32, 64, 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 19, 19, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 17, 17, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 97,858\n",
      "Trainable params: 97,410\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "model3.add(Conv2D(32, (2, 2), input_shape=(40,40,3)))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Conv2D(64, (3, 3)))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(Conv2D(128, (3, 3)))\n",
    "model3.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Activation('relu'))\n",
    "\n",
    "model3.add(GlobalAveragePooling2D())\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1768 samples, validate on 590 samples\n",
      "Epoch 1/40\n",
      "1768/1768 [==============================] - 2s 1ms/step - loss: 0.6440 - acc: 0.6250 - val_loss: 0.6686 - val_acc: 0.5576\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66857, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 2/40\n",
      "1768/1768 [==============================] - 1s 559us/step - loss: 0.5712 - acc: 0.6985 - val_loss: 0.6318 - val_acc: 0.6407\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66857 to 0.63175, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 3/40\n",
      "1768/1768 [==============================] - 1s 548us/step - loss: 0.5086 - acc: 0.7732 - val_loss: 0.6411 - val_acc: 0.6254\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.63175\n",
      "Epoch 4/40\n",
      "1768/1768 [==============================] - 1s 550us/step - loss: 0.4522 - acc: 0.7952 - val_loss: 0.4687 - val_acc: 0.7898\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63175 to 0.46873, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 5/40\n",
      "1768/1768 [==============================] - 1s 543us/step - loss: 0.4262 - acc: 0.7969 - val_loss: 0.4848 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.46873\n",
      "Epoch 6/40\n",
      "1768/1768 [==============================] - 1s 550us/step - loss: 0.3944 - acc: 0.8241 - val_loss: 0.3881 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46873 to 0.38805, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 7/40\n",
      "1768/1768 [==============================] - 1s 548us/step - loss: 0.3697 - acc: 0.8439 - val_loss: 0.4290 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.38805\n",
      "Epoch 8/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.3462 - acc: 0.8524 - val_loss: 0.4713 - val_acc: 0.8034\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.38805\n",
      "Epoch 9/40\n",
      "1768/1768 [==============================] - 1s 547us/step - loss: 0.3228 - acc: 0.8507 - val_loss: 0.3555 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.38805 to 0.35554, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 10/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.3243 - acc: 0.8546 - val_loss: 0.4101 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.35554\n",
      "Epoch 11/40\n",
      "1768/1768 [==============================] - 1s 547us/step - loss: 0.2876 - acc: 0.8807 - val_loss: 0.3961 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.35554\n",
      "Epoch 12/40\n",
      "1768/1768 [==============================] - 1s 548us/step - loss: 0.2845 - acc: 0.8807 - val_loss: 0.4121 - val_acc: 0.8492\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.35554\n",
      "Epoch 13/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.2937 - acc: 0.8790 - val_loss: 0.4088 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.35554\n",
      "Epoch 14/40\n",
      "1768/1768 [==============================] - 1s 547us/step - loss: 0.2718 - acc: 0.8812 - val_loss: 0.4072 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.35554\n",
      "Epoch 15/40\n",
      "1768/1768 [==============================] - 1s 545us/step - loss: 0.2675 - acc: 0.8880 - val_loss: 0.2950 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.35554 to 0.29497, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 16/40\n",
      "1768/1768 [==============================] - 1s 547us/step - loss: 0.2649 - acc: 0.8880 - val_loss: 0.2931 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.29497 to 0.29305, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 17/40\n",
      "1768/1768 [==============================] - 1s 549us/step - loss: 0.2549 - acc: 0.8869 - val_loss: 0.3904 - val_acc: 0.8627\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.29305\n",
      "Epoch 18/40\n",
      "1768/1768 [==============================] - 1s 547us/step - loss: 0.2515 - acc: 0.9027 - val_loss: 0.3204 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.29305\n",
      "Epoch 19/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.2499 - acc: 0.8942 - val_loss: 0.3176 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.29305\n",
      "Epoch 20/40\n",
      "1768/1768 [==============================] - 1s 547us/step - loss: 0.2403 - acc: 0.9010 - val_loss: 0.3467 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.29305\n",
      "Epoch 21/40\n",
      "1768/1768 [==============================] - 1s 547us/step - loss: 0.2536 - acc: 0.8993 - val_loss: 0.3122 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.29305\n",
      "Epoch 22/40\n",
      "1768/1768 [==============================] - 1s 548us/step - loss: 0.2527 - acc: 0.8999 - val_loss: 0.2877 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.29305 to 0.28766, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 23/40\n",
      "1768/1768 [==============================] - 1s 548us/step - loss: 0.2345 - acc: 0.8948 - val_loss: 0.2625 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.28766 to 0.26249, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 24/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.2290 - acc: 0.9112 - val_loss: 0.2843 - val_acc: 0.8932\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.26249\n",
      "Epoch 25/40\n",
      "1768/1768 [==============================] - 1s 548us/step - loss: 0.2244 - acc: 0.9078 - val_loss: 0.2533 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.26249 to 0.25333, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 26/40\n",
      "1768/1768 [==============================] - 1s 568us/step - loss: 0.2267 - acc: 0.9089 - val_loss: 0.2305 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.25333 to 0.23048, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 27/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.2288 - acc: 0.9089 - val_loss: 0.2557 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.23048\n",
      "Epoch 28/40\n",
      "1768/1768 [==============================] - 1s 549us/step - loss: 0.2123 - acc: 0.9129 - val_loss: 0.2429 - val_acc: 0.9085\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.23048\n",
      "Epoch 29/40\n",
      "1768/1768 [==============================] - 1s 542us/step - loss: 0.2086 - acc: 0.9101 - val_loss: 0.2794 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.23048\n",
      "Epoch 30/40\n",
      "1768/1768 [==============================] - 1s 547us/step - loss: 0.2238 - acc: 0.9112 - val_loss: 0.2571 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.23048\n",
      "Epoch 31/40\n",
      "1768/1768 [==============================] - 1s 543us/step - loss: 0.2070 - acc: 0.9219 - val_loss: 0.2646 - val_acc: 0.8966\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.23048\n",
      "Epoch 32/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.2036 - acc: 0.9140 - val_loss: 0.2140 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.23048 to 0.21400, saving model to weights.3CL3.NOAUG.hdf5\n",
      "Epoch 33/40\n",
      "1768/1768 [==============================] - 1s 541us/step - loss: 0.2072 - acc: 0.9225 - val_loss: 0.2496 - val_acc: 0.9017\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.21400\n",
      "Epoch 34/40\n",
      "1768/1768 [==============================] - 1s 553us/step - loss: 0.1815 - acc: 0.9202 - val_loss: 0.2968 - val_acc: 0.8831\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.21400\n",
      "Epoch 35/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.1835 - acc: 0.9293 - val_loss: 0.2233 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.21400\n",
      "Epoch 36/40\n",
      "1768/1768 [==============================] - 1s 551us/step - loss: 0.1758 - acc: 0.9304 - val_loss: 0.2246 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.21400\n",
      "Epoch 37/40\n",
      "1768/1768 [==============================] - 1s 544us/step - loss: 0.1996 - acc: 0.9197 - val_loss: 0.2444 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.21400\n",
      "Epoch 38/40\n",
      "1768/1768 [==============================] - 1s 550us/step - loss: 0.1692 - acc: 0.9372 - val_loss: 0.2277 - val_acc: 0.9136\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.21400\n",
      "Epoch 39/40\n",
      "1768/1768 [==============================] - 1s 546us/step - loss: 0.2075 - acc: 0.9146 - val_loss: 0.2690 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.21400\n",
      "Epoch 40/40\n",
      "1768/1768 [==============================] - 1s 550us/step - loss: 0.1865 - acc: 0.9276 - val_loss: 0.2087 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.21400 to 0.20868, saving model to weights.3CL3.NOAUG.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f8d37c978>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.3CL3.NOAUG.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model3.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, val_labels),\n",
    "          epochs=40, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 92.2034%\n"
     ]
    }
   ],
   "source": [
    "model3_pred = [np.argmax(model3.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy3 = 100*np.sum(np.array(model3_pred)==np.argmax(test_labels, axis=1))/len(model3_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no change observed for Model 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.4: Model 4 - Model 2 with 2 extra layers and additional dropout layer.**\n",
    "Instead of having more filters, two more layers were added: dropout tends to work better on larger networks. Also, a dropout layer was applied to the first fully connected layer. This time the model is trained for 100 epochs; it should increase the model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 19, 19, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 3, 3, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 2, 2, 32)          4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 2, 2, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 1, 32)          4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 1, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 29,058\n",
      "Trainable params: 28,674\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "model4.add(Conv2D(32, (2, 2),input_shape=(40,40,3)))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "model4.add(Conv2D(32, (3, 3)))\n",
    "model4.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "model4.add(Conv2D(32, (2, 2)))\n",
    "model4.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Activation('relu'))\n",
    "\n",
    "model4.add(Conv2D(32, (2, 2)))\n",
    "model4.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Activation('relu'))\n",
    " \n",
    "model4.add(GlobalAveragePooling2D())\n",
    "model4.add(Dense(32, activation='relu'))\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1768 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "1768/1768 [==============================] - 3s 2ms/step - loss: 1.0492 - acc: 0.5028 - val_loss: 0.6890 - val_acc: 0.5237\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68900, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 2/50\n",
      "1768/1768 [==============================] - 1s 761us/step - loss: 0.9197 - acc: 0.5096 - val_loss: 0.6922 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.68900\n",
      "Epoch 3/50\n",
      "1768/1768 [==============================] - 1s 764us/step - loss: 0.8669 - acc: 0.5028 - val_loss: 0.6903 - val_acc: 0.5390\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.68900\n",
      "Epoch 4/50\n",
      "1768/1768 [==============================] - 1s 752us/step - loss: 0.7753 - acc: 0.5390 - val_loss: 0.6911 - val_acc: 0.5203\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.68900\n",
      "Epoch 5/50\n",
      "1768/1768 [==============================] - 1s 765us/step - loss: 0.7637 - acc: 0.5057 - val_loss: 0.6910 - val_acc: 0.5068\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.68900\n",
      "Epoch 6/50\n",
      "1768/1768 [==============================] - 1s 762us/step - loss: 0.7346 - acc: 0.5328 - val_loss: 0.6919 - val_acc: 0.5220\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.68900\n",
      "Epoch 7/50\n",
      "1768/1768 [==============================] - 1s 754us/step - loss: 0.7171 - acc: 0.5396 - val_loss: 0.6905 - val_acc: 0.5136\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.68900\n",
      "Epoch 8/50\n",
      "1768/1768 [==============================] - 1s 758us/step - loss: 0.6920 - acc: 0.5588 - val_loss: 0.6897 - val_acc: 0.5542\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.68900\n",
      "Epoch 9/50\n",
      "1768/1768 [==============================] - 1s 758us/step - loss: 0.6814 - acc: 0.5758 - val_loss: 0.6891 - val_acc: 0.5542\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.68900\n",
      "Epoch 10/50\n",
      "1768/1768 [==============================] - 1s 758us/step - loss: 0.6714 - acc: 0.5905 - val_loss: 0.6893 - val_acc: 0.5339\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.68900\n",
      "Epoch 11/50\n",
      "1768/1768 [==============================] - 1s 767us/step - loss: 0.6598 - acc: 0.6131 - val_loss: 0.6891 - val_acc: 0.5136\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.68900\n",
      "Epoch 12/50\n",
      "1768/1768 [==============================] - 1s 767us/step - loss: 0.6588 - acc: 0.6069 - val_loss: 0.6836 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.68900 to 0.68363, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 13/50\n",
      "1768/1768 [==============================] - 1s 757us/step - loss: 0.6419 - acc: 0.6261 - val_loss: 0.6780 - val_acc: 0.5729\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68363 to 0.67797, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 14/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.6306 - acc: 0.6408 - val_loss: 0.6686 - val_acc: 0.6119\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.67797 to 0.66864, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 15/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.6055 - acc: 0.6674 - val_loss: 0.6580 - val_acc: 0.6153\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.66864 to 0.65795, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 16/50\n",
      "1768/1768 [==============================] - 1s 757us/step - loss: 0.5933 - acc: 0.6742 - val_loss: 0.6368 - val_acc: 0.6475\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.65795 to 0.63681, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 17/50\n",
      "1768/1768 [==============================] - 1s 756us/step - loss: 0.5891 - acc: 0.6951 - val_loss: 0.6329 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.63681 to 0.63293, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 18/50\n",
      "1768/1768 [==============================] - 1s 761us/step - loss: 0.5674 - acc: 0.7093 - val_loss: 0.6282 - val_acc: 0.6559\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.63293 to 0.62825, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 19/50\n",
      "1768/1768 [==============================] - 1s 760us/step - loss: 0.5525 - acc: 0.7330 - val_loss: 0.6192 - val_acc: 0.6542\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.62825 to 0.61919, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 20/50\n",
      "1768/1768 [==============================] - 1s 758us/step - loss: 0.5351 - acc: 0.7387 - val_loss: 0.5993 - val_acc: 0.6627\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.61919 to 0.59930, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 21/50\n",
      "1768/1768 [==============================] - 1s 762us/step - loss: 0.5343 - acc: 0.7438 - val_loss: 0.5697 - val_acc: 0.6949\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.59930 to 0.56974, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 22/50\n",
      "1768/1768 [==============================] - 1s 755us/step - loss: 0.5134 - acc: 0.7562 - val_loss: 0.5154 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.56974 to 0.51536, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 23/50\n",
      "1768/1768 [==============================] - 1s 758us/step - loss: 0.4906 - acc: 0.7641 - val_loss: 0.5054 - val_acc: 0.7593\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.51536 to 0.50538, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 24/50\n",
      "1768/1768 [==============================] - 1s 760us/step - loss: 0.4749 - acc: 0.7771 - val_loss: 0.4948 - val_acc: 0.7627\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.50538 to 0.49476, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 25/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.4388 - acc: 0.8015 - val_loss: 0.5325 - val_acc: 0.7424\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.49476\n",
      "Epoch 26/50\n",
      "1768/1768 [==============================] - 1s 755us/step - loss: 0.4664 - acc: 0.7924 - val_loss: 0.4536 - val_acc: 0.8017\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.49476 to 0.45362, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 27/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.4453 - acc: 0.7986 - val_loss: 0.4322 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.45362 to 0.43219, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 28/50\n",
      "1768/1768 [==============================] - 1s 760us/step - loss: 0.4239 - acc: 0.8281 - val_loss: 0.4378 - val_acc: 0.8085\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.43219\n",
      "Epoch 29/50\n",
      "1768/1768 [==============================] - 1s 757us/step - loss: 0.4473 - acc: 0.8060 - val_loss: 0.4208 - val_acc: 0.8136\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.43219 to 0.42083, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 30/50\n",
      "1768/1768 [==============================] - 1s 758us/step - loss: 0.4064 - acc: 0.8314 - val_loss: 0.4135 - val_acc: 0.8254\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.42083 to 0.41352, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 31/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.4254 - acc: 0.8184 - val_loss: 0.4388 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.41352\n",
      "Epoch 32/50\n",
      "1768/1768 [==============================] - 1s 753us/step - loss: 0.3970 - acc: 0.8314 - val_loss: 0.3853 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.41352 to 0.38532, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 33/50\n",
      "1768/1768 [==============================] - 1s 767us/step - loss: 0.4069 - acc: 0.8230 - val_loss: 0.3873 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.38532\n",
      "Epoch 34/50\n",
      "1768/1768 [==============================] - 1s 761us/step - loss: 0.3833 - acc: 0.8416 - val_loss: 0.3576 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.38532 to 0.35762, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 35/50\n",
      "1768/1768 [==============================] - 1s 755us/step - loss: 0.3757 - acc: 0.8422 - val_loss: 0.4096 - val_acc: 0.8322\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.35762\n",
      "Epoch 36/50\n",
      "1768/1768 [==============================] - 1s 760us/step - loss: 0.3774 - acc: 0.8467 - val_loss: 0.3911 - val_acc: 0.8305\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.35762\n",
      "Epoch 37/50\n",
      "1768/1768 [==============================] - 1s 760us/step - loss: 0.3444 - acc: 0.8580 - val_loss: 0.3737 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.35762\n",
      "Epoch 38/50\n",
      "1768/1768 [==============================] - 1s 755us/step - loss: 0.3738 - acc: 0.8422 - val_loss: 0.3521 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.35762 to 0.35213, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 765us/step - loss: 0.3771 - acc: 0.8490 - val_loss: 0.3323 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.35213 to 0.33229, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 40/50\n",
      "1768/1768 [==============================] - 1s 758us/step - loss: 0.3501 - acc: 0.8665 - val_loss: 0.3173 - val_acc: 0.8831\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.33229 to 0.31726, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 41/50\n",
      "1768/1768 [==============================] - 1s 764us/step - loss: 0.3517 - acc: 0.8479 - val_loss: 0.3451 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.31726\n",
      "Epoch 42/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.3282 - acc: 0.8688 - val_loss: 0.3097 - val_acc: 0.8831\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.31726 to 0.30970, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 43/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.3270 - acc: 0.8722 - val_loss: 0.3154 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.30970\n",
      "Epoch 44/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.3511 - acc: 0.8626 - val_loss: 0.3307 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.30970\n",
      "Epoch 45/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.3218 - acc: 0.8722 - val_loss: 0.3240 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.30970\n",
      "Epoch 46/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.3311 - acc: 0.8648 - val_loss: 0.2918 - val_acc: 0.8831\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.30970 to 0.29177, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 47/50\n",
      "1768/1768 [==============================] - 1s 763us/step - loss: 0.3220 - acc: 0.8727 - val_loss: 0.3151 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.29177\n",
      "Epoch 48/50\n",
      "1768/1768 [==============================] - 1s 758us/step - loss: 0.2940 - acc: 0.8852 - val_loss: 0.2843 - val_acc: 0.8915\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.29177 to 0.28431, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 49/50\n",
      "1768/1768 [==============================] - 1s 762us/step - loss: 0.3213 - acc: 0.8778 - val_loss: 0.2682 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.28431 to 0.26823, saving model to weights.4CL3.NOAUG.hdf5\n",
      "Epoch 50/50\n",
      "1768/1768 [==============================] - 1s 759us/step - loss: 0.3181 - acc: 0.8693 - val_loss: 0.2876 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.26823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1fc00fb048>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.4CL3.NOAUG.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model4.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, val_labels),\n",
    "          epochs=50, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 90.3390%\n"
     ]
    }
   ],
   "source": [
    "model4_pred = [np.argmax(model4.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy4 = 100*np.sum(np.array(model4_pred)==np.argmax(test_labels, axis=1))/len(model4_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, Model 4 achieved the worst accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3: Testing different CNN architectures on augmented data.\n",
    "** Step 3.1: Model 1 with augmented data.** <br>\n",
    "The best model is the first model we trained; the modifications that were applied did not improve the performance. Now we will test if the first model will perform better if we use\n",
    "augmented data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 37, 37, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 84,513\n",
      "Trainable params: 84,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_AUG = Sequential()\n",
    "\n",
    "model_AUG.add(Conv2D(32, (2, 2), activation='relu', input_shape=(40,40,3)))\n",
    "model_AUG.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_AUG.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_AUG.add(Dropout(0.4))\n",
    "model_AUG.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_AUG.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_AUG.add(Dropout(0.4))\n",
    " \n",
    "model_AUG.add(Flatten())\n",
    "model_AUG.add(Dense(32, activation='relu'))\n",
    "model_AUG.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model_AUG.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_AUG.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 7.8714 - acc: 0.5063 - val_loss: 7.7814 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.78140, saving model to weights.3CL.AUG.hdf5\n",
      "Epoch 2/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9115 - acc: 0.5037 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.78140 to 7.75144, saving model to weights.3CL.AUG.hdf5\n",
      "Epoch 3/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7818 - acc: 0.5119 - val_loss: 7.7414 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.75144 to 7.74145, saving model to weights.3CL.AUG.hdf5\n",
      "Epoch 4/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7719 - acc: 0.5125 - val_loss: 7.8813 - val_acc: 0.5056\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 7.74145\n",
      "Epoch 5/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9314 - acc: 0.5025 - val_loss: 7.7015 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.74145 to 7.70149, saving model to weights.3CL.AUG.hdf5\n",
      "Epoch 6/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9610 - acc: 0.5006 - val_loss: 7.8813 - val_acc: 0.5056\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7.70149\n",
      "Epoch 7/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0111 - acc: 0.4975 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 7.70149\n",
      "Epoch 8/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7619 - acc: 0.5131 - val_loss: 7.7414 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7.70149\n",
      "Epoch 9/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7718 - acc: 0.5125 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.70149\n",
      "Epoch 10/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9013 - acc: 0.5044 - val_loss: 7.8613 - val_acc: 0.5069\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7.70149\n",
      "Epoch 11/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7618 - acc: 0.5131 - val_loss: 7.7814 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 7.70149\n",
      "Epoch 12/80\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 7.9713 - acc: 0.5000 - val_loss: 7.7814 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 7.70149\n",
      "Epoch 13/80\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 7.8117 - acc: 0.5100 - val_loss: 7.7315 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 7.70149\n",
      "Epoch 14/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8716 - acc: 0.5062 - val_loss: 7.6615 - val_acc: 0.5194\n",
      "\n",
      "Epoch 00014: val_loss improved from 7.70149 to 7.66153, saving model to weights.3CL.AUG.hdf5\n",
      "Epoch 15/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7219 - acc: 0.5156 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 7.66153\n",
      "Epoch 16/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.1008 - acc: 0.4919 - val_loss: 7.8313 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 7.66153\n",
      "Epoch 17/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9413 - acc: 0.5019 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 7.66153\n",
      "Epoch 18/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7322 - acc: 0.5150 - val_loss: 7.6515 - val_acc: 0.5201\n",
      "\n",
      "Epoch 00018: val_loss improved from 7.66153 to 7.65155, saving model to weights.3CL.AUG.hdf5\n",
      "Epoch 19/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8817 - acc: 0.5056 - val_loss: 7.8413 - val_acc: 0.5081\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 7.65155\n",
      "Epoch 20/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8117 - acc: 0.5100 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 7.65155\n",
      "Epoch 21/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8913 - acc: 0.5050 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 7.65155\n",
      "Epoch 22/80\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 7.9510 - acc: 0.5013 - val_loss: 7.8913 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 7.65155\n",
      "Epoch 23/80\n",
      "100/100 [==============================] - 2s 25ms/step - loss: 7.6922 - acc: 0.5175 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 7.65155\n",
      "Epoch 24/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9212 - acc: 0.5031 - val_loss: 7.7814 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 7.65155\n",
      "Epoch 25/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0210 - acc: 0.4969 - val_loss: 7.6515 - val_acc: 0.5201\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 7.65155\n",
      "Epoch 26/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8317 - acc: 0.5088 - val_loss: 7.7814 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 7.65155\n",
      "Epoch 27/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.6622 - acc: 0.5194 - val_loss: 7.6915 - val_acc: 0.5175\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 7.65155\n",
      "Epoch 28/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9612 - acc: 0.5006 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 7.65155\n",
      "Epoch 29/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9016 - acc: 0.5044 - val_loss: 7.7315 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 7.65155\n",
      "Epoch 30/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8714 - acc: 0.5063 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 7.65155\n",
      "Epoch 31/80\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7.8716 - acc: 0.5062 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 7.65155\n",
      "Epoch 32/80\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 7.7321 - acc: 0.5150 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 7.65155\n",
      "Epoch 33/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9815 - acc: 0.4994 - val_loss: 7.7015 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 7.65155\n",
      "Epoch 34/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8217 - acc: 0.5094 - val_loss: 7.8813 - val_acc: 0.5056\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 7.65155\n",
      "Epoch 35/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9612 - acc: 0.5006 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 7.65155\n",
      "Epoch 36/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.6425 - acc: 0.5206 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 7.65155\n",
      "Epoch 37/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0310 - acc: 0.4962 - val_loss: 7.8313 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 7.65155\n",
      "Epoch 38/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.6923 - acc: 0.5175 - val_loss: 7.6815 - val_acc: 0.5182\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 7.65155\n",
      "Epoch 39/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0609 - acc: 0.4944 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 7.65155\n",
      "Epoch 40/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8416 - acc: 0.5081 - val_loss: 7.8413 - val_acc: 0.5081\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 7.65155\n",
      "Epoch 41/80\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7.7618 - acc: 0.5131 - val_loss: 7.7414 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 7.65155\n",
      "Epoch 42/80\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 7.9512 - acc: 0.5013 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 7.65155\n",
      "Epoch 43/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8516 - acc: 0.5075 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 7.65155\n",
      "Epoch 44/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7221 - acc: 0.5156 - val_loss: 7.8214 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 7.65155\n",
      "Epoch 45/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.1008 - acc: 0.4919 - val_loss: 7.8613 - val_acc: 0.5069\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 7.65155\n",
      "Epoch 46/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7519 - acc: 0.5138 - val_loss: 7.8313 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 7.65155\n",
      "Epoch 47/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8217 - acc: 0.5094 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 7.65155\n",
      "Epoch 48/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0410 - acc: 0.4956 - val_loss: 7.8313 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 7.65155\n",
      "Epoch 49/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.6922 - acc: 0.5175 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 7.65155\n",
      "Epoch 50/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9611 - acc: 0.5006 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 7.65155\n",
      "Epoch 51/80\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7.8215 - acc: 0.5094 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 7.65155\n",
      "Epoch 52/80\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 7.9612 - acc: 0.5006 - val_loss: 7.8613 - val_acc: 0.5069\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 7.65155\n",
      "Epoch 53/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7521 - acc: 0.5137 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 7.65155\n",
      "Epoch 54/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9314 - acc: 0.5025 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 7.65155\n",
      "Epoch 55/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7719 - acc: 0.5125 - val_loss: 7.7315 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 7.65155\n",
      "Epoch 56/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9811 - acc: 0.4994 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 7.65155\n",
      "Epoch 57/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7420 - acc: 0.5144 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 7.65155\n",
      "Epoch 58/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9311 - acc: 0.5025 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 7.65155\n",
      "Epoch 59/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8018 - acc: 0.5106 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 7.65155\n",
      "Epoch 60/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9512 - acc: 0.5013 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 7.65155\n",
      "Epoch 61/80\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7.8618 - acc: 0.5069 - val_loss: 7.6615 - val_acc: 0.5194\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 7.65155\n",
      "Epoch 62/80\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 7.8614 - acc: 0.5069 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 7.65155\n",
      "Epoch 63/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7918 - acc: 0.5112 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 7.65155\n",
      "Epoch 64/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9313 - acc: 0.5025 - val_loss: 7.8413 - val_acc: 0.5081\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 7.65155\n",
      "Epoch 65/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0013 - acc: 0.4981 - val_loss: 7.9612 - val_acc: 0.5006\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 7.65155\n",
      "Epoch 66/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.6025 - acc: 0.5231 - val_loss: 7.8713 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 7.65155\n",
      "Epoch 67/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0509 - acc: 0.4950 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 7.65155\n",
      "Epoch 68/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.6824 - acc: 0.5181 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 7.65155\n",
      "Epoch 69/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.9611 - acc: 0.5006 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 7.65155\n",
      "Epoch 70/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8418 - acc: 0.5081 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 7.65155\n",
      "Epoch 71/80\n",
      "100/100 [==============================] - 2s 23ms/step - loss: 7.9013 - acc: 0.5044 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 7.65155\n",
      "Epoch 72/80\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 7.7220 - acc: 0.5156 - val_loss: 7.9013 - val_acc: 0.5044\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 7.65155\n",
      "Epoch 73/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7520 - acc: 0.5138 - val_loss: 7.6515 - val_acc: 0.5201\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 7.65155\n",
      "Epoch 74/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.1804 - acc: 0.4869 - val_loss: 7.7115 - val_acc: 0.5163\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 7.65155\n",
      "Epoch 75/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.6324 - acc: 0.5213 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 7.65155\n",
      "Epoch 76/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0210 - acc: 0.4969 - val_loss: 7.9013 - val_acc: 0.5044\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 7.65155\n",
      "Epoch 77/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0011 - acc: 0.4981 - val_loss: 7.9212 - val_acc: 0.5031\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 7.65155\n",
      "Epoch 78/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7718 - acc: 0.5125 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 7.65155\n",
      "Epoch 79/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8815 - acc: 0.5056 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 7.65155\n",
      "Epoch 80/80\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.8815 - acc: 0.5056 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 7.65155\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.3CL.AUG.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history=model_AUG.fit_generator(train_generator, steps_per_epoch=100, epochs=80,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=100, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 50.0000%\n"
     ]
    }
   ],
   "source": [
    "modelAUG_pred = [np.argmax(model_AUG.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy_AUG = 100*np.sum(np.array(modelAUG_pred)==np.argmax(test_labels, axis=1))/len(modelAUG_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy_AUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training history\n",
    "#accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtained very poor accuracy of 50% meaning that the model with augmented data is no better than random chance.\n",
    "However, after further analysis it actually makes sense. If we apply augmentation to CT scan data, it can potentially change the labeling.\n",
    "Anyway, we will try to add some modifications to our model to see if we can improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**STEP 3.2: Model 2 - Model 1 with more layers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 37, 37, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 3, 3, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 1, 1, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1, 1, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 39,009\n",
      "Trainable params: 38,753\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_AUG2 = Sequential()\n",
    "\n",
    "model_AUG2.add(Conv2D(32, (2, 2), activation='relu', input_shape=(40,40,3)))\n",
    "\n",
    "model_AUG2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_AUG2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_AUG2.add(BatchNormalization())\n",
    "model_AUG2.add(Dropout(0.4))\n",
    "\n",
    "model_AUG2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_AUG2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_AUG2.add(BatchNormalization())\n",
    "model_AUG2.add(Dropout(0.4))\n",
    "\n",
    "model_AUG2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_AUG2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_AUG2.add(BatchNormalization())\n",
    "model_AUG2.add(Dropout(0.4))\n",
    "\n",
    "model_AUG2.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_AUG2.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model_AUG2.add(BatchNormalization())\n",
    "model_AUG2.add(Dropout(0.4))\n",
    "    \n",
    "model_AUG2.add(GlobalAveragePooling2D())\n",
    "model_AUG2.add(Dense(32, activation='relu'))\n",
    "model_AUG2.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model_AUG2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_AUG2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 4s 47ms/step - loss: 7.7218 - acc: 0.5156 - val_loss: 7.8413 - val_acc: 0.5081\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.84134, saving model to weights.3CL.AUG2.hdf5\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.9587 - acc: 0.5008 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 7.84134\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8465 - acc: 0.5078 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.84134 to 7.79139, saving model to weights.3CL.AUG2.hdf5\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.9467 - acc: 0.5015 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00004: val_loss improved from 7.79139 to 7.77141, saving model to weights.3CL.AUG2.hdf5\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.8715 - acc: 0.5063 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00005: val_loss improved from 7.77141 to 7.75144, saving model to weights.3CL.AUG2.hdf5\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8217 - acc: 0.5094 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 7.75144\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9586 - acc: 0.5008 - val_loss: 7.7315 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.75144 to 7.73146, saving model to weights.3CL.AUG2.hdf5\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8712 - acc: 0.5063 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 7.73146\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.7471 - acc: 0.5141 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 7.73146\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 8.0335 - acc: 0.4961 - val_loss: 7.6715 - val_acc: 0.5188\n",
      "\n",
      "Epoch 00010: val_loss improved from 7.73146 to 7.67152, saving model to weights.3CL.AUG2.hdf5\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7719 - acc: 0.5125 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 7.67152\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.9461 - acc: 0.5016 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 7.67152\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.9961 - acc: 0.4984 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 7.67152\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7345 - acc: 0.5148 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 7.67152\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8592 - acc: 0.5070 - val_loss: 7.7414 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 7.67152\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.9836 - acc: 0.4992 - val_loss: 7.7814 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 7.67152\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.6349 - acc: 0.5211 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 7.67152\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 7.9089 - acc: 0.5039 - val_loss: 7.7814 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 7.67152\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 7.7842 - acc: 0.5117 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 7.67152\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8345 - acc: 0.5086 - val_loss: 7.8913 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 7.67152\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8217 - acc: 0.5094 - val_loss: 7.6615 - val_acc: 0.5194\n",
      "\n",
      "Epoch 00021: val_loss improved from 7.67152 to 7.66153, saving model to weights.3CL.AUG2.hdf5\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8339 - acc: 0.5086 - val_loss: 7.9013 - val_acc: 0.5044\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 7.66153\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.8219 - acc: 0.5094 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 7.66153\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 8.0833 - acc: 0.4930 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 7.66153\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8213 - acc: 0.5094 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 7.66153\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8840 - acc: 0.5055 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 7.66153\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 8.0456 - acc: 0.4953 - val_loss: 7.6715 - val_acc: 0.5188\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 7.66153\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.6475 - acc: 0.5203 - val_loss: 7.6815 - val_acc: 0.5182\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 7.66153\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9836 - acc: 0.4992 - val_loss: 7.8214 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 7.66153\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.8466 - acc: 0.5078 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 7.66153\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7224 - acc: 0.5156 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 7.66153\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 8.0957 - acc: 0.4922 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 7.66153\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 8.0579 - acc: 0.4946 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 7.66153\n",
      "Epoch 34/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.5104 - acc: 0.5289 - val_loss: 7.8613 - val_acc: 0.5069\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 7.66153\n",
      "Epoch 35/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9838 - acc: 0.4992 - val_loss: 7.7015 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 7.66153\n",
      "Epoch 36/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7468 - acc: 0.5141 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 7.66153\n",
      "Epoch 37/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.8966 - acc: 0.5047 - val_loss: 7.7015 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 7.66153\n",
      "Epoch 38/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8091 - acc: 0.5102 - val_loss: 7.8413 - val_acc: 0.5081\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 7.66153\n",
      "Epoch 39/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 8.0335 - acc: 0.4961 - val_loss: 7.8214 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 7.66153\n",
      "Epoch 40/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7844 - acc: 0.5117 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 7.66153\n",
      "Epoch 41/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.8466 - acc: 0.5078 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 7.66153\n",
      "Epoch 42/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.7474 - acc: 0.5140 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 7.66153\n",
      "Epoch 43/100\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 7.8842 - acc: 0.5055 - val_loss: 7.8413 - val_acc: 0.5081\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 7.66153\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 2s 30ms/step - loss: 7.7468 - acc: 0.5141 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 7.66153\n",
      "Epoch 45/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 8.2452 - acc: 0.4828 - val_loss: 7.6715 - val_acc: 0.5188\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 7.66153\n",
      "Epoch 46/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7842 - acc: 0.5117 - val_loss: 7.8413 - val_acc: 0.5081\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 7.66153\n",
      "Epoch 47/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.6601 - acc: 0.5195 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 7.66153\n",
      "Epoch 48/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.8965 - acc: 0.5047 - val_loss: 7.7914 - val_acc: 0.5113\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 7.66153\n",
      "Epoch 49/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7965 - acc: 0.5110 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 7.66153\n",
      "Epoch 50/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8965 - acc: 0.5047 - val_loss: 7.7414 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 7.66153\n",
      "Epoch 51/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8468 - acc: 0.5078 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 7.66153\n",
      "Epoch 52/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 8.1079 - acc: 0.4914 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 7.66153\n",
      "Epoch 53/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7968 - acc: 0.5109 - val_loss: 7.8214 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 7.66153\n",
      "Epoch 54/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 8.0086 - acc: 0.4977 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 7.66153\n",
      "Epoch 55/100\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 7.7221 - acc: 0.5156 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 7.66153\n",
      "Epoch 56/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.6718 - acc: 0.5188 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 7.66153\n",
      "Epoch 57/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 8.0210 - acc: 0.4969 - val_loss: 7.8713 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 7.66153\n",
      "Epoch 58/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8343 - acc: 0.5086 - val_loss: 7.6815 - val_acc: 0.5182\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 7.66153\n",
      "Epoch 59/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.7470 - acc: 0.5141 - val_loss: 7.7115 - val_acc: 0.5163\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 7.66153\n",
      "Epoch 60/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 8.0835 - acc: 0.4930 - val_loss: 7.8214 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 7.66153\n",
      "Epoch 61/100\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 7.7595 - acc: 0.5133 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 7.66153\n",
      "Epoch 62/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.8346 - acc: 0.5086 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 7.66153\n",
      "Epoch 63/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.9959 - acc: 0.4984 - val_loss: 7.8313 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 7.66153\n",
      "Epoch 64/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.7345 - acc: 0.5148 - val_loss: 7.7015 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 7.66153\n",
      "Epoch 65/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9958 - acc: 0.4985 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 7.66153\n",
      "Epoch 66/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.7098 - acc: 0.5164 - val_loss: 7.8913 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 7.66153\n",
      "Epoch 67/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9587 - acc: 0.5008 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 7.66153\n",
      "Epoch 68/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8217 - acc: 0.5094 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 7.66153\n",
      "Epoch 69/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9217 - acc: 0.5031 - val_loss: 7.8214 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 7.66153\n",
      "Epoch 70/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8965 - acc: 0.5047 - val_loss: 7.6915 - val_acc: 0.5175\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 7.66153\n",
      "Epoch 71/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7096 - acc: 0.5164 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 7.66153\n",
      "Epoch 72/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9340 - acc: 0.5023 - val_loss: 7.8313 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 7.66153\n",
      "Epoch 73/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 8.0084 - acc: 0.4977 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 7.66153\n",
      "Epoch 74/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.7595 - acc: 0.5133 - val_loss: 7.7015 - val_acc: 0.5169\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 7.66153\n",
      "Epoch 75/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7222 - acc: 0.5156 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 7.66153\n",
      "Epoch 76/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.8714 - acc: 0.5063 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 7.66153\n",
      "Epoch 77/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 8.0086 - acc: 0.4977 - val_loss: 7.8313 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 7.66153\n",
      "Epoch 78/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.6975 - acc: 0.5172 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 7.66153\n",
      "Epoch 79/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 8.0086 - acc: 0.4977 - val_loss: 7.7614 - val_acc: 0.5132\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 7.66153\n",
      "Epoch 80/100\n",
      "80/80 [==============================] - 2s 30ms/step - loss: 7.7719 - acc: 0.5125 - val_loss: 7.8214 - val_acc: 0.5094\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 7.66153\n",
      "Epoch 81/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.7970 - acc: 0.5109 - val_loss: 7.7215 - val_acc: 0.5157\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 7.66153\n",
      "Epoch 82/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7721 - acc: 0.5125 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 7.66153\n",
      "Epoch 83/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8094 - acc: 0.5101 - val_loss: 7.7414 - val_acc: 0.5144\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 7.66153\n",
      "Epoch 84/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.9836 - acc: 0.4992 - val_loss: 7.8313 - val_acc: 0.5088\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 7.66153\n",
      "Epoch 85/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7468 - acc: 0.5141 - val_loss: 7.8513 - val_acc: 0.5075\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 7.66153\n",
      "Epoch 86/100\n",
      "80/80 [==============================] - 2s 26ms/step - loss: 8.0333 - acc: 0.4961 - val_loss: 7.8713 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 7.66153\n",
      "Epoch 87/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 8.0336 - acc: 0.4961 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 7.66153\n",
      "Epoch 88/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.6225 - acc: 0.5219 - val_loss: 7.8713 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 7.66153\n",
      "Epoch 89/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.9586 - acc: 0.5008 - val_loss: 7.8913 - val_acc: 0.5050\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 7.66153\n",
      "Epoch 90/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9209 - acc: 0.5032 - val_loss: 7.7814 - val_acc: 0.5119\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 7.66153\n",
      "Epoch 91/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.6598 - acc: 0.5195 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 7.66153\n",
      "Epoch 92/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 8.0958 - acc: 0.4922 - val_loss: 7.8713 - val_acc: 0.5063\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 7.66153\n",
      "Epoch 93/100\n",
      "80/80 [==============================] - 2s 28ms/step - loss: 7.7224 - acc: 0.5156 - val_loss: 7.6915 - val_acc: 0.5175\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 7.66153\n",
      "Epoch 94/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7098 - acc: 0.5164 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 7.66153\n",
      "Epoch 95/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 8.0087 - acc: 0.4976 - val_loss: 7.8114 - val_acc: 0.5100\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 7.66153\n",
      "Epoch 96/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.9836 - acc: 0.4992 - val_loss: 7.7514 - val_acc: 0.5138\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 7.66153\n",
      "Epoch 97/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.7844 - acc: 0.5117 - val_loss: 7.8413 - val_acc: 0.5081\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 7.66153\n",
      "Epoch 98/100\n",
      "80/80 [==============================] - 2s 29ms/step - loss: 7.9587 - acc: 0.5008 - val_loss: 7.7115 - val_acc: 0.5163\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 7.66153\n",
      "Epoch 99/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8096 - acc: 0.5101 - val_loss: 7.7714 - val_acc: 0.5125\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 7.66153\n",
      "Epoch 100/100\n",
      "80/80 [==============================] - 2s 27ms/step - loss: 7.8466 - acc: 0.5078 - val_loss: 7.8014 - val_acc: 0.5107\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 7.66153\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.3CL.AUG2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history2=model_AUG2.fit_generator(train_generator, steps_per_epoch=80, epochs=100,\n",
    "          validation_data=validation_generator,\n",
    "          validation_steps=100, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 50.0000%\n"
     ]
    }
   ],
   "source": [
    "modelAUG2_pred = [np.argmax(model_AUG2.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy_AUG2 = 100*np.sum(np.array(modelAUG2_pred)==np.argmax(test_labels, axis=1))/len(modelAUG2_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy_AUG2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance with augmented data is much worse. Therefore, we will go back to the first model we trained and try to improve the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 4: Improving Model 1 performance with non-augmented data.\n",
    "**Step 4.1: Model 5 - Model 1 with Global Average Pooling layer.**\n",
    "\n",
    "This time the change will be made step by step to see the separate effect of each modification.\n",
    "First, let's see if replacing Flatting layer with Global Average pooling improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 37, 37, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 20,034\n",
      "Trainable params: 20,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "\n",
    "model5.add(Conv2D(32, (2, 2), activation='relu', input_shape=(40,40,3)))\n",
    "\n",
    "model5.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model5.add(Dropout(0.4))\n",
    "\n",
    "model5.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model5.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model5.add(Dropout(0.4))\n",
    " \n",
    "model5.add(GlobalAveragePooling2D())\n",
    "model5.add(Dense(32, activation='relu'))\n",
    "model5.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1768 samples, validate on 590 samples\n",
      "Epoch 1/50\n",
      "1768/1768 [==============================] - 2s 867us/step - loss: 0.6832 - acc: 0.5226 - val_loss: 0.6696 - val_acc: 0.5627\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66956, saving model to weights.5CL.hdf5\n",
      "Epoch 2/50\n",
      "1768/1768 [==============================] - 1s 426us/step - loss: 0.6421 - acc: 0.6267 - val_loss: 0.6341 - val_acc: 0.6373\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66956 to 0.63412, saving model to weights.5CL.hdf5\n",
      "Epoch 3/50\n",
      "1768/1768 [==============================] - 1s 429us/step - loss: 0.6162 - acc: 0.6623 - val_loss: 0.6455 - val_acc: 0.6661\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.63412\n",
      "Epoch 4/50\n",
      "1768/1768 [==============================] - 1s 435us/step - loss: 0.5886 - acc: 0.7002 - val_loss: 0.5957 - val_acc: 0.6831\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63412 to 0.59566, saving model to weights.5CL.hdf5\n",
      "Epoch 5/50\n",
      "1768/1768 [==============================] - 1s 430us/step - loss: 0.5610 - acc: 0.7240 - val_loss: 0.5819 - val_acc: 0.6847\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59566 to 0.58188, saving model to weights.5CL.hdf5\n",
      "Epoch 6/50\n",
      "1768/1768 [==============================] - 1s 423us/step - loss: 0.5537 - acc: 0.7189 - val_loss: 0.5449 - val_acc: 0.7356\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.58188 to 0.54493, saving model to weights.5CL.hdf5\n",
      "Epoch 7/50\n",
      "1768/1768 [==============================] - 1s 435us/step - loss: 0.5267 - acc: 0.7336 - val_loss: 0.5432 - val_acc: 0.7542\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.54493 to 0.54322, saving model to weights.5CL.hdf5\n",
      "Epoch 8/50\n",
      "1768/1768 [==============================] - 1s 429us/step - loss: 0.5258 - acc: 0.7421 - val_loss: 0.5228 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.54322 to 0.52280, saving model to weights.5CL.hdf5\n",
      "Epoch 9/50\n",
      "1768/1768 [==============================] - 1s 428us/step - loss: 0.5009 - acc: 0.7528 - val_loss: 0.5261 - val_acc: 0.7508\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.52280\n",
      "Epoch 10/50\n",
      "1768/1768 [==============================] - 1s 430us/step - loss: 0.5054 - acc: 0.7540 - val_loss: 0.5015 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.52280 to 0.50151, saving model to weights.5CL.hdf5\n",
      "Epoch 11/50\n",
      "1768/1768 [==============================] - 1s 422us/step - loss: 0.4879 - acc: 0.7590 - val_loss: 0.5080 - val_acc: 0.7593\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.50151\n",
      "Epoch 12/50\n",
      "1768/1768 [==============================] - 1s 431us/step - loss: 0.4723 - acc: 0.7755 - val_loss: 0.5035 - val_acc: 0.7881\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.50151\n",
      "Epoch 13/50\n",
      "1768/1768 [==============================] - 1s 433us/step - loss: 0.4644 - acc: 0.7845 - val_loss: 0.4949 - val_acc: 0.7780\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.50151 to 0.49486, saving model to weights.5CL.hdf5\n",
      "Epoch 14/50\n",
      "1768/1768 [==============================] - 1s 427us/step - loss: 0.4508 - acc: 0.7986 - val_loss: 0.4701 - val_acc: 0.8017\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.49486 to 0.47013, saving model to weights.5CL.hdf5\n",
      "Epoch 15/50\n",
      "1768/1768 [==============================] - 1s 425us/step - loss: 0.4416 - acc: 0.7998 - val_loss: 0.4613 - val_acc: 0.8017\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.47013 to 0.46126, saving model to weights.5CL.hdf5\n",
      "Epoch 16/50\n",
      "1768/1768 [==============================] - 1s 431us/step - loss: 0.4348 - acc: 0.7907 - val_loss: 0.4591 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.46126 to 0.45908, saving model to weights.5CL.hdf5\n",
      "Epoch 17/50\n",
      "1768/1768 [==============================] - 1s 428us/step - loss: 0.4198 - acc: 0.8003 - val_loss: 0.4747 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.45908\n",
      "Epoch 18/50\n",
      "1768/1768 [==============================] - 1s 432us/step - loss: 0.4275 - acc: 0.7936 - val_loss: 0.4706 - val_acc: 0.8136\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.45908\n",
      "Epoch 19/50\n",
      "1768/1768 [==============================] - 1s 429us/step - loss: 0.4157 - acc: 0.8235 - val_loss: 0.4349 - val_acc: 0.8153\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.45908 to 0.43490, saving model to weights.5CL.hdf5\n",
      "Epoch 20/50\n",
      "1768/1768 [==============================] - 1s 425us/step - loss: 0.4120 - acc: 0.8179 - val_loss: 0.4260 - val_acc: 0.8136\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.43490 to 0.42602, saving model to weights.5CL.hdf5\n",
      "Epoch 21/50\n",
      "1768/1768 [==============================] - 1s 430us/step - loss: 0.4009 - acc: 0.8133 - val_loss: 0.4267 - val_acc: 0.8136\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.42602\n",
      "Epoch 22/50\n",
      "1768/1768 [==============================] - 1s 429us/step - loss: 0.3897 - acc: 0.8264 - val_loss: 0.4283 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.42602\n",
      "Epoch 23/50\n",
      "1768/1768 [==============================] - 1s 426us/step - loss: 0.3896 - acc: 0.8139 - val_loss: 0.4133 - val_acc: 0.8390\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.42602 to 0.41328, saving model to weights.5CL.hdf5\n",
      "Epoch 24/50\n",
      "1768/1768 [==============================] - 1s 427us/step - loss: 0.3735 - acc: 0.8348 - val_loss: 0.4245 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.41328\n",
      "Epoch 25/50\n",
      "1768/1768 [==============================] - 1s 431us/step - loss: 0.3705 - acc: 0.8309 - val_loss: 0.3930 - val_acc: 0.8271\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.41328 to 0.39298, saving model to weights.5CL.hdf5\n",
      "Epoch 26/50\n",
      "1768/1768 [==============================] - 1s 427us/step - loss: 0.3682 - acc: 0.8258 - val_loss: 0.4204 - val_acc: 0.8102\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.39298\n",
      "Epoch 27/50\n",
      "1768/1768 [==============================] - 1s 429us/step - loss: 0.3707 - acc: 0.8354 - val_loss: 0.3940 - val_acc: 0.8153\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.39298\n",
      "Epoch 28/50\n",
      "1768/1768 [==============================] - 1s 425us/step - loss: 0.3705 - acc: 0.8241 - val_loss: 0.3984 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.39298\n",
      "Epoch 29/50\n",
      "1768/1768 [==============================] - 1s 431us/step - loss: 0.3627 - acc: 0.8230 - val_loss: 0.4133 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.39298\n",
      "Epoch 30/50\n",
      "1768/1768 [==============================] - 1s 430us/step - loss: 0.3554 - acc: 0.8326 - val_loss: 0.4087 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.39298\n",
      "Epoch 31/50\n",
      "1768/1768 [==============================] - 1s 429us/step - loss: 0.3553 - acc: 0.8354 - val_loss: 0.3901 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.39298 to 0.39010, saving model to weights.5CL.hdf5\n",
      "Epoch 32/50\n",
      "1768/1768 [==============================] - 1s 428us/step - loss: 0.3449 - acc: 0.8411 - val_loss: 0.3759 - val_acc: 0.8271\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.39010 to 0.37593, saving model to weights.5CL.hdf5\n",
      "Epoch 33/50\n",
      "1768/1768 [==============================] - 1s 426us/step - loss: 0.3491 - acc: 0.8495 - val_loss: 0.3983 - val_acc: 0.8153\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.37593\n",
      "Epoch 34/50\n",
      "1768/1768 [==============================] - 1s 428us/step - loss: 0.3389 - acc: 0.8473 - val_loss: 0.3934 - val_acc: 0.8169\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.37593\n",
      "Epoch 35/50\n",
      "1768/1768 [==============================] - 1s 438us/step - loss: 0.3426 - acc: 0.8439 - val_loss: 0.3675 - val_acc: 0.8373\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.37593 to 0.36750, saving model to weights.5CL.hdf5\n",
      "Epoch 36/50\n",
      "1768/1768 [==============================] - 1s 427us/step - loss: 0.3341 - acc: 0.8524 - val_loss: 0.3605 - val_acc: 0.8373\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.36750 to 0.36052, saving model to weights.5CL.hdf5\n",
      "Epoch 37/50\n",
      "1768/1768 [==============================] - 1s 424us/step - loss: 0.3366 - acc: 0.8518 - val_loss: 0.3646 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.36052\n",
      "Epoch 38/50\n",
      "1768/1768 [==============================] - 1s 430us/step - loss: 0.3306 - acc: 0.8456 - val_loss: 0.3572 - val_acc: 0.8441\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.36052 to 0.35719, saving model to weights.5CL.hdf5\n",
      "Epoch 39/50\n",
      "1768/1768 [==============================] - 1s 429us/step - loss: 0.3120 - acc: 0.8609 - val_loss: 0.3474 - val_acc: 0.8492\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.35719 to 0.34742, saving model to weights.5CL.hdf5\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 425us/step - loss: 0.3229 - acc: 0.8575 - val_loss: 0.3572 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.34742\n",
      "Epoch 41/50\n",
      "1768/1768 [==============================] - 1s 428us/step - loss: 0.3195 - acc: 0.8597 - val_loss: 0.3766 - val_acc: 0.8356\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34742\n",
      "Epoch 42/50\n",
      "1768/1768 [==============================] - 1s 424us/step - loss: 0.3164 - acc: 0.8569 - val_loss: 0.3686 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.34742\n",
      "Epoch 43/50\n",
      "1768/1768 [==============================] - 1s 433us/step - loss: 0.3244 - acc: 0.8569 - val_loss: 0.3566 - val_acc: 0.8458\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34742\n",
      "Epoch 44/50\n",
      "1768/1768 [==============================] - 1s 426us/step - loss: 0.3146 - acc: 0.8614 - val_loss: 0.3593 - val_acc: 0.8508\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34742\n",
      "Epoch 45/50\n",
      "1768/1768 [==============================] - 1s 430us/step - loss: 0.3210 - acc: 0.8529 - val_loss: 0.3529 - val_acc: 0.8441\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34742\n",
      "Epoch 46/50\n",
      "1768/1768 [==============================] - 1s 430us/step - loss: 0.3077 - acc: 0.8592 - val_loss: 0.3527 - val_acc: 0.8492\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34742\n",
      "Epoch 47/50\n",
      "1768/1768 [==============================] - 1s 427us/step - loss: 0.3139 - acc: 0.8580 - val_loss: 0.3407 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.34742 to 0.34066, saving model to weights.5CL.hdf5\n",
      "Epoch 48/50\n",
      "1768/1768 [==============================] - 1s 427us/step - loss: 0.2996 - acc: 0.8733 - val_loss: 0.3374 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.34066 to 0.33736, saving model to weights.5CL.hdf5\n",
      "Epoch 49/50\n",
      "1768/1768 [==============================] - 1s 434us/step - loss: 0.2982 - acc: 0.8733 - val_loss: 0.3385 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33736\n",
      "Epoch 50/50\n",
      "1768/1768 [==============================] - 1s 424us/step - loss: 0.2896 - acc: 0.8688 - val_loss: 0.3310 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.33736 to 0.33099, saving model to weights.5CL.hdf5\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.5CL.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history5=model5.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, val_labels),\n",
    "          epochs=50, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 83.3898%\n"
     ]
    }
   ],
   "source": [
    "model5_pred = [np.argmax(model5.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy_model5 = 100*np.sum(np.array(model5_pred)==np.argmax(test_labels, axis=1))/len(model5_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy_model5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten layer works better than Global Average Pooling Layer, therefore we will go back to Flatten layer and try batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Step 4.2: Model 6 - Model 1 with batch normalization. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 37, 37, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 84,802\n",
      "Trainable params: 84,674\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "\n",
    "model6.add(Conv2D(32, (2, 2), activation='relu', input_shape=(40,40,3)))\n",
    "\n",
    "model6.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(Dropout(0.4))\n",
    "\n",
    "model6.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model6.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model6.add(BatchNormalization())\n",
    "model6.add(Dropout(0.4))\n",
    " \n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(32, activation='relu'))\n",
    "model6.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1768 samples, validate on 590 samples\n",
      "Epoch 1/80\n",
      "1768/1768 [==============================] - 2s 1ms/step - loss: 0.4834 - acc: 0.8094 - val_loss: 0.3528 - val_acc: 0.8576\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.35278, saving model to weights.6CL.hdf5\n",
      "Epoch 2/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.3294 - acc: 0.8722 - val_loss: 0.3500 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.35278 to 0.35003, saving model to weights.6CL.hdf5\n",
      "Epoch 3/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.2784 - acc: 0.8874 - val_loss: 0.2751 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.35003 to 0.27510, saving model to weights.6CL.hdf5\n",
      "Epoch 4/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.2191 - acc: 0.9169 - val_loss: 0.3967 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27510\n",
      "Epoch 5/80\n",
      "1768/1768 [==============================] - 1s 516us/step - loss: 0.1909 - acc: 0.9253 - val_loss: 0.2582 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.27510 to 0.25815, saving model to weights.6CL.hdf5\n",
      "Epoch 6/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.1716 - acc: 0.9287 - val_loss: 0.2381 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.25815 to 0.23807, saving model to weights.6CL.hdf5\n",
      "Epoch 7/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.1464 - acc: 0.9412 - val_loss: 0.3052 - val_acc: 0.8847\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.23807\n",
      "Epoch 8/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.1588 - acc: 0.9423 - val_loss: 0.3100 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.23807\n",
      "Epoch 9/80\n",
      "1768/1768 [==============================] - 1s 505us/step - loss: 0.1251 - acc: 0.9559 - val_loss: 0.1754 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.23807 to 0.17541, saving model to weights.6CL.hdf5\n",
      "Epoch 10/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.1127 - acc: 0.9593 - val_loss: 0.1871 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.17541\n",
      "Epoch 11/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.1016 - acc: 0.9632 - val_loss: 0.2051 - val_acc: 0.9288\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.17541\n",
      "Epoch 12/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0811 - acc: 0.9745 - val_loss: 0.2263 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.17541\n",
      "Epoch 13/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.0771 - acc: 0.9706 - val_loss: 0.3797 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.17541\n",
      "Epoch 14/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.0651 - acc: 0.9762 - val_loss: 0.2471 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.17541\n",
      "Epoch 15/80\n",
      "1768/1768 [==============================] - 1s 515us/step - loss: 0.0602 - acc: 0.9774 - val_loss: 0.3401 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.17541\n",
      "Epoch 16/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0595 - acc: 0.9785 - val_loss: 0.2296 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.17541\n",
      "Epoch 17/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.0583 - acc: 0.9779 - val_loss: 0.1950 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.17541\n",
      "Epoch 18/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.0487 - acc: 0.9819 - val_loss: 0.2414 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.17541\n",
      "Epoch 19/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0398 - acc: 0.9847 - val_loss: 0.2117 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.17541\n",
      "Epoch 20/80\n",
      "1768/1768 [==============================] - 1s 506us/step - loss: 0.0386 - acc: 0.9870 - val_loss: 0.2520 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.17541\n",
      "Epoch 21/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0370 - acc: 0.9864 - val_loss: 0.2141 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.17541\n",
      "Epoch 22/80\n",
      "1768/1768 [==============================] - 1s 507us/step - loss: 0.0299 - acc: 0.9898 - val_loss: 0.2006 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17541\n",
      "Epoch 23/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.0282 - acc: 0.9921 - val_loss: 0.1802 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17541\n",
      "Epoch 24/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.0391 - acc: 0.9881 - val_loss: 0.2116 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.17541\n",
      "Epoch 25/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.0405 - acc: 0.9864 - val_loss: 0.2191 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.17541\n",
      "Epoch 26/80\n",
      "1768/1768 [==============================] - 1s 518us/step - loss: 0.0350 - acc: 0.9881 - val_loss: 0.1786 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.17541\n",
      "Epoch 27/80\n",
      "1768/1768 [==============================] - 1s 508us/step - loss: 0.0225 - acc: 0.9938 - val_loss: 0.1828 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.17541\n",
      "Epoch 28/80\n",
      "1768/1768 [==============================] - 1s 514us/step - loss: 0.0294 - acc: 0.9887 - val_loss: 0.2121 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.17541\n",
      "Epoch 29/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.0411 - acc: 0.9853 - val_loss: 0.1940 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.17541\n",
      "Epoch 30/80\n",
      "1768/1768 [==============================] - 1s 507us/step - loss: 0.0272 - acc: 0.9887 - val_loss: 0.1805 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17541\n",
      "Epoch 31/80\n",
      "1768/1768 [==============================] - 1s 507us/step - loss: 0.0148 - acc: 0.9955 - val_loss: 0.2538 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.17541\n",
      "Epoch 32/80\n",
      "1768/1768 [==============================] - 1s 507us/step - loss: 0.0182 - acc: 0.9943 - val_loss: 0.2279 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.17541\n",
      "Epoch 33/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0281 - acc: 0.9893 - val_loss: 0.2169 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.17541\n",
      "Epoch 34/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.0226 - acc: 0.9926 - val_loss: 0.1894 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.17541\n",
      "Epoch 35/80\n",
      "1768/1768 [==============================] - 1s 518us/step - loss: 0.0227 - acc: 0.9926 - val_loss: 0.1996 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.17541\n",
      "Epoch 36/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0286 - acc: 0.9904 - val_loss: 0.2344 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.17541\n",
      "Epoch 37/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0293 - acc: 0.9910 - val_loss: 0.2225 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.17541\n",
      "Epoch 38/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.0344 - acc: 0.9870 - val_loss: 0.3073 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.17541\n",
      "Epoch 39/80\n",
      "1768/1768 [==============================] - 1s 514us/step - loss: 0.0220 - acc: 0.9938 - val_loss: 0.2500 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.17541\n",
      "Epoch 40/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0332 - acc: 0.9893 - val_loss: 0.1993 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.17541\n",
      "Epoch 41/80\n",
      "1768/1768 [==============================] - 1s 504us/step - loss: 0.0218 - acc: 0.9938 - val_loss: 0.2430 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.17541\n",
      "Epoch 42/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0380 - acc: 0.9853 - val_loss: 0.2719 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.17541\n",
      "Epoch 43/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 507us/step - loss: 0.0246 - acc: 0.9938 - val_loss: 0.2202 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.17541\n",
      "Epoch 44/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0328 - acc: 0.9893 - val_loss: 0.2426 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.17541\n",
      "Epoch 45/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0390 - acc: 0.9859 - val_loss: 0.1920 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.17541\n",
      "Epoch 46/80\n",
      "1768/1768 [==============================] - 1s 514us/step - loss: 0.0218 - acc: 0.9938 - val_loss: 0.2252 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.17541\n",
      "Epoch 47/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0221 - acc: 0.9915 - val_loss: 0.2406 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.17541\n",
      "Epoch 48/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.0336 - acc: 0.9915 - val_loss: 0.1931 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.17541\n",
      "Epoch 49/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0142 - acc: 0.9960 - val_loss: 0.2513 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.17541\n",
      "Epoch 50/80\n",
      "1768/1768 [==============================] - 1s 507us/step - loss: 0.0093 - acc: 0.9966 - val_loss: 0.2267 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.17541\n",
      "Epoch 51/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0179 - acc: 0.9943 - val_loss: 0.2375 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.17541\n",
      "Epoch 52/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0159 - acc: 0.9960 - val_loss: 0.2225 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.17541\n",
      "Epoch 53/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0141 - acc: 0.9949 - val_loss: 0.2179 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.17541\n",
      "Epoch 54/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.0182 - acc: 0.9938 - val_loss: 0.2345 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.17541\n",
      "Epoch 55/80\n",
      "1768/1768 [==============================] - 1s 514us/step - loss: 0.0096 - acc: 0.9960 - val_loss: 0.2234 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.17541\n",
      "Epoch 56/80\n",
      "1768/1768 [==============================] - 1s 508us/step - loss: 0.0100 - acc: 0.9977 - val_loss: 0.2251 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.17541\n",
      "Epoch 57/80\n",
      "1768/1768 [==============================] - 1s 514us/step - loss: 0.0106 - acc: 0.9972 - val_loss: 0.2685 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.17541\n",
      "Epoch 58/80\n",
      "1768/1768 [==============================] - 1s 519us/step - loss: 0.0109 - acc: 0.9943 - val_loss: 0.2140 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.17541\n",
      "Epoch 59/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0078 - acc: 0.9966 - val_loss: 0.2919 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.17541\n",
      "Epoch 60/80\n",
      "1768/1768 [==============================] - 1s 515us/step - loss: 0.0089 - acc: 0.9983 - val_loss: 0.2607 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.17541\n",
      "Epoch 61/80\n",
      "1768/1768 [==============================] - 1s 514us/step - loss: 0.0131 - acc: 0.9955 - val_loss: 0.2850 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.17541\n",
      "Epoch 62/80\n",
      "1768/1768 [==============================] - 1s 509us/step - loss: 0.0143 - acc: 0.9977 - val_loss: 0.2506 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.17541\n",
      "Epoch 63/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0105 - acc: 0.9955 - val_loss: 0.2192 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.17541\n",
      "Epoch 64/80\n",
      "1768/1768 [==============================] - 1s 518us/step - loss: 0.0104 - acc: 0.9960 - val_loss: 0.2627 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.17541\n",
      "Epoch 65/80\n",
      "1768/1768 [==============================] - 1s 511us/step - loss: 0.0167 - acc: 0.9943 - val_loss: 0.1965 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.17541\n",
      "Epoch 66/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0125 - acc: 0.9955 - val_loss: 0.1717 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.17541 to 0.17165, saving model to weights.6CL.hdf5\n",
      "Epoch 67/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0129 - acc: 0.9949 - val_loss: 0.2501 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.17165\n",
      "Epoch 68/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0242 - acc: 0.9938 - val_loss: 0.3218 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.17165\n",
      "Epoch 69/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0205 - acc: 0.9932 - val_loss: 0.2599 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.17165\n",
      "Epoch 70/80\n",
      "1768/1768 [==============================] - 1s 506us/step - loss: 0.0231 - acc: 0.9910 - val_loss: 0.3157 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.17165\n",
      "Epoch 71/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.2410 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.17165\n",
      "Epoch 72/80\n",
      "1768/1768 [==============================] - 1s 510us/step - loss: 0.0288 - acc: 0.9932 - val_loss: 0.2878 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.17165\n",
      "Epoch 73/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0207 - acc: 0.9910 - val_loss: 0.2385 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.17165\n",
      "Epoch 74/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0235 - acc: 0.9910 - val_loss: 0.2884 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.17165\n",
      "Epoch 75/80\n",
      "1768/1768 [==============================] - 1s 508us/step - loss: 0.0299 - acc: 0.9921 - val_loss: 0.2427 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.17165\n",
      "Epoch 76/80\n",
      "1768/1768 [==============================] - 1s 515us/step - loss: 0.0173 - acc: 0.9938 - val_loss: 0.2272 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.17165\n",
      "Epoch 77/80\n",
      "1768/1768 [==============================] - 1s 508us/step - loss: 0.0107 - acc: 0.9949 - val_loss: 0.2119 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.17165\n",
      "Epoch 78/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.1897 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.17165\n",
      "Epoch 79/80\n",
      "1768/1768 [==============================] - 1s 512us/step - loss: 0.0192 - acc: 0.9932 - val_loss: 0.2074 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.17165\n",
      "Epoch 80/80\n",
      "1768/1768 [==============================] - 1s 513us/step - loss: 0.0088 - acc: 0.9960 - val_loss: 0.2198 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17165\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.6CL.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history6=model6.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, val_labels),\n",
    "          epochs=80, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 96.4407%\n"
     ]
    }
   ],
   "source": [
    "model6.load_weights('weights.6CL.hdf5')\n",
    "model6_pred = [np.argmax(model6.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy_model6 = 100*np.sum(np.array(model6_pred)==np.argmax(test_labels, axis=1))/len(model6_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy_model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_CNN=np.argmax(test_labels,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuraccy is still lower than for Model 1 and our benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4.3: Model 7 - add extra layers to Model 6.** <br>\n",
    "Testing if more layers can give us increase in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 39, 39, 32)        416       \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 37, 37, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 3, 3, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                9248      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 37,858\n",
      "Trainable params: 37,666\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "\n",
    "model7.add(Conv2D(32, (2, 2), activation='relu', input_shape=(40,40,3)))\n",
    "\n",
    "model7.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(Dropout(0.4))\n",
    "\n",
    "model7.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(Dropout(0.4))\n",
    "\n",
    "model7.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model7.add(BatchNormalization())\n",
    "model7.add(Dropout(0.4))\n",
    " \n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(32, activation='relu'))\n",
    "model7.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1768 samples, validate on 590 samples\n",
      "Epoch 1/80\n",
      "1768/1768 [==============================] - 2s 1ms/step - loss: 0.6160 - acc: 0.7460 - val_loss: 0.4068 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.40680, saving model to weights.7CL.hdf5\n",
      "Epoch 2/80\n",
      "1768/1768 [==============================] - 1s 596us/step - loss: 0.4229 - acc: 0.8224 - val_loss: 0.3765 - val_acc: 0.8441\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.40680 to 0.37649, saving model to weights.7CL.hdf5\n",
      "Epoch 3/80\n",
      "1768/1768 [==============================] - 1s 598us/step - loss: 0.3875 - acc: 0.8416 - val_loss: 0.3186 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37649 to 0.31855, saving model to weights.7CL.hdf5\n",
      "Epoch 4/80\n",
      "1768/1768 [==============================] - 1s 596us/step - loss: 0.3013 - acc: 0.8795 - val_loss: 0.2793 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.31855 to 0.27934, saving model to weights.7CL.hdf5\n",
      "Epoch 5/80\n",
      "1768/1768 [==============================] - 1s 593us/step - loss: 0.2781 - acc: 0.8807 - val_loss: 0.2843 - val_acc: 0.8814\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27934\n",
      "Epoch 6/80\n",
      "1768/1768 [==============================] - 1s 601us/step - loss: 0.2704 - acc: 0.8976 - val_loss: 0.3672 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27934\n",
      "Epoch 7/80\n",
      "1768/1768 [==============================] - 1s 596us/step - loss: 0.2471 - acc: 0.8976 - val_loss: 0.2531 - val_acc: 0.9068\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.27934 to 0.25312, saving model to weights.7CL.hdf5\n",
      "Epoch 8/80\n",
      "1768/1768 [==============================] - 1s 594us/step - loss: 0.2492 - acc: 0.8942 - val_loss: 0.2405 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.25312 to 0.24050, saving model to weights.7CL.hdf5\n",
      "Epoch 9/80\n",
      "1768/1768 [==============================] - 1s 591us/step - loss: 0.2105 - acc: 0.9112 - val_loss: 0.2297 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.24050 to 0.22966, saving model to weights.7CL.hdf5\n",
      "Epoch 10/80\n",
      "1768/1768 [==============================] - 1s 594us/step - loss: 0.2088 - acc: 0.9214 - val_loss: 0.2652 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22966\n",
      "Epoch 11/80\n",
      "1768/1768 [==============================] - 1s 591us/step - loss: 0.1898 - acc: 0.9202 - val_loss: 0.2747 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.22966\n",
      "Epoch 12/80\n",
      "1768/1768 [==============================] - 1s 596us/step - loss: 0.1926 - acc: 0.9259 - val_loss: 0.1986 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.22966 to 0.19861, saving model to weights.7CL.hdf5\n",
      "Epoch 13/80\n",
      "1768/1768 [==============================] - 1s 612us/step - loss: 0.1852 - acc: 0.9265 - val_loss: 0.1842 - val_acc: 0.9288\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.19861 to 0.18424, saving model to weights.7CL.hdf5\n",
      "Epoch 14/80\n",
      "1768/1768 [==============================] - 1s 597us/step - loss: 0.1605 - acc: 0.9361 - val_loss: 0.1820 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.18424 to 0.18203, saving model to weights.7CL.hdf5\n",
      "Epoch 15/80\n",
      "1768/1768 [==============================] - 1s 590us/step - loss: 0.1625 - acc: 0.9299 - val_loss: 0.8433 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.18203\n",
      "Epoch 16/80\n",
      "1768/1768 [==============================] - 1s 596us/step - loss: 0.1664 - acc: 0.9367 - val_loss: 0.1574 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.18203 to 0.15742, saving model to weights.7CL.hdf5\n",
      "Epoch 17/80\n",
      "1768/1768 [==============================] - 1s 595us/step - loss: 0.1693 - acc: 0.9350 - val_loss: 0.1641 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.15742\n",
      "Epoch 18/80\n",
      "1768/1768 [==============================] - 1s 598us/step - loss: 0.1579 - acc: 0.9412 - val_loss: 0.2325 - val_acc: 0.9186\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.15742\n",
      "Epoch 19/80\n",
      "1768/1768 [==============================] - 1s 592us/step - loss: 0.1429 - acc: 0.9463 - val_loss: 0.2001 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.15742\n",
      "Epoch 20/80\n",
      "1768/1768 [==============================] - 1s 593us/step - loss: 0.1365 - acc: 0.9400 - val_loss: 0.1989 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.15742\n",
      "Epoch 21/80\n",
      "1768/1768 [==============================] - 1s 597us/step - loss: 0.1195 - acc: 0.9536 - val_loss: 0.1810 - val_acc: 0.9288\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.15742\n",
      "Epoch 22/80\n",
      "1768/1768 [==============================] - 1s 596us/step - loss: 0.1138 - acc: 0.9502 - val_loss: 0.1925 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.15742\n",
      "Epoch 23/80\n",
      "1768/1768 [==============================] - 1s 598us/step - loss: 0.1200 - acc: 0.9536 - val_loss: 0.1847 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.15742\n",
      "Epoch 24/80\n",
      "1768/1768 [==============================] - 1s 595us/step - loss: 0.1205 - acc: 0.9519 - val_loss: 0.2298 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.15742\n",
      "Epoch 25/80\n",
      "1768/1768 [==============================] - 1s 604us/step - loss: 0.1038 - acc: 0.9638 - val_loss: 0.1837 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15742\n",
      "Epoch 26/80\n",
      "1768/1768 [==============================] - 1s 602us/step - loss: 0.1024 - acc: 0.9615 - val_loss: 0.1428 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.15742 to 0.14275, saving model to weights.7CL.hdf5\n",
      "Epoch 27/80\n",
      "1768/1768 [==============================] - 1s 600us/step - loss: 0.1012 - acc: 0.9632 - val_loss: 0.1474 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.14275\n",
      "Epoch 28/80\n",
      "1768/1768 [==============================] - 1s 599us/step - loss: 0.0938 - acc: 0.9615 - val_loss: 0.1433 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.14275\n",
      "Epoch 29/80\n",
      "1768/1768 [==============================] - 1s 602us/step - loss: 0.1172 - acc: 0.9576 - val_loss: 0.2397 - val_acc: 0.9305\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.14275\n",
      "Epoch 30/80\n",
      "1768/1768 [==============================] - 1s 604us/step - loss: 0.0994 - acc: 0.9593 - val_loss: 0.2093 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.14275\n",
      "Epoch 31/80\n",
      "1768/1768 [==============================] - 1s 607us/step - loss: 0.1005 - acc: 0.9632 - val_loss: 0.1810 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.14275\n",
      "Epoch 32/80\n",
      "1768/1768 [==============================] - 1s 602us/step - loss: 0.0917 - acc: 0.9672 - val_loss: 0.1522 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.14275\n",
      "Epoch 33/80\n",
      "1768/1768 [==============================] - 1s 603us/step - loss: 0.0944 - acc: 0.9672 - val_loss: 0.1994 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.14275\n",
      "Epoch 34/80\n",
      "1768/1768 [==============================] - 1s 606us/step - loss: 0.1029 - acc: 0.9587 - val_loss: 0.1486 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.14275\n",
      "Epoch 35/80\n",
      "1768/1768 [==============================] - 1s 605us/step - loss: 0.0929 - acc: 0.9649 - val_loss: 0.1407 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.14275 to 0.14071, saving model to weights.7CL.hdf5\n",
      "Epoch 36/80\n",
      "1768/1768 [==============================] - 1s 599us/step - loss: 0.0903 - acc: 0.9627 - val_loss: 0.1739 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.14071\n",
      "Epoch 37/80\n",
      "1768/1768 [==============================] - 1s 592us/step - loss: 0.0838 - acc: 0.9683 - val_loss: 0.2346 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.14071\n",
      "Epoch 38/80\n",
      "1768/1768 [==============================] - 1s 597us/step - loss: 0.0842 - acc: 0.9706 - val_loss: 0.1447 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.14071\n",
      "Epoch 39/80\n",
      "1768/1768 [==============================] - 1s 592us/step - loss: 0.0741 - acc: 0.9683 - val_loss: 0.1234 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.14071 to 0.12337, saving model to weights.7CL.hdf5\n",
      "Epoch 40/80\n",
      "1768/1768 [==============================] - 1s 594us/step - loss: 0.0726 - acc: 0.9689 - val_loss: 0.2190 - val_acc: 0.9237\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.12337\n",
      "Epoch 41/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 594us/step - loss: 0.0751 - acc: 0.9706 - val_loss: 0.2972 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.12337\n",
      "Epoch 42/80\n",
      "1768/1768 [==============================] - 1s 595us/step - loss: 0.0679 - acc: 0.9712 - val_loss: 0.1339 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.12337\n",
      "Epoch 43/80\n",
      "1768/1768 [==============================] - 1s 590us/step - loss: 0.0715 - acc: 0.9729 - val_loss: 0.1658 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.12337\n",
      "Epoch 44/80\n",
      "1768/1768 [==============================] - 1s 593us/step - loss: 0.0708 - acc: 0.9734 - val_loss: 0.1567 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.12337\n",
      "Epoch 45/80\n",
      "1768/1768 [==============================] - 1s 593us/step - loss: 0.0698 - acc: 0.9706 - val_loss: 0.2114 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.12337\n",
      "Epoch 46/80\n",
      "1768/1768 [==============================] - 1s 594us/step - loss: 0.0746 - acc: 0.9672 - val_loss: 0.1913 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.12337\n",
      "Epoch 47/80\n",
      "1768/1768 [==============================] - 1s 610us/step - loss: 0.0650 - acc: 0.9774 - val_loss: 0.1077 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12337 to 0.10772, saving model to weights.7CL.hdf5\n",
      "Epoch 48/80\n",
      "1768/1768 [==============================] - 1s 600us/step - loss: 0.0687 - acc: 0.9734 - val_loss: 0.1384 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.10772\n",
      "Epoch 49/80\n",
      "1768/1768 [==============================] - 1s 602us/step - loss: 0.0817 - acc: 0.9717 - val_loss: 0.1232 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.10772\n",
      "Epoch 50/80\n",
      "1768/1768 [==============================] - 1s 592us/step - loss: 0.0669 - acc: 0.9751 - val_loss: 0.1417 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.10772\n",
      "Epoch 51/80\n",
      "1768/1768 [==============================] - 1s 598us/step - loss: 0.0703 - acc: 0.9734 - val_loss: 0.2454 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.10772\n",
      "Epoch 52/80\n",
      "1768/1768 [==============================] - 1s 596us/step - loss: 0.0610 - acc: 0.9779 - val_loss: 0.1327 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.10772\n",
      "Epoch 53/80\n",
      "1768/1768 [==============================] - 1s 594us/step - loss: 0.0594 - acc: 0.9791 - val_loss: 0.1392 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.10772\n",
      "Epoch 54/80\n",
      "1768/1768 [==============================] - 1s 595us/step - loss: 0.0546 - acc: 0.9785 - val_loss: 0.1204 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.10772\n",
      "Epoch 55/80\n",
      "1768/1768 [==============================] - 1s 600us/step - loss: 0.0580 - acc: 0.9785 - val_loss: 0.1244 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.10772\n",
      "Epoch 56/80\n",
      "1768/1768 [==============================] - 1s 597us/step - loss: 0.0621 - acc: 0.9751 - val_loss: 0.1442 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.10772\n",
      "Epoch 57/80\n",
      "1768/1768 [==============================] - 1s 589us/step - loss: 0.0540 - acc: 0.9813 - val_loss: 0.2486 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.10772\n",
      "Epoch 58/80\n",
      "1768/1768 [==============================] - 1s 593us/step - loss: 0.0565 - acc: 0.9802 - val_loss: 0.1198 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.10772\n",
      "Epoch 59/80\n",
      "1768/1768 [==============================] - 1s 592us/step - loss: 0.0484 - acc: 0.9830 - val_loss: 0.1767 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.10772\n",
      "Epoch 60/80\n",
      "1768/1768 [==============================] - 1s 603us/step - loss: 0.0578 - acc: 0.9785 - val_loss: 0.2061 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.10772\n",
      "Epoch 61/80\n",
      "1768/1768 [==============================] - 1s 601us/step - loss: 0.0557 - acc: 0.9791 - val_loss: 0.2131 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.10772\n",
      "Epoch 62/80\n",
      "1768/1768 [==============================] - 1s 596us/step - loss: 0.0453 - acc: 0.9847 - val_loss: 0.1200 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.10772\n",
      "Epoch 63/80\n",
      "1768/1768 [==============================] - 1s 595us/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.1129 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.10772\n",
      "Epoch 64/80\n",
      "1768/1768 [==============================] - 1s 593us/step - loss: 0.0438 - acc: 0.9847 - val_loss: 0.1915 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.10772\n",
      "Epoch 65/80\n",
      "1768/1768 [==============================] - 1s 600us/step - loss: 0.0468 - acc: 0.9836 - val_loss: 0.1907 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.10772\n",
      "Epoch 66/80\n",
      "1768/1768 [==============================] - 1s 594us/step - loss: 0.0637 - acc: 0.9762 - val_loss: 0.1318 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.10772\n",
      "Epoch 67/80\n",
      "1768/1768 [==============================] - 1s 602us/step - loss: 0.0551 - acc: 0.9842 - val_loss: 0.1094 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.10772\n",
      "Epoch 68/80\n",
      "1768/1768 [==============================] - 1s 598us/step - loss: 0.0625 - acc: 0.9785 - val_loss: 0.1187 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.10772\n",
      "Epoch 69/80\n",
      "1768/1768 [==============================] - 1s 600us/step - loss: 0.0534 - acc: 0.9819 - val_loss: 0.2290 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.10772\n",
      "Epoch 70/80\n",
      "1768/1768 [==============================] - 1s 606us/step - loss: 0.0511 - acc: 0.9836 - val_loss: 0.2089 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.10772\n",
      "Epoch 71/80\n",
      "1768/1768 [==============================] - 1s 594us/step - loss: 0.0463 - acc: 0.9836 - val_loss: 0.1606 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.10772\n",
      "Epoch 72/80\n",
      "1768/1768 [==============================] - 1s 597us/step - loss: 0.0468 - acc: 0.9808 - val_loss: 0.2052 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.10772\n",
      "Epoch 73/80\n",
      "1768/1768 [==============================] - 1s 595us/step - loss: 0.0570 - acc: 0.9802 - val_loss: 0.1690 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.10772\n",
      "Epoch 74/80\n",
      "1768/1768 [==============================] - 1s 599us/step - loss: 0.0358 - acc: 0.9881 - val_loss: 0.1395 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.10772\n",
      "Epoch 75/80\n",
      "1768/1768 [==============================] - 1s 595us/step - loss: 0.0561 - acc: 0.9791 - val_loss: 0.1697 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.10772\n",
      "Epoch 76/80\n",
      "1768/1768 [==============================] - 1s 600us/step - loss: 0.0470 - acc: 0.9825 - val_loss: 0.2776 - val_acc: 0.9220\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.10772\n",
      "Epoch 77/80\n",
      "1768/1768 [==============================] - 1s 600us/step - loss: 0.0512 - acc: 0.9796 - val_loss: 0.1412 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.10772\n",
      "Epoch 78/80\n",
      "1768/1768 [==============================] - 1s 592us/step - loss: 0.0370 - acc: 0.9881 - val_loss: 0.1493 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.10772\n",
      "Epoch 79/80\n",
      "1768/1768 [==============================] - 1s 599us/step - loss: 0.0445 - acc: 0.9847 - val_loss: 0.1538 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.10772\n",
      "Epoch 80/80\n",
      "1768/1768 [==============================] - 1s 599us/step - loss: 0.0336 - acc: 0.9898 - val_loss: 0.1995 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.10772\n"
     ]
    }
   ],
   "source": [
    "model7.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "checkpointer = ModelCheckpoint(filepath='weights.7CL.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history7=model7.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, val_labels),\n",
    "          epochs=80, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 95.5932%\n"
     ]
    }
   ],
   "source": [
    "model7_pred = [np.argmax(model7.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy_model7 = 100*np.sum(np.array(model7_pred)==np.argmax(test_labels, axis=1))/len(model7_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy_model7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4.4: Model 8 - decrease droput rate, change filter dimensions, add one layer.** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 38, 38, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 18, 18, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 18, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 17, 17, 32)        4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8, 8, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 7, 7, 32)          4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 3, 3, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 2, 2, 32)          4128      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 1, 1, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 24,162\n",
      "Trainable params: 23,906\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "\n",
    "model8.add(Conv2D(32, (3, 3), activation='relu', input_shape=(40,40,3)))\n",
    "\n",
    "model8.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model8.add(BatchNormalization())\n",
    "model8.add(Dropout(0.3))\n",
    "\n",
    "model8.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model8.add(BatchNormalization())\n",
    "model8.add(Dropout(0.3))\n",
    "\n",
    "model8.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model8.add(BatchNormalization())\n",
    "model8.add(Dropout(0.3))\n",
    "\n",
    "model8.add(Conv2D(32, (2, 2), activation='relu'))\n",
    "model8.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model8.add(BatchNormalization())\n",
    "model8.add(Dropout(0.3))\n",
    "\n",
    "model8.add(Flatten())\n",
    "model8.add(Dense(32, activation='relu'))\n",
    "model8.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model8.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1768 samples, validate on 590 samples\n",
      "Epoch 1/300\n",
      "1768/1768 [==============================] - 3s 2ms/step - loss: 0.0542 - acc: 0.9762 - val_loss: 0.6014 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.60136, saving model to weights.8CL.hdf5\n",
      "Epoch 2/300\n",
      "1768/1768 [==============================] - 1s 486us/step - loss: 0.0441 - acc: 0.9864 - val_loss: 0.4454 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.60136 to 0.44541, saving model to weights.8CL.hdf5\n",
      "Epoch 3/300\n",
      "1768/1768 [==============================] - 1s 485us/step - loss: 0.0503 - acc: 0.9779 - val_loss: 0.2317 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.44541 to 0.23170, saving model to weights.8CL.hdf5\n",
      "Epoch 4/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0432 - acc: 0.9847 - val_loss: 0.2055 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.23170 to 0.20554, saving model to weights.8CL.hdf5\n",
      "Epoch 5/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0510 - acc: 0.9791 - val_loss: 0.1492 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.20554 to 0.14916, saving model to weights.8CL.hdf5\n",
      "Epoch 6/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0581 - acc: 0.9796 - val_loss: 0.1412 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14916 to 0.14119, saving model to weights.8CL.hdf5\n",
      "Epoch 7/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0526 - acc: 0.9813 - val_loss: 0.1292 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14119 to 0.12921, saving model to weights.8CL.hdf5\n",
      "Epoch 8/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0416 - acc: 0.9859 - val_loss: 0.1462 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.12921\n",
      "Epoch 9/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0486 - acc: 0.9847 - val_loss: 0.1803 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.12921\n",
      "Epoch 10/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0410 - acc: 0.9853 - val_loss: 0.1599 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.12921\n",
      "Epoch 11/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0381 - acc: 0.9881 - val_loss: 0.2662 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.12921\n",
      "Epoch 12/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0655 - acc: 0.9774 - val_loss: 0.1626 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.12921\n",
      "Epoch 13/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0453 - acc: 0.9870 - val_loss: 0.1518 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.12921\n",
      "Epoch 14/300\n",
      "1768/1768 [==============================] - 1s 490us/step - loss: 0.0470 - acc: 0.9825 - val_loss: 0.1373 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.12921\n",
      "Epoch 15/300\n",
      "1768/1768 [==============================] - 1s 494us/step - loss: 0.0493 - acc: 0.9808 - val_loss: 0.1293 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12921\n",
      "Epoch 16/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0432 - acc: 0.9842 - val_loss: 0.1173 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.12921 to 0.11729, saving model to weights.8CL.hdf5\n",
      "Epoch 17/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0454 - acc: 0.9853 - val_loss: 0.1515 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.11729\n",
      "Epoch 18/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0514 - acc: 0.9785 - val_loss: 0.1320 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.11729\n",
      "Epoch 19/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0645 - acc: 0.9762 - val_loss: 0.1364 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.11729\n",
      "Epoch 20/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0470 - acc: 0.9847 - val_loss: 0.1718 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.11729\n",
      "Epoch 21/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0407 - acc: 0.9830 - val_loss: 0.1347 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11729\n",
      "Epoch 22/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0415 - acc: 0.9870 - val_loss: 0.1835 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.11729\n",
      "Epoch 23/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0309 - acc: 0.9893 - val_loss: 0.1717 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11729\n",
      "Epoch 24/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0442 - acc: 0.9847 - val_loss: 0.1589 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.11729\n",
      "Epoch 25/300\n",
      "1768/1768 [==============================] - 1s 485us/step - loss: 0.0457 - acc: 0.9825 - val_loss: 0.1836 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.11729\n",
      "Epoch 26/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0417 - acc: 0.9870 - val_loss: 0.1843 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.11729\n",
      "Epoch 27/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0377 - acc: 0.9859 - val_loss: 0.1808 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.11729\n",
      "Epoch 28/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0505 - acc: 0.9830 - val_loss: 0.1516 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.11729\n",
      "Epoch 29/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0360 - acc: 0.9864 - val_loss: 0.1503 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.11729\n",
      "Epoch 30/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0422 - acc: 0.9830 - val_loss: 0.2532 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.11729\n",
      "Epoch 31/300\n",
      "1768/1768 [==============================] - 1s 492us/step - loss: 0.0404 - acc: 0.9870 - val_loss: 0.1583 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.11729\n",
      "Epoch 32/300\n",
      "1768/1768 [==============================] - 1s 493us/step - loss: 0.0385 - acc: 0.9876 - val_loss: 0.1575 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.11729\n",
      "Epoch 33/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0488 - acc: 0.9853 - val_loss: 0.1622 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.11729\n",
      "Epoch 34/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0349 - acc: 0.9876 - val_loss: 0.1576 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.11729\n",
      "Epoch 35/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0541 - acc: 0.9836 - val_loss: 0.1441 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.11729\n",
      "Epoch 36/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0412 - acc: 0.9853 - val_loss: 0.1372 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.11729\n",
      "Epoch 37/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0388 - acc: 0.9870 - val_loss: 0.1452 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.11729\n",
      "Epoch 38/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0360 - acc: 0.9864 - val_loss: 0.1658 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.11729\n",
      "Epoch 39/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0410 - acc: 0.9864 - val_loss: 0.2433 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11729\n",
      "Epoch 40/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0429 - acc: 0.9842 - val_loss: 0.2399 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11729\n",
      "Epoch 41/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0321 - acc: 0.9859 - val_loss: 0.1473 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11729\n",
      "Epoch 42/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0433 - acc: 0.9830 - val_loss: 0.1493 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.11729\n",
      "Epoch 43/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0524 - acc: 0.9847 - val_loss: 0.1471 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.11729\n",
      "Epoch 44/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0356 - acc: 0.9853 - val_loss: 0.1569 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11729\n",
      "Epoch 45/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0397 - acc: 0.9853 - val_loss: 0.1963 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.11729\n",
      "Epoch 46/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0386 - acc: 0.9876 - val_loss: 0.1220 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.11729\n",
      "Epoch 47/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0386 - acc: 0.9870 - val_loss: 0.2015 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.11729\n",
      "Epoch 48/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0403 - acc: 0.9853 - val_loss: 0.1414 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.11729\n",
      "Epoch 49/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0562 - acc: 0.9779 - val_loss: 0.1441 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.11729\n",
      "Epoch 50/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0310 - acc: 0.9876 - val_loss: 0.1455 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.11729\n",
      "Epoch 51/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0371 - acc: 0.9847 - val_loss: 0.1577 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.11729\n",
      "Epoch 52/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0393 - acc: 0.9887 - val_loss: 0.2032 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.11729\n",
      "Epoch 53/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.1530 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.11729\n",
      "Epoch 54/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0260 - acc: 0.9910 - val_loss: 0.2009 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.11729\n",
      "Epoch 55/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0326 - acc: 0.9876 - val_loss: 0.1680 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.11729\n",
      "Epoch 56/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0678 - acc: 0.9779 - val_loss: 0.2188 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.11729\n",
      "Epoch 57/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0474 - acc: 0.9836 - val_loss: 0.1617 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.11729\n",
      "Epoch 58/300\n",
      "1768/1768 [==============================] - 1s 496us/step - loss: 0.0501 - acc: 0.9796 - val_loss: 0.1941 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.11729\n",
      "Epoch 59/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0495 - acc: 0.9808 - val_loss: 0.2077 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.11729\n",
      "Epoch 60/300\n",
      "1768/1768 [==============================] - 1s 487us/step - loss: 0.0515 - acc: 0.9819 - val_loss: 0.1835 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.11729\n",
      "Epoch 61/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0389 - acc: 0.9887 - val_loss: 0.1662 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.11729\n",
      "Epoch 62/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0573 - acc: 0.9830 - val_loss: 0.1458 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.11729\n",
      "Epoch 63/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0435 - acc: 0.9830 - val_loss: 0.1628 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.11729\n",
      "Epoch 64/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0339 - acc: 0.9864 - val_loss: 0.1415 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.11729\n",
      "Epoch 65/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0468 - acc: 0.9830 - val_loss: 0.1568 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.11729\n",
      "Epoch 66/300\n",
      "1768/1768 [==============================] - 1s 486us/step - loss: 0.0616 - acc: 0.9779 - val_loss: 0.1378 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.11729\n",
      "Epoch 67/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0311 - acc: 0.9926 - val_loss: 0.1507 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.11729\n",
      "Epoch 68/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0330 - acc: 0.9859 - val_loss: 0.1165 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.11729 to 0.11653, saving model to weights.8CL.hdf5\n",
      "Epoch 69/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0373 - acc: 0.9847 - val_loss: 0.1521 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.11653\n",
      "Epoch 70/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0382 - acc: 0.9864 - val_loss: 0.1439 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.11653\n",
      "Epoch 71/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0288 - acc: 0.9881 - val_loss: 0.1636 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.11653\n",
      "Epoch 72/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0354 - acc: 0.9842 - val_loss: 0.1793 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.11653\n",
      "Epoch 73/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0338 - acc: 0.9881 - val_loss: 0.2718 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.11653\n",
      "Epoch 74/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0437 - acc: 0.9864 - val_loss: 0.1720 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.11653\n",
      "Epoch 75/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0389 - acc: 0.9898 - val_loss: 0.2217 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.11653\n",
      "Epoch 76/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0331 - acc: 0.9876 - val_loss: 0.2461 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.11653\n",
      "Epoch 77/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0464 - acc: 0.9864 - val_loss: 0.1779 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.11653\n",
      "Epoch 78/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0356 - acc: 0.9876 - val_loss: 0.2140 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.11653\n",
      "Epoch 79/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0340 - acc: 0.9864 - val_loss: 0.2046 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.11653\n",
      "Epoch 80/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0262 - acc: 0.9893 - val_loss: 0.1469 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.11653\n",
      "Epoch 81/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0305 - acc: 0.9859 - val_loss: 0.1598 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.11653\n",
      "Epoch 82/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0313 - acc: 0.9881 - val_loss: 0.1569 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.11653\n",
      "Epoch 83/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0398 - acc: 0.9819 - val_loss: 0.1753 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.11653\n",
      "Epoch 84/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0347 - acc: 0.9893 - val_loss: 0.1941 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.11653\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0366 - acc: 0.9893 - val_loss: 0.1746 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.11653\n",
      "Epoch 86/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0388 - acc: 0.9859 - val_loss: 0.1745 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.11653\n",
      "Epoch 87/300\n",
      "1768/1768 [==============================] - 1s 485us/step - loss: 0.0340 - acc: 0.9893 - val_loss: 0.2193 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.11653\n",
      "Epoch 88/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0347 - acc: 0.9870 - val_loss: 0.1617 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.11653\n",
      "Epoch 89/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0350 - acc: 0.9893 - val_loss: 0.1693 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.11653\n",
      "Epoch 90/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0428 - acc: 0.9859 - val_loss: 0.2272 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.11653\n",
      "Epoch 91/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0366 - acc: 0.9853 - val_loss: 0.2558 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.11653\n",
      "Epoch 92/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0380 - acc: 0.9842 - val_loss: 0.2023 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.11653\n",
      "Epoch 93/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0172 - acc: 0.9938 - val_loss: 0.1966 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.11653\n",
      "Epoch 94/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0206 - acc: 0.9949 - val_loss: 0.1826 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.11653\n",
      "Epoch 95/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0393 - acc: 0.9830 - val_loss: 0.1535 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.11653\n",
      "Epoch 96/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0399 - acc: 0.9864 - val_loss: 0.1467 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.11653\n",
      "Epoch 97/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0522 - acc: 0.9842 - val_loss: 0.1779 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.11653\n",
      "Epoch 98/300\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.0332 - acc: 0.9887 - val_loss: 0.1500 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.11653\n",
      "Epoch 99/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0294 - acc: 0.9881 - val_loss: 0.2113 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.11653\n",
      "Epoch 100/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0369 - acc: 0.9864 - val_loss: 0.1826 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.11653\n",
      "Epoch 101/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0361 - acc: 0.9859 - val_loss: 0.1506 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.11653\n",
      "Epoch 102/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0460 - acc: 0.9870 - val_loss: 0.1625 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.11653\n",
      "Epoch 103/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0348 - acc: 0.9898 - val_loss: 0.1669 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.11653\n",
      "Epoch 104/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0210 - acc: 0.9955 - val_loss: 0.2043 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.11653\n",
      "Epoch 105/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.2026 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.11653\n",
      "Epoch 106/300\n",
      "1768/1768 [==============================] - 1s 486us/step - loss: 0.0435 - acc: 0.9847 - val_loss: 0.1670 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.11653\n",
      "Epoch 107/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0380 - acc: 0.9853 - val_loss: 0.2150 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.11653\n",
      "Epoch 108/300\n",
      "1768/1768 [==============================] - 1s 490us/step - loss: 0.0384 - acc: 0.9847 - val_loss: 0.1813 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.11653\n",
      "Epoch 109/300\n",
      "1768/1768 [==============================] - 1s 501us/step - loss: 0.0329 - acc: 0.9876 - val_loss: 0.2361 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.11653\n",
      "Epoch 110/300\n",
      "1768/1768 [==============================] - 1s 495us/step - loss: 0.0374 - acc: 0.9876 - val_loss: 0.2170 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.11653\n",
      "Epoch 111/300\n",
      "1768/1768 [==============================] - 1s 501us/step - loss: 0.0302 - acc: 0.9876 - val_loss: 0.2397 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.11653\n",
      "Epoch 112/300\n",
      "1768/1768 [==============================] - 1s 486us/step - loss: 0.0418 - acc: 0.9847 - val_loss: 0.1862 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.11653\n",
      "Epoch 113/300\n",
      "1768/1768 [==============================] - 1s 495us/step - loss: 0.0216 - acc: 0.9921 - val_loss: 0.1954 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.11653\n",
      "Epoch 114/300\n",
      "1768/1768 [==============================] - 1s 492us/step - loss: 0.0470 - acc: 0.9859 - val_loss: 0.1829 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.11653\n",
      "Epoch 115/300\n",
      "1768/1768 [==============================] - 1s 488us/step - loss: 0.0276 - acc: 0.9904 - val_loss: 0.1928 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.11653\n",
      "Epoch 116/300\n",
      "1768/1768 [==============================] - 1s 485us/step - loss: 0.0314 - acc: 0.9859 - val_loss: 0.2037 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.11653\n",
      "Epoch 117/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0560 - acc: 0.9791 - val_loss: 0.2616 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 0.11653\n",
      "Epoch 118/300\n",
      "1768/1768 [==============================] - 1s 487us/step - loss: 0.0257 - acc: 0.9910 - val_loss: 0.1803 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.11653\n",
      "Epoch 119/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0267 - acc: 0.9921 - val_loss: 0.2204 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.11653\n",
      "Epoch 120/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0294 - acc: 0.9904 - val_loss: 0.1850 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.11653\n",
      "Epoch 121/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0192 - acc: 0.9932 - val_loss: 0.2099 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.11653\n",
      "Epoch 122/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0319 - acc: 0.9859 - val_loss: 0.2385 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.11653\n",
      "Epoch 123/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0488 - acc: 0.9825 - val_loss: 0.2020 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.11653\n",
      "Epoch 124/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0343 - acc: 0.9870 - val_loss: 0.2267 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.11653\n",
      "Epoch 125/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0567 - acc: 0.9785 - val_loss: 0.2113 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.11653\n",
      "Epoch 126/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0430 - acc: 0.9842 - val_loss: 0.1274 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.11653\n",
      "Epoch 127/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0349 - acc: 0.9870 - val_loss: 0.1548 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.11653\n",
      "Epoch 128/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 491us/step - loss: 0.0278 - acc: 0.9881 - val_loss: 0.1737 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.11653\n",
      "Epoch 129/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0337 - acc: 0.9847 - val_loss: 0.1711 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.11653\n",
      "Epoch 130/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0369 - acc: 0.9893 - val_loss: 0.1901 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.11653\n",
      "Epoch 131/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0455 - acc: 0.9830 - val_loss: 0.1996 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.11653\n",
      "Epoch 132/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0313 - acc: 0.9881 - val_loss: 0.2221 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.11653\n",
      "Epoch 133/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0429 - acc: 0.9847 - val_loss: 0.2413 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.11653\n",
      "Epoch 134/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0379 - acc: 0.9870 - val_loss: 0.2041 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.11653\n",
      "Epoch 135/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0316 - acc: 0.9876 - val_loss: 0.1899 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.11653\n",
      "Epoch 136/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0332 - acc: 0.9876 - val_loss: 0.1646 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.11653\n",
      "Epoch 137/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0271 - acc: 0.9932 - val_loss: 0.1730 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.11653\n",
      "Epoch 138/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0309 - acc: 0.9887 - val_loss: 0.1807 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.11653\n",
      "Epoch 139/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0211 - acc: 0.9926 - val_loss: 0.2210 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.11653\n",
      "Epoch 140/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0392 - acc: 0.9864 - val_loss: 0.2345 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.11653\n",
      "Epoch 141/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0308 - acc: 0.9887 - val_loss: 0.2196 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.11653\n",
      "Epoch 142/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0370 - acc: 0.9864 - val_loss: 0.2019 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.11653\n",
      "Epoch 143/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0231 - acc: 0.9910 - val_loss: 0.2198 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.11653\n",
      "Epoch 144/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0278 - acc: 0.9921 - val_loss: 0.2531 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.11653\n",
      "Epoch 145/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0393 - acc: 0.9859 - val_loss: 0.3188 - val_acc: 0.9288\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.11653\n",
      "Epoch 146/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0277 - acc: 0.9881 - val_loss: 0.1914 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.11653\n",
      "Epoch 147/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0426 - acc: 0.9859 - val_loss: 0.1922 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.11653\n",
      "Epoch 148/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0326 - acc: 0.9898 - val_loss: 0.2041 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.11653\n",
      "Epoch 149/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0243 - acc: 0.9921 - val_loss: 0.1598 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.11653\n",
      "Epoch 150/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0306 - acc: 0.9881 - val_loss: 0.2570 - val_acc: 0.9322\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.11653\n",
      "Epoch 151/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0201 - acc: 0.9921 - val_loss: 0.2308 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.11653\n",
      "Epoch 152/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0347 - acc: 0.9876 - val_loss: 0.2024 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.11653\n",
      "Epoch 153/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0320 - acc: 0.9887 - val_loss: 0.2380 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.11653\n",
      "Epoch 154/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0464 - acc: 0.9836 - val_loss: 0.2764 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.11653\n",
      "Epoch 155/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0388 - acc: 0.9853 - val_loss: 0.2389 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.11653\n",
      "Epoch 156/300\n",
      "1768/1768 [==============================] - 1s 493us/step - loss: 0.0257 - acc: 0.9926 - val_loss: 0.2172 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.11653\n",
      "Epoch 157/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0214 - acc: 0.9932 - val_loss: 0.2161 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.11653\n",
      "Epoch 158/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0226 - acc: 0.9893 - val_loss: 0.2111 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.11653\n",
      "Epoch 159/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0316 - acc: 0.9881 - val_loss: 0.2085 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.11653\n",
      "Epoch 160/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0277 - acc: 0.9915 - val_loss: 0.2010 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.11653\n",
      "Epoch 161/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0374 - acc: 0.9864 - val_loss: 0.2619 - val_acc: 0.9339\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.11653\n",
      "Epoch 162/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0327 - acc: 0.9893 - val_loss: 0.1713 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.11653\n",
      "Epoch 163/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0316 - acc: 0.9887 - val_loss: 0.2098 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.11653\n",
      "Epoch 164/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0298 - acc: 0.9881 - val_loss: 0.2449 - val_acc: 0.9373\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.11653\n",
      "Epoch 165/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0396 - acc: 0.9881 - val_loss: 0.1977 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.11653\n",
      "Epoch 166/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0421 - acc: 0.9836 - val_loss: 0.1830 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.11653\n",
      "Epoch 167/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0202 - acc: 0.9932 - val_loss: 0.1642 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.11653\n",
      "Epoch 168/300\n",
      "1768/1768 [==============================] - 1s 486us/step - loss: 0.0233 - acc: 0.9921 - val_loss: 0.2029 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.11653\n",
      "Epoch 169/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0269 - acc: 0.9898 - val_loss: 0.2110 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.11653\n",
      "Epoch 170/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0274 - acc: 0.9893 - val_loss: 0.2226 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.11653\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0278 - acc: 0.9904 - val_loss: 0.1889 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.11653\n",
      "Epoch 172/300\n",
      "1768/1768 [==============================] - 1s 490us/step - loss: 0.0228 - acc: 0.9910 - val_loss: 0.1987 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.11653\n",
      "Epoch 173/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0369 - acc: 0.9893 - val_loss: 0.1822 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.11653\n",
      "Epoch 174/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0269 - acc: 0.9904 - val_loss: 0.1949 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.11653\n",
      "Epoch 175/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0292 - acc: 0.9887 - val_loss: 0.1568 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.11653\n",
      "Epoch 176/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0229 - acc: 0.9898 - val_loss: 0.2235 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.11653\n",
      "Epoch 177/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0441 - acc: 0.9830 - val_loss: 0.1647 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.11653\n",
      "Epoch 178/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0480 - acc: 0.9859 - val_loss: 0.2249 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.11653\n",
      "Epoch 179/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0445 - acc: 0.9864 - val_loss: 0.2228 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.11653\n",
      "Epoch 180/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0397 - acc: 0.9864 - val_loss: 0.1926 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.11653\n",
      "Epoch 181/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0369 - acc: 0.9864 - val_loss: 0.1773 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.11653\n",
      "Epoch 182/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0201 - acc: 0.9932 - val_loss: 0.2042 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.11653\n",
      "Epoch 183/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0272 - acc: 0.9904 - val_loss: 0.1848 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.11653\n",
      "Epoch 184/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0309 - acc: 0.9910 - val_loss: 0.1686 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.11653\n",
      "Epoch 185/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0312 - acc: 0.9887 - val_loss: 0.1572 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.11653\n",
      "Epoch 186/300\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.0349 - acc: 0.9853 - val_loss: 0.1603 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.11653\n",
      "Epoch 187/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0261 - acc: 0.9881 - val_loss: 0.1998 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.11653\n",
      "Epoch 188/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0247 - acc: 0.9910 - val_loss: 0.1947 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.11653\n",
      "Epoch 189/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0257 - acc: 0.9893 - val_loss: 0.2289 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.11653\n",
      "Epoch 190/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0331 - acc: 0.9842 - val_loss: 0.1685 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.11653\n",
      "Epoch 191/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0319 - acc: 0.9904 - val_loss: 0.1486 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.11653\n",
      "Epoch 192/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0408 - acc: 0.9864 - val_loss: 0.2010 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.11653\n",
      "Epoch 193/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0262 - acc: 0.9893 - val_loss: 0.2033 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.11653\n",
      "Epoch 194/300\n",
      "1768/1768 [==============================] - 1s 487us/step - loss: 0.0285 - acc: 0.9904 - val_loss: 0.2004 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.11653\n",
      "Epoch 195/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0301 - acc: 0.9887 - val_loss: 0.2173 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.11653\n",
      "Epoch 196/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0185 - acc: 0.9921 - val_loss: 0.1613 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.11653\n",
      "Epoch 197/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0233 - acc: 0.9910 - val_loss: 0.1683 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.11653\n",
      "Epoch 198/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0258 - acc: 0.9926 - val_loss: 0.1911 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.11653\n",
      "Epoch 199/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0251 - acc: 0.9915 - val_loss: 0.1993 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.11653\n",
      "Epoch 200/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0268 - acc: 0.9926 - val_loss: 0.1528 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.11653\n",
      "Epoch 201/300\n",
      "1768/1768 [==============================] - 1s 485us/step - loss: 0.0275 - acc: 0.9898 - val_loss: 0.1998 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.11653\n",
      "Epoch 202/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0248 - acc: 0.9915 - val_loss: 0.2204 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.11653\n",
      "Epoch 203/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0410 - acc: 0.9842 - val_loss: 0.1620 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.11653\n",
      "Epoch 204/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0344 - acc: 0.9881 - val_loss: 0.1885 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.11653\n",
      "Epoch 205/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0434 - acc: 0.9870 - val_loss: 0.2114 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.11653\n",
      "Epoch 206/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0334 - acc: 0.9881 - val_loss: 0.2021 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.11653\n",
      "Epoch 207/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.2482 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.11653\n",
      "Epoch 208/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0432 - acc: 0.9836 - val_loss: 0.2023 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.11653\n",
      "Epoch 209/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0232 - acc: 0.9932 - val_loss: 0.2931 - val_acc: 0.9271\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.11653\n",
      "Epoch 210/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0226 - acc: 0.9910 - val_loss: 0.2145 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.11653\n",
      "Epoch 211/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0248 - acc: 0.9904 - val_loss: 0.2366 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 0.11653\n",
      "Epoch 212/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0282 - acc: 0.9910 - val_loss: 0.1656 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.11653\n",
      "Epoch 213/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0351 - acc: 0.9893 - val_loss: 0.1504 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.11653\n",
      "Epoch 214/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0316 - acc: 0.9893 - val_loss: 0.2519 - val_acc: 0.9390\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.11653\n",
      "Epoch 215/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0391 - acc: 0.9859 - val_loss: 0.2269 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.11653\n",
      "Epoch 216/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0400 - acc: 0.9847 - val_loss: 0.1717 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 0.11653\n",
      "Epoch 217/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0301 - acc: 0.9893 - val_loss: 0.2228 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.11653\n",
      "Epoch 218/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.1936 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.11653\n",
      "Epoch 219/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0288 - acc: 0.9910 - val_loss: 0.1885 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.11653\n",
      "Epoch 220/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0289 - acc: 0.9898 - val_loss: 0.2355 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.11653\n",
      "Epoch 221/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0259 - acc: 0.9915 - val_loss: 0.1877 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.11653\n",
      "Epoch 222/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0178 - acc: 0.9932 - val_loss: 0.2099 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.11653\n",
      "Epoch 223/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0216 - acc: 0.9926 - val_loss: 0.2293 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.11653\n",
      "Epoch 224/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0214 - acc: 0.9915 - val_loss: 0.1798 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.11653\n",
      "Epoch 225/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0475 - acc: 0.9864 - val_loss: 0.2005 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.11653\n",
      "Epoch 226/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0168 - acc: 0.9949 - val_loss: 0.2073 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.11653\n",
      "Epoch 227/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0332 - acc: 0.9893 - val_loss: 0.2070 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.11653\n",
      "Epoch 228/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0242 - acc: 0.9904 - val_loss: 0.1889 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.11653\n",
      "Epoch 229/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0231 - acc: 0.9898 - val_loss: 0.1974 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.11653\n",
      "Epoch 230/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0154 - acc: 0.9960 - val_loss: 0.2559 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.11653\n",
      "Epoch 231/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0247 - acc: 0.9910 - val_loss: 0.1834 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.11653\n",
      "Epoch 232/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0349 - acc: 0.9887 - val_loss: 0.2458 - val_acc: 0.9407\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.11653\n",
      "Epoch 233/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0252 - acc: 0.9904 - val_loss: 0.1917 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.11653\n",
      "Epoch 234/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0401 - acc: 0.9864 - val_loss: 0.2206 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.11653\n",
      "Epoch 235/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0249 - acc: 0.9898 - val_loss: 0.2033 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.11653\n",
      "Epoch 236/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0307 - acc: 0.9870 - val_loss: 0.1532 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.11653\n",
      "Epoch 237/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0206 - acc: 0.9932 - val_loss: 0.2085 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 0.11653\n",
      "Epoch 238/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0333 - acc: 0.9859 - val_loss: 0.1824 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.11653\n",
      "Epoch 239/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0237 - acc: 0.9926 - val_loss: 0.2079 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.11653\n",
      "Epoch 240/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0186 - acc: 0.9932 - val_loss: 0.2312 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.11653\n",
      "Epoch 241/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0319 - acc: 0.9864 - val_loss: 0.3400 - val_acc: 0.9288\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.11653\n",
      "Epoch 242/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0146 - acc: 0.9943 - val_loss: 0.1834 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 0.11653\n",
      "Epoch 243/300\n",
      "1768/1768 [==============================] - 1s 485us/step - loss: 0.0347 - acc: 0.9915 - val_loss: 0.2189 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.11653\n",
      "Epoch 244/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0332 - acc: 0.9904 - val_loss: 0.2468 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.11653\n",
      "Epoch 245/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0217 - acc: 0.9938 - val_loss: 0.1899 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.11653\n",
      "Epoch 246/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0436 - acc: 0.9853 - val_loss: 0.1670 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 0.11653\n",
      "Epoch 247/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0346 - acc: 0.9898 - val_loss: 0.1689 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.11653\n",
      "Epoch 248/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0210 - acc: 0.9921 - val_loss: 0.1887 - val_acc: 0.9424\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.11653\n",
      "Epoch 249/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0180 - acc: 0.9938 - val_loss: 0.1844 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.11653\n",
      "Epoch 250/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0349 - acc: 0.9898 - val_loss: 0.1679 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.11653\n",
      "Epoch 251/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0202 - acc: 0.9915 - val_loss: 0.1905 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.11653\n",
      "Epoch 252/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0297 - acc: 0.9887 - val_loss: 0.2123 - val_acc: 0.9441\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.11653\n",
      "Epoch 253/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0278 - acc: 0.9915 - val_loss: 0.1808 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.11653\n",
      "Epoch 254/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0205 - acc: 0.9938 - val_loss: 0.1878 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.11653\n",
      "Epoch 255/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0264 - acc: 0.9876 - val_loss: 0.2311 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.11653\n",
      "Epoch 256/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0265 - acc: 0.9910 - val_loss: 0.2511 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.11653\n",
      "Epoch 257/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0243 - acc: 0.9915 - val_loss: 0.2018 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.11653\n",
      "Epoch 258/300\n",
      "1768/1768 [==============================] - 1s 489us/step - loss: 0.0287 - acc: 0.9893 - val_loss: 0.1916 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.11653\n",
      "Epoch 259/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0220 - acc: 0.9938 - val_loss: 0.1907 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.11653\n",
      "Epoch 260/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0187 - acc: 0.9915 - val_loss: 0.2409 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.11653\n",
      "Epoch 261/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0153 - acc: 0.9949 - val_loss: 0.2020 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.11653\n",
      "Epoch 262/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0233 - acc: 0.9926 - val_loss: 0.2098 - val_acc: 0.9458\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.11653\n",
      "Epoch 263/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0263 - acc: 0.9921 - val_loss: 0.1824 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.11653\n",
      "Epoch 264/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0209 - acc: 0.9960 - val_loss: 0.1953 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.11653\n",
      "Epoch 265/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0253 - acc: 0.9898 - val_loss: 0.2086 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.11653\n",
      "Epoch 266/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0280 - acc: 0.9921 - val_loss: 0.1950 - val_acc: 0.9627\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.11653\n",
      "Epoch 267/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0211 - acc: 0.9932 - val_loss: 0.1768 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.11653\n",
      "Epoch 268/300\n",
      "1768/1768 [==============================] - 1s 483us/step - loss: 0.0224 - acc: 0.9915 - val_loss: 0.1796 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.11653\n",
      "Epoch 269/300\n",
      "1768/1768 [==============================] - 1s 488us/step - loss: 0.0266 - acc: 0.9926 - val_loss: 0.1903 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.11653\n",
      "Epoch 270/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0260 - acc: 0.9881 - val_loss: 0.1857 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.11653\n",
      "Epoch 271/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0281 - acc: 0.9870 - val_loss: 0.1887 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.11653\n",
      "Epoch 272/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0274 - acc: 0.9904 - val_loss: 0.1554 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.11653\n",
      "Epoch 273/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0334 - acc: 0.9898 - val_loss: 0.1363 - val_acc: 0.9661\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.11653\n",
      "Epoch 274/300\n",
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0357 - acc: 0.9904 - val_loss: 0.2254 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.11653\n",
      "Epoch 275/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0315 - acc: 0.9893 - val_loss: 0.1636 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.11653\n",
      "Epoch 276/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0161 - acc: 0.9932 - val_loss: 0.2139 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.11653\n",
      "Epoch 277/300\n",
      "1768/1768 [==============================] - 1s 481us/step - loss: 0.0264 - acc: 0.9893 - val_loss: 0.2269 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.11653\n",
      "Epoch 278/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0328 - acc: 0.9881 - val_loss: 0.1372 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.11653\n",
      "Epoch 279/300\n",
      "1768/1768 [==============================] - 1s 474us/step - loss: 0.0244 - acc: 0.9938 - val_loss: 0.1553 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.11653\n",
      "Epoch 280/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0268 - acc: 0.9893 - val_loss: 0.2099 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.11653\n",
      "Epoch 281/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.2133 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.11653\n",
      "Epoch 282/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0225 - acc: 0.9910 - val_loss: 0.2162 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.11653\n",
      "Epoch 283/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0200 - acc: 0.9943 - val_loss: 0.1972 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 0.11653\n",
      "Epoch 284/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0135 - acc: 0.9938 - val_loss: 0.2100 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 0.11653\n",
      "Epoch 285/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0319 - acc: 0.9910 - val_loss: 0.2031 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 0.11653\n",
      "Epoch 286/300\n",
      "1768/1768 [==============================] - 1s 479us/step - loss: 0.0129 - acc: 0.9977 - val_loss: 0.1684 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.11653\n",
      "Epoch 287/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0319 - acc: 0.9876 - val_loss: 0.1882 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 0.11653\n",
      "Epoch 288/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0312 - acc: 0.9898 - val_loss: 0.1897 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.11653\n",
      "Epoch 289/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0345 - acc: 0.9893 - val_loss: 0.1663 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.11653\n",
      "Epoch 290/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0188 - acc: 0.9915 - val_loss: 0.1832 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.11653\n",
      "Epoch 291/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0279 - acc: 0.9932 - val_loss: 0.1853 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.11653\n",
      "Epoch 292/300\n",
      "1768/1768 [==============================] - 1s 475us/step - loss: 0.0273 - acc: 0.9898 - val_loss: 0.1671 - val_acc: 0.9593\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.11653\n",
      "Epoch 293/300\n",
      "1768/1768 [==============================] - 1s 476us/step - loss: 0.0216 - acc: 0.9932 - val_loss: 0.1734 - val_acc: 0.9576\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 0.11653\n",
      "Epoch 294/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0373 - acc: 0.9881 - val_loss: 0.2129 - val_acc: 0.9508\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.11653\n",
      "Epoch 295/300\n",
      "1768/1768 [==============================] - 1s 478us/step - loss: 0.0487 - acc: 0.9847 - val_loss: 0.2161 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.11653\n",
      "Epoch 296/300\n",
      "1768/1768 [==============================] - 1s 482us/step - loss: 0.0214 - acc: 0.9898 - val_loss: 0.2368 - val_acc: 0.9356\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.11653\n",
      "Epoch 297/300\n",
      "1768/1768 [==============================] - 1s 484us/step - loss: 0.0247 - acc: 0.9921 - val_loss: 0.1945 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.11653\n",
      "Epoch 298/300\n",
      "1768/1768 [==============================] - 1s 485us/step - loss: 0.0251 - acc: 0.9910 - val_loss: 0.2070 - val_acc: 0.9525\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.11653\n",
      "Epoch 299/300\n",
      "1768/1768 [==============================] - 1s 480us/step - loss: 0.0204 - acc: 0.9926 - val_loss: 0.1911 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.11653\n",
      "Epoch 300/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1768/1768 [==============================] - 1s 477us/step - loss: 0.0238 - acc: 0.9938 - val_loss: 0.2148 - val_acc: 0.9492\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 0.11653\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.8CL.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "history8=model8.fit(train_tensors, train_labels, \n",
    "          validation_data=(valid_tensors, val_labels),\n",
    "          epochs=300, batch_size=30, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 95.2542%\n"
     ]
    }
   ],
   "source": [
    "model8.load_weights('weights.8CL.hdf5')\n",
    "model8_pred = [np.argmax(model8.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "test_accuracy_model8 = 100*np.sum(np.array(model8_pred)==np.argmax(test_labels, axis=1))/len(model8_pred)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy_model8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4.5: Model training analysis.** <br>\n",
    "To check whether the number of epoch has been selected properly and that there is no sign of overfitting for our model, the training history for validaiton and train sets has been analyzed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training history for model 6\n",
    "#accuracy\n",
    "plt.plot(history6.history['acc'])\n",
    "plt.plot(history6.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXd4VFX6+D/vpPdOSQKEHjqEZsMCFqq9lxUbrmXVXf3tWva7uu66u+666rq69t4Vu2ABBQVFWugQeksCIQFCej+/P87cZDKZTEkySYDzeZ55ZubW987ce95z3nZEKYXBYDAYDO6wdbQABoPBYOj8GGVhMBgMBo8YZWEwGAwGjxhlYTAYDAaPGGVhMBgMBo8YZWEwGAwGjxhlYTAAIvKaiPzVy213iciZ/pbJYOhMGGVhMBgMBo8YZWEwHEOISGBHy2A4NjHKwnDUYDf//D8RWSsipSLysoh0FZGvRKRYROaLSJzD9ueKyAYRKRSRhSIyyGHdKBHJtO/3PhDqdK7pIrLavu/PIjLcSxmnicgqESkSkb0i8pDT+lPsxyu0r59pXx4mIv8Wkd0ickREFtuXnS4i2S5+hzPtnx8Skdki8paIFAEzRWSciCyxn2OfiDwtIsEO+w8RkXkickhE8kTkfhHpJiJlIpLgsF2GiOSLSJA31244tjHKwnC0cRFwFjAAmAF8BdwPJKHv5zsARGQA8C5wl33dXOALEQm2N5yfAm8C8cCH9uNi33cU8ApwM5AAPA98LiIhXshXCvwKiAWmAbeIyPn24/ayy/tfu0wjgdX2/R4DRgMn2WX6PVDn5W9yHjDbfs63gVrgt0AicCIwCbjVLkMUMB/4GkgG+gHfKaX2AwuBSx2Oew3wnlKq2ks5DMcwRlkYjjb+q5TKU0rlAIuApUqpVUqpCuATYJR9u8uAOUqpefbG7jEgDN0YnwAEAU8qpaqVUrOB5Q7nmAU8r5RaqpSqVUq9DlTa93OLUmqhUmqdUqpOKbUWrbBOs6++EpivlHrXft6DSqnVImIDrgfuVErl2M/5s1Kq0svfZIlS6lP7OcuVUiuVUr8opWqUUrvQys6SYTqwXyn1b6VUhVKqWCm11L7udeBqABEJAK5AK1SDwSgLw1FHnsPnchffI+2fk4Hd1gqlVB2wF0ixr8tRjato7nb43Au4227GKRSRQqCHfT+3iMh4EVlgN98cAX6N7uFjP8Z2F7slos1grtZ5w14nGQaIyJcist9umvqbFzIAfAYMFpHe6NHbEaXUshbKZDjGMMrCcKySi270ARARQTeUOcA+IMW+zKKnw+e9wCNKqViHV7hS6l0vzvsO8DnQQykVAzwHWOfZC/R1sU8BUNHMulIg3OE6AtAmLEecS0c/C2QB/ZVS0WgznaMMfVwJbh+dfYAeXVyDGVUYHDDKwnCs8gEwTUQm2R20d6NNST8DS4Aa4A4RCRKRC4FxDvu+CPzaPkoQEYmwO66jvDhvFHBIKVUhIuPQpieLt4EzReRSEQkUkQQRGWkf9bwCPC4iySISICIn2n0kW4BQ+/mDgD8CnnwnUUARUCIi6cAtDuu+BLqLyF0iEiIiUSIy3mH9G8BM4FyMsjA4YJSF4ZhEKbUZ3UP+L7rnPgOYoZSqUkpVAReiG8VDaP/Gxw77rgBuAp4GDgPb7Nt6w63AwyJSDPwJrbSs4+4BpqIV1yG0c3uEffU9wDq07+QQ8ChgU0odsR/zJfSoqBRoFB3lgnvQSqoYrfjed5ChGG1imgHsB7YCZzis/wntWM9USjma5gzHOWImPzIYDI6IyPfAO0qplzpaFkPnwSgLg8FQj4iMBeahfS7FHS2PofNgzFAGgwEAEXkdnYNxl1EUBmfMyMJgMBgMHjEjC4PBYDB45JgpOpaYmKjS0tI6WgyDwWA4qli5cmWBUso5d6cJx4yySEtLY8WKFR0thsFgMBxViIhXIdLGDGUwGAwGjxhlYTAYDAaPGGVhMBgMBo8cMz4LV1RXV5OdnU1FRUVHi3LMEBoaSmpqKkFBZj4cg+F44phWFtnZ2URFRZGWlkbjAqOGlqCU4uDBg2RnZ9O7d++OFsdgMLQjfjNDicgrInJARNY3s15E5CkR2SZ6mswMh3XXishW++valspQUVFBQkKCURRthIiQkJBgRmoGw3GIP30WrwGT3ayfAvS3v2aha/AjIvHAg8B4dNnoB8VhXmVfMYqibTG/p8FwfOI3M5RS6kcRSXOzyXnAG/bZyn4RkVgR6Q6cDsxTSh0CEJF5aKXjzcQzraa6po7DZVXUOVRBCbQJCZHBbd5Q1tUpDpdVERcRjK0Fxy6uqCbQJoQFd25r4vqcI2w7UML5o1I6WhS/oZRi4ZZ8QgJsnNQv0fMOnYicwnI+WplNTW3zU36f0DeBk/oeXdflT7bmFTN33X5q6xp+s/Tu0Uwd1r0DpfIvHdnKpNB4Oshs+7LmljdBRGahRyX07NnT1SZeU1NbR35JJQdLqqhzUS8rKFCICQv2+biFhYW888473HrrrU3WHS6rIqewHBEhPqLxsadOnco777xDbGysy+PW1il2HywjKMDGgK6RnbLHv7OglMe+3cyctfsASI0LY0xafAdL1fYs33WIf3yVxcrdh4kKDWT5A2cSGhTQ0WJ5RV5RBZe/sIS9h8pp7hZSCp5ZuJ0XrhnNpEFd21fATkZuYTlPzNvCR5nZ1CnqfzOryXjnxvFHXWfBWzp3l9QDSqkXgBcAxowZ06KKiHV1ioLSSvKLK6mtU8SFB9M1OoTgwADrHGzOKya/uJLo0CCfG+XCwkL+97//NVEWNTU1HC6rBuBwaVUTZTF37ly3xz1SXk2dUlTW1FJUUUNMmG/RSTV1dZRU1BAdGoTN1vialFKUVtZQXt24pxkdGkiIF43ggeIKnvpuK+8t20twoI3bz+jH20t389wP23nJC2WxdMdB0hIj6Bod6tM1tYQFWQfYnl9S/z0owMa5I5KJi/DcMdh7qIyHPt/Ad1kH6BodwsyT0njt513M25jHjBFNp+v+YUs+A7tG0S3G/9flDYdLq7j6paUcKqnis9tOZkQP1x2T4opqrnppKbe+ncnr14/jhD4JzR6zuraO77MOMDG9C0EB/o3Mr7Gf67SBSYQEtl45u/t/qmrq+Pe3m3n1512g4PqTe3PrGf3qn9uK6lrOefJH/vjpeubeOaFNOwuHSqvI3H2YSYO6dGinsCOVRQ56TmSLVPuyHLQpynH5Qn8JUVOnyCuqJDIkkG7RoYQFN/6TRYSkyBByCssprawhMtS3Rvnee+9l+/btjBw5kqCgIEJDQ4mLi2PTpiw+WrCM3914Nbm52VBTzV133cmsWbOAhvIlJSUlTJkyhVNOOYWff/6ZlJQUPvvsMw6X1RISaEOBXZEF+nQjFRRXcaC4gqAAG12jQ4kL14qwrKqG/UcqKKmsabLPkfIA+iZFNnvMoopqXvhhBy8v3kl1bR1Xju/Jbyb2JykqhMAA4cn5W9m8v5iB3ZqfnfSD5Xv5/UdrOXdEMk9dMcrr62kJew6WccPryxuZHAHeX76Xd2ed4FYB5xaWc9nzSyiuqOEPk9OZeVIaIYE2vt2wn9krs5soi20HSpj56jImpXfhpWvH+uNyfKKksoaZry5j96EyXrtubLOKAiAqNIjXrhvHpc8v4cbXV/DOTeMZntp0+7o6xe9nr+WTVTn85fyhXHNCLxdHazue/3EH//pmMzef2of7pg5q1bHeWLKLP322geGpMXxy68kEOHWgnl6wjed/3MFFGan87uwBpMSGNVofGhTAX84byq9eWcazC7fz27MGtEoei8KyKq588Rey9hfzzJUZTBvecWaujlQWnwO3i8h7aGf2EaXUPhH5Bvibg1P7bOC+1p7sz19sYGNukct1SimPDW1ZVS02oVGPYXByNA/OGOK0XQ02kfrt/vGPf7B+/XpWr17NwoULmTZtGuvXryc0vhsFxVW89torHKoJJipQMePMCVx00UUkJDTuuW3dupV3332XF198kUsvvZT3P/iQjEnn0i06lACb2BVZLZGh3v+dJZU1hAQGEGCD7MNlFBQHEBJk40h5NYE2G8mxYcSGBdUPsw+XVZNrV5jO1NUpXvt5F//9fiuHy6qZMSKZu88aQFpiRP02156YxvM/7OD5H7fz+KUjXcr01bp93PvxWmwCy3Yecvm/KKWYu25/IzniIoI5swW9rhcX7SDQZuPb355KQqTuIS7fdYib31zJDa8t580bxjfpPAAUlFRy9ctLKa6s4b2bT2BIckz9ugszUvnfwm3kFVU0Ghm98ON2lIL5mw6wJa+YAV29mc67gT0HyzhQXNGsGW99zhHiIoKbNGKg/5/vsg5wuLSqftnHq7JZn1vEc1eP9soXER8RzJs3jOPiZ5dw7SvLeOvG8Y2uWynFQ19s4JNVOfVKs7XKQinFku0H6ZMU2aS3v+dgGU99t5Xw4ABeWryT80elMKh7dKNtDpVW8X3WAeocegNpiRGM6934N/x0VQ5/+mwD/btEsjb7CG8u2cXMkxtCw7cdKOG5hds5b2Qy/750BM1x6oAkzh2RzLMLt3PuyGS3HStvKK2s4brXlrMjv5ReCeH8+YsNTBiQSLSPHda2wm/KQkTeRY8QEkUkGx3hFASglHoOmIuej3gbUAZcZ193SET+gp6LGOBhy9ntR1k9bhMUIFTV1FGnlEtndHlVDfsceuSxYcF0jQlpst24ceNIS0sja38xUaGBvPT0E7z/4UcoYF/2XrZu3dpEWfTu3ZuRI3UDO3r0aLK27SBjEsSGBxNoE/KKKskvqfRaWdTU1lFeVUOX6FC6RIVQVF7N/qJKiitq6BodSmJkSJOeVXx4MAeKKjlQXNnkeO+v2MvDX25kQv9E/jA5naEpMU22iYsI5vJxPXhzyW7uPntgk0Zt0dZ87nxvNaN6xnHmoK48+nUWOYXlpMaFN9rup20Hue2dzCbHv2lCb+6fOshrhVFQUskHK/ZywaiURkptYnpXnrxsFL95N5Nfv7WSF381huDABnNKUUU1176yjNzCct66oXGDCXDR6FSeXrCNT1bl8OvT+gKw/0gFn6zK4dwRyczbmMdzPzSvMJ1xNOnVKsWTl43kvJGNXXgLNh/gptdXEBsezOxfn9joepRSPDJ3Ey8v3tlonwCb8K+Lh3PWYO99EN1jwnj7xvFc8vwSZvx3MZeM7sFdZ/Wne0wY//52C28s2c2sU/sgwCs/7aSoorrFDdvSHQd59OssMvcUkhIbxuxbTqR7TFj9Nf3xs/UEBdiYfcuJXPXiUu77eB0f33JSvUn1UGkVlz6/hG0HSpoc++R+CfxhcjrDU2OZvzGPuz9cw4l9Enj1urHMenMlj327hclDu9MtJhSlFA98so7QIBt/nDbYo9x/nD6IhZsP8MAn63j3phNabDaqrKnl12+tZM3eQv531WiSY0M5/5mfeOybzTx83tAWHbO1+DMa6goP6xVwWzPrXgFeaUt5nEcAvlJbV0fWPt3A90xoeBgra2rJO1JJYXkVATahe0wotXWKgpIqjpRXU1rUOCchIiKCksoaqmvr2L5mKfPnz+e7HxZRUAG3XXmeyxyGkJAGpWOz2Sgp12YzqxFLjAxmf1EF5VU1XkVGlVbVoIDIEG26igkPJtpucmnu5rbZhMSoYPYfqUDVNPgy8osr+fvcTYzvHc8b149z+3DcOKEPby7ZzUuLdjT6P5btPMSsN1bSJymCV64dS3ZhGY9+DSt2HW6iLBZtzScoQPj2t6fVX/8LP2znxUU7iQkL4vaJ/T1eP8BrP+2iqraOWaf1abJu2vDuFFcM496P13HHu6s4f1SDSenlxTvZklfMi78a47KX3zsxgjG94pi9MpubT+2DiPDy4h3UKfh/5wwkITK4WYXpiLNJ7/JxPdiSV8LdH6whKjSQield63+7W95aSb8ukRworuSql5Y2alj/+/02Xl68k5knpXHTqQ3XGhEcQGy47wEbaYkRfH3nBJ5ZsJ23ftnNp6tzmNA/kfmbDnD52B7cNyWdzD2Hef7HHSzcnM+5Lnw37th2oIRH5mxkweZ8ukaHcM/ZA3juhx1c/dJSPrj5RBIiQ/hi7T5+3JLPgzMGk94tmj9OH8Rv31/D28v2cM0JvSi2K/S9h8p4deZYBtjNnkopvt2Qx9MLtnHu0z8xKb0Li7YVMDQ5mhevHUNoUAB/PW8oZz3xA3/+YgPPXj2ajzJzWLrzEH+7YBhJUU07f850iQrlD1PSeeCT9TwxfyuDu7seQYoIJ/VNIMqFMq2prePOd1ezaGsBj10ygslDuwHwqxPTeH3JLi7MSGWkG7OhvziqHdztSYDNRnxkMAXFlVTW1GIT4UBRJYdKqxDRN0lSVDABNt2AJUSGkFdUQeHhEA4XFjUKSzxcWk2ATaiuKCUuLo5u8TGsXLSC5cuWepSjqlZpR7yDAzY+Mpj84kryi6vomeD5Ly2p0KYyRxOLNz2ghIhg8osqKXQwAT0yZyPl1bU8csEwj8dIiQ3j3JHJvLdsL3dM7E9JZQ1PzNvCJ6tz6BUfzps3jCcmPIjI0GgiQwJZvutQk3DbxdsKyOgZR2+H3vODM4ZQXFHDY99uISo0iGtPSnN//ZU1vLFkF5OHdGvWVHD5uJ4UV9TwyNxNfL1hf/1ym8BTV4zi9IFdmj3+RaNTue/jdazNPkJaQgTvLN3D9OHd6REf3qzCtKioruWtX3bz9IJtFJZVM314d+45eyBpiREUV1Rz5YtLueUt7WiODAnkhteWkxKre/y5hRVc8eIvXPPyMj64+UQ+W53D4/O2cPHoVP40fXCTQIaWkhAZwp9mDOa6k9N4Yv4WPlmVw7Rh3evvgZE94kiMDOHbDft9UhZFFdVc+eIvVFTX1vuBwoIDGJsWz69eWcbMV5fz3DWjefiLjQxLieFXJ6YBcP7IFGavzOafX2dx+oAk7v5wDZv2FfHCr0ZzRnrj/+n6U3pzyZhUXly0k5cW7aBXfDivXad/S4CeCeHcMak///pmM7NXZvPInI2M7hXH5WN7OIvbLFeM7clnq3N56rutbrcbkhzNu7NOaDT6qqtT3PfxOr7esJ8/TR/MxaNT69fdffYAvlq/j/s/Xsfnt59MoJ8DCJwxysIHEiNDKCipYs/BMipr6lAK4iOC6BId2iTyIyjARmpcODFhqYwYM57BQ4YSExVBly5dKKqoJi4imKlTpvDC888zZMhgevbpx7BRY6h1sK/W1tVRVVPb6LjlVTUINLrBAhspshCPkSEllTVEhgT6nNthKcx9VbXsPljKnkNlfLo6lzsm9qNfF+/ss78+rS8fZ+Yw89VlbNpXjAjMmtCHW0/vR0x4kP08wqiesazcfbjRvodKq9iQW8TdTs5Dm0149OLhFFXU8ODnG4gOC+SCUak0x7tL91BUUVNvJmqOm07tw+Sh3Ro5++PCgz1GM00b3p2HPt/A7JXZdI0OobSqtv5cKbFhnDcypV5hWkq/tk7xcWY2T87fSk5hORP6J/L7c9IZltpg5ooKDeL16xsczcGBNqLDgnjzhvEkRIaQEBnCS9eO4dpXlnHeM4vZe6icc4Z05R8XDmszReFIj/hwHr90JPdNGURCRHD9OQJswlmDu/DFmn1U1tQ2uh9rauvYd6SCHvHhTY732DebKSip5NPbTm7kQB/fJ4Fnr85g1hsrOfvxHyivruW168bWm0pFhL+cN5TJ/1nE5Cd/pKy6licvG1k/+nImKjSI3501gBsn9CbIZmvil7ppQh8+XZXDPR+uIdAm/O0C334/m014+8bxLk1gFlvyirn7gzXc8Npy3rhe+8aUUvx1ziY+XJnNnZP6c/0pjUvqRIUG8dCMIdzydiaPfbuFCf0bfE2RIYFugxTaAqMsfCAowEZ8eBAHS6uICQuiW3Sox1DSqNAg3n3nbfYcKiMiJJDosCByC8uJCw8iJDiQr776CtDOrO35JaTGhVNXp1i2LkuH84YGM+eHpVRW1xIYYOPyG24jNiyoiU/BUmR5RZX0dPEgWlTV1FJZU0dChOchtSsSI0NA4KnvtrFy9yHSEsK59Yx+Xu8/oGsU5wzpyryNeY1s3s6MTYvniflbOFJWXa9EftpWAMAp/Zs6ZIMCbDx95Siue3U5v5+9lqHJMfR34USurKnlpcU7OKlvglcPl6tGzRPRoUFMHtqNz9fkEmgTzhiY1Mj5+uvT+vBRZjavL9nFnZP6M3/TAf71TRZb8koYkRrDvy4e3mysfnxEMG/dMJ6Ln/tZj0JuHE+ygznrBIeG9eR+Cfzn8lF+74G6Ms+cNbgr7y7by5LtBxuNwu7/ZB2zV2bzzJUZTHFIYFu9t5A3f9nNtSemuYy0mpjelccvG8md763i+pN7N/GL9UmK5Ddn9OPf87bw1/OHNvHruKI5f0pwoI2/XTiMy55fwqxT+7iN3muOoABbE4e7I4O6R2MT4Y73VnHL2yt54ZoxPLtwO6/8tJPrTk7jrjNdm1MnD+3GmYO68twP23nuh+31y0f2iOXT2072WU5fMMrCR7rHhpEU1ZCH4Q0x4cGkKB11VFpZQ2hQAGFOSiY8OICQwADyiyvJK6qguraOqNAgwoJsFJRUUVReQnhwAHVKucwBCAqwkRQVwoGiCuLCg1zaQoH6XrIvkVPO5wkPDuCjzGwA3rphvM8x5U9cNpKi8hq3PfQxaXEoBZl7DtebEn7aVkBUaCDDXDjQQUeqPX3lKCY9/gP3f7KO92ed2KRH+OmqHPKKKnnskuajWtqCi0en8tnqXABuOb2xMu3fNYozB3XltZ93sWhrASt3H6ZPYgT/uyqDKUO7eTTndYsJZe6dE6itdX0vTEzvyo+/P4OkqBC/5zo0x0l9EwkPDmDexrx6ZbFk+0E+WJFNVGggd763msjQQCb0T6Kmto77P15Hl6gQ7j67+ZDTc0ckM6ZXHN2ayb+5fWI/Lhyd6tYX5C1j0+JZct8kunjhp2gpM0YkU1JZw30fr+O8Z35i074iLh6dyv9NG9zsPSAiPHt1Bmv2FjYK+Y4I8X8SqJnPwkdsIj4pCov4iGC6x4Sh0KYM55tBRIiLCKKyppagABt9kiLpnRhBt5gwBnaLIj4ymLJqPaQPdxHOCdAlUpugcgvLG4ULOlJSUUNQgI2QwJb/9VEhgQTahPNHJrvs5XsiPDjQoylnZI9YAm3C8l06EE4pxaKtBZzUN8FtTzkhMoT7pqSzfNdhPly5t9G6PQfLeOzbLQxNieYUP2fZntQ3kZTYMEb3imNsWtPSZrec3pfCsmr2HirjbxcM49vfnsrUYd29jp6JDg1ymziYHBvWYYoCtOI+fWAS8zbmUVenk0cf+HQdPeLDmP+70+iTFMGsN1aycvdhXvt5Fxv3FfHQjCHNdnIskmPDmjUJiUibKAqLrtGhfk+Cu2JcT+6fms6mfUVemwyDAmyMSYtnXO+Gl3NUnj8wI4t2JCkqhKjQwGYb6qTIECJDAgkLCmh0kwYF2EiJDSMpUvdy3EUspcSGsqOglAPFlU0aZKUUJZW1RPmYwOdMYICN7+4+rZH5o60JDw5kSEoMK+x+i90Hy8gpLOfXLqKXnLlkdA8+WpnD3+ZmMWlQVxLtwQZXvfwL1bV1PH7pSL83AgE24f2bT2jyX1qM7hXH3Dsm0DsxwmUux7HAWYO7MnfdftZkF7JoawE78kt57bqxdI0O5c0bxnPJcz9z3avLqKlTTErvUh/1c7wx69S+nNIvif5dI9vdae0LnVeyY5TQZhoP0EogPLj5hjw40NYo5t8VkaFBxIUHk19SSUV1Y+d4RXUtNXV19ZEfraFXQoTfe65jesWxZm8hlTW1LLb7K072YkRgswmPXDCUsqoa/jZnE4dLq7jmZV3W4rXrxvmcENdSUuPCSYhs3owxODn6mFUUABMHdiXAJry4aAdPL9jG9OHd601SSVEhvHXjeCJCAlEK/nzekE5Z36y9GJwc3aEjQW8wI4tjkG4xoRRVVJNzuJw+SRH1D2Fr/RXtzdi0OF5evJP1OUUs3lpASmxYo5BZd/TvGsXNp/bl6QXbWLW3kJzCcl6bObZD4tOPV2LCgzihTzxz1+0nKjSQP01vnNSWGhfOZ7efTGFZdZN8GkPno3OrMkOLCAqw0T0mlNKqGnYdLKPcPsIorqghNDCg0/dgLEb30klvS3ce5OftBZzcz7eJrG6f2I9eCeHsOVTG01eMOmargXZmzh6sTUu/n5xOFxeO6S5Roe020jO0jqOj1TiOiIzU+Qq5ublcfPHFLrc5/fTTWbFihdvjvP7C/4gJqqOsqoatecVMPOsc9ucfPGpGFaBNFb0TI3j7F50XcUr/JJ/2Dw0K4K0bxvPhr0/k7CHHpz28o7lsbA+eu3o0V41r3RQCho7HKItOSnJyMrNnz27x/v/5z3+ICKhjYNcokqJCeOq1D4iMjmkTf0V7MqZXHDmF5QCc1Lf50tjN0SM+nIyeLZ5o0dBKQoMCmDy0m1+SAg3ti1EWfubee+/lmWeeqf/+0EMP8de//pVJkyaRkZHBsGHD+Oyzz5rst2vXLoYO1QXDysvLufzyyxk0aBAXXHAB5eXl9dvdcsstjBkzhiFDhvDggw8C8NRTT5Gbm8sZZ5zBWWdOontMGNNPHkFYbRlRoYE8/vjjDB06lKFDh/Lkk0/Wn2/QoEHcdNNNDBkyhLPPPrvReTqKsfb6S4O6R+uEQIPB0CEcXd3M1vDVvbB/Xdses9swmPIPt5tcdtll3HXXXdx2m66Z+MEHH/DNN99wxx13EB0dTUFBASeccALnnntus/b4Z599lvDwcDZt2sTatWvJyMioX/fII48QHx9PbW0tkyZNYu3atdxxxx08/vjjLFiwgMTEBjt9XEQwmZmZvPrqqyxduhSlFOPHj+e0004jLi6uSSn0jz76iKuvvroNfqiWM8aeo3BKP99HFQaDoe0wIws/M2rUKA4cOEBubi5r1qzRhQO7deP+++9n+PDhnHnmmeTk5JCXl9fsMX788cf6Rnv48OEMHz68ft0HH3xARkYGo0aNYsOGDWzcuNGtPIsXL+aCCy4gIiKCyMhILrzwQhYtWgQ0LYW+a9euVl596+mdGMHfLxzGTRM851f+HhGoAAAgAElEQVQYDAb/cfyMLDyMAPzJJZdcwuzZs9m/fz+XXXYZb7/9Nvn5+axcuZKgoCDS0tJclib3xM6dO3nsscdYvnw5cXFxzJw5s0XHsXAshR4QENApzFAiwhXGOWowdDhmZNEOXHbZZbz33nvMnj2bSy65hCNHjtClSxeCgoJYsGABu3fvdrv/qaeeyjvvvAPA+vXrWbt2LQBFRUVEREQQExNDXl5efVFCgKioKIqLi5sca8KECXz66aeUlZVRWlrKJ598woQJE9rwag0Gw7HI8TOy6ECGDBlCcXExKSkpdO/enauuuooZM2YwbNgwxowZQ3p6utv9b7nlFq677joGDRrEoEGDGD16NAAjRoxg1KhRpKen06NHD04+uaHq5KxZs5g8eTLJycksWLCgfnlGRgYzZ85k3LhxANx4442MGjWqU5icDAZD50X0hHVHP2PGjFHOuQebNm1i0KDWTeRuaIr5XQ2GYwcRWamUGuNpO2OGMhgMBoNHjLIwGAwGg0eOeWVxrJjZOgvm9zQYjk+OaWURGhrKwYMHTQPXRiilOHjwIKGh7icuMhgMxx7HdDRUamoq2dnZ5Ofnd7QoxwyhoaGkpqZ2tBgGg6GdOaaVRVBQEL179+5oMQwGg+Go55g2QxkMBoOhbTDKwmAwGAweMcrCYDAYDB4xysJgMBgMHvGrshCRySKyWUS2ici9Ltb3EpHvRGStiCwUkVSHdY+KyHr76zJ/ymkwGAwG9/hNWYhIAPAMMAUYDFwhIoOdNnsMeEMpNRx4GPi7fd9pQAYwEhgP3CMi0f6S1WAwGAzu8efIYhywTSm1QylVBbwHnOe0zWDge/vnBQ7rBwM/KqVqlFKlwFpgsh9lNRgMBoMb/KksUoC9Dt+z7cscWQNcaP98ARAlIgn25ZNFJFxEEoEzgB7OJxCRWSKyQkRWmMQ7g8Fg8B8d7eC+BzhNRFYBpwE5QK1S6ltgLvAz8C6wBKh13lkp9YJSaoxSakxSUlI7im0wGAzHF/5UFjk0Hg2k2pfVo5TKVUpdqJQaBTxgX1Zof39EKTVSKXUWIMAWP8pqMBgMBjf4U1ksB/qLSG8RCQYuBz533EBEEkXEkuE+4BX78gC7OQoRGQ4MB771o6wGg8FgcIPfakMppWpE5HbgGyAAeEUptUFEHgZWKKU+B04H/i4iCvgRuM2+exCwSEQAioCrlVI1/pLVYDAYDO45pqdVNRgMBoN7zLSqBoPBYGgzjLIwGAwGg0eMsjAYDAaDR4yyMBgMBoNHjLIwGAwGg0eMsjAYDAaDR4yyMBgMBoNHjLIwGAwGg0eMsjAYDAaDR4yyMBgMBoNHjLIwGAwGg0eMsjAYDAaDR4yyMBgMBoNHjLIwGAwGg0eMsjAYDAaDR4yyMBgMBoNHjLIwGAwGg0eMsjAYDAaDR4yyMBgMBoNHjLIwGAwGg0eMsjAYDAaDR4yyMBgMBoNHjLIwGAwGg0eMsjAYDAaDR4yyMBgMBoNHjLIwGAwGg0eMsjAYDAaDR/yqLERksohsFpFtInKvi/W9ROQ7EVkrIgtFJNVh3T9FZIOIbBKRp0RE/CmrwWAwGJrHb8pCRAKAZ4ApwGDgChEZ7LTZY8AbSqnhwMPA3+37ngScDAwHhgJjgdP8JavBYDAY3OPPkcU4YJtSaodSqgp4DzjPaZvBwPf2zwsc1isgFAgGQoAgIM+PshoMBoPBDf5UFinAXofv2fZljqwBLrR/vgCIEpEEpdQStPLYZ399o5Ta5HwCEZklIitEZEV+fn6bX4DBYDAYNB3t4L4HOE1EVqHNTDlArYj0AwYBqWgFM1FEJjjvrJR6QSk1Rik1JikpqT3lNhgMhuOKQD8eOwfo4fA91b6sHqVULvaRhYhEAhcppQpF5CbgF6VUiX3dV8CJwCI/ymswGAyGZvDnyGI50F9EeotIMHA58LnjBiKSKCKWDPcBr9g/70GPOAJFJAg96mhihjIYDAZD++A3ZaGUqgFuB75BN/QfKKU2iMjDInKufbPTgc0isgXoCjxiXz4b2A6sQ/s11iilvvCXrAaDwWBwjyilOlqGNmHMmDFqxYoVHS2GwWAwHFWIyEql1BhP23k1shCRj0VkmoPJyGAwGAzHEd42/v8DrgS2isg/RGSgH2UyGAwGQyfDK2WhlJqvlLoKyAB2AfNF5GcRuc7ugDYYDAbDMYzXZiURSQBmAjcCq4D/oJXHPL9IZjAYDIZOg1d5FiLyCTAQeBOYoZTaZ1/1vogYr7LBYDAc43iblPeUUmqBqxXeeNENBoPBcHTjrRlqsIjEWl9EJE5EbvWTTAaDwWDoZHirLG5SShVaX5RSh4Gb/COSwWAwGDob3iqLAMfJh+xzVQT7RySDwWAwdDa89Vl8jXZmP2//frN9mcFgMBiOA7xVFn9AK4hb7N/nAS/5RSKDwWAwdDq8UhZKqTrgWfvLYDAYDMcZ3uZZ9EfPjz0YPd0pAEqpPn6Sy2AwGAydCG8d3K+iRxU1wBnAG8Bb/hLKYDAYDJ0Lb5VFmFLqO3RJ891KqYeAaf4Ty2AwGAydCW8d3JX28uRbReR29PSokf4Ty2AwGAydCW9HFncC4cAdwGjgauBafwllMBgMhs6Fx5GFPQHvMqXUPUAJcJ3fpTIYDAZDp8LjyEIpVQuc0g6yGAwGg6GT4q3PYpWIfA58CJRaC5VSH/tFKoPBYDB0KrxVFqHAQWCiwzIFGGVhMBgMxwHeZnAbP4XBYDAcx3ibwf0qeiTRCKXU9W0ukcFgMBg6Hd6aob50+BwKXADktr04BoPBYOiMeGuG+sjxu4i8Cyz2i0QGg8Fg6HR4m5TnTH+gS1sKYjAYDIbOi7c+i2Ia+yz2o+e4MBgMBsNxgFcjC6VUlFIq2uE1wNk05QoRmSwim0Vkm4jc62J9LxH5TkTWishCEUm1Lz9DRFY7vCpE5HzfL89gMBgMbYFXykJELhCRGIfvsZ4ab3uZkGeAKeh5MK4QkcFOmz0GvKGUGg48jJ4zA6XUAqXUSKXUSHRuRxnwrZfXZDAYDIY2xlufxYNKqSPWF6VUIfCgh33GAduUUjuUUlXAe8B5TtsMBr63f17gYj3AxcBXSqkyL2U1GAwGQxvjrbJwtZ0nf0cKsNfhe7Z9mSNrgAvtny8AokQkwWmby4F3vZTTYDAYDH7AW2WxQkQeF5G+9tfjwMo2OP89wGkisgo4DT1PRq21UkS6A8OAb1ztLCKzRGSFiKzIz89vA3EMBoPB4ApvlcVvgCrgfbQ5qQK4zcM+OUAPh++p9mX1KKVylVIXKqVGAQ/YlxU6bHIp8IlSqtrVCZRSLyilxiilxiQlJXl5KQaDwWDwFW+T8kqBJtFMHlgO9BeR3mglcTlwpeMGIpIIHFJK1QH3Aa84HeMK+3KDwWAwdCDeRkPNE5FYh+9xIuLSNGShlKoBbkebkDYBHyilNojIwyJyrn2z04HNIrIF6Ao84nCONPTI5Aevr8ZgMBgMfsHb2lCJjuYhpdRhEfGYwa2UmgvMdVr2J4fPs4HZzey7i6YOcYPBYDB0AN76LOpEpKf1xd7rb1KF1mAwGAzHJt6OLB4AFovID4AAE4BZfpPKYDAYDJ0Kbx3cX4vIGLSCWAV8CpT7UzCDwWAwdB68LSR4I3AnOvx1NXACsITG06waDAaD4RjFW5/FncBYYLdS6gxgFFDofheDwWAwHCt4qywqlFIVACISopTKAgb6TyyDwWAwdCa8dXBn2/MsPgXmichhYLf/xDIYDAZDZ8JbB/cF9o8PicgCIAb42m9SGQwGg6FT4fO0qkqpH5RSn9vLjhsMvvPTf+C9qzpaCkNnYMkz8MGvOloKgxd4a4YyGNoGpWDZS3BkL1QUQWh0R0tk6Ei2zYftC6CyGEKiOloagxt8HlkYDK1i/zo4sgdQsG91R0tj6GgKrXthTUdLYvCAURaG9iVrDroIAJCT2aGiGDqYujootM+PZu6FTo8xQxnal6w50PMEKN4HuaaBOK4pPQC1lfqzuRc6PWZkYWg/Du+CvHWQPg2SM0xv8nincI9+D42BnLaYeNPgT4yy8MSBLJh9PdRUdrQk7qmthk9+DTsWtmz/rDkw5x7tgG4th3bC+1dDidNUt5u/0u8Dp0JKhnZyO2/TmSg5oKO2ivZ1tCSeWfgPWPthR0vhG5aySJ+uP5cWdKw8vnAgCz66EaqPnxJ5Rll4YvmLsP4j3QB2ZpY8DWvehSX/a9n+q9/R17r67dbLkvUlbPoCvrnfafkc6DIYEvrqkQV0bvPDug/1tax9r6MlcU9tNSx6HH54tKMl8Y1Ce17v4PP0e+6qjpPFV7Z8pe+P7d93tCTthlEW7qirgyz73E1lBztWFncc3gULH4WAYD2yqCz2/RgFW/X7t39sfQ/PMims+6DhYSo7BLt/0iYogO4jQGyd2xSVNafxe2clb4O2/R/cCvlbOloa7yncA+GJ0OskQDr3veCMNSrq7PdGG2KUhTv2rYLiXP25syoLpWDO3WALgPOe0Y3Gtu98O0ZtNRzaoc1DlcXw7f+1TqacTBgwBeL7wpe/00P1LV+DqmtQFiGRkJTeeUcWpQWwZwmEJ0D2cije39ESNY/jb5j1ZcfJ4SuFeyC2p86vSBzQee8FV1jKYvNXUFvTsbK0E0ZZuMOx19BZlcWGT3Ri08T/gyEXQlg8bJ7reT9HDu+GumoYNANOvhPWvAM7f2yZPKUHtXmh14kw/Qk4vBMW/Vv/ltEp0H1kw7bJGXoU0hZ+krbGUm5n26eFt/wtnZGcTP2/dx/p+3/fkRTugdge+nPK6M57L7iicA8ER0H5Idi7tKOlaReMsnBH1lxIHac/d0ZlUV4IX9+rG4lxN0FAIAycohu62mrvj1NgN10kDoBT/x/EpcGXv4XqCt9lsnqHyRnQ5zQYcQUsflIrtIFTQaRh25RR+ne1emmdiay5EJ0KIy7Xv0dnNjfkZELyKBg0vfOPgiyUgiPZemQBOuChNF8v6+wope/ZYRdDQEjnvjfaEKMsmuPgdsjfBEMvhOBIbXP3ho2fwY4f/Cubxfd/0Q/YjP9oMxRoM0/FEe0f8BZLWST0g6AwmPY4HNwG714Gn/+m4bXnF8/HyskEBJLtI4iz/6pNTjUVDSYoC384uQu2wrIXW3eMqjLta0mfppVb+nTY+YMuT+JI3gZ9ro7sDVeV6vs0ZbSWE46O0UXJAX1PxPbS34+GgAeL0nwte5fB0Od0bfpry3ug7BB880DjZ2/B3zp81GWURXNYvYWBUyE83vuRxdf3w1d/8J9cFnuXw/KXYdzNDQ0zQJ8zIDDMt95OwVaI7Aphsfp7v0naHJW/GbbO068178GPj3k+Vm6mHqFYdX4iErU5Km0CpJ3SeNuuQ7VTvi0dm0uegbn3tMzJb7H9e6gpb1Bu6dOgtkqPjiyqy3VY7dx7YNPnrZO5Nexbq81lKRnaBxTX++jo6VqjSWtk0W0o2IKODie3o+zpU7XZNW9D2x3/63vhl/81PHubvtCRbvlZbXeOFmCURXNkzYFuwyCul3ZyeqMsKkugKFv39A5u959stdXw5V0QnQwTH2i8LjhcN/ZZc73viRRs0Q28I2c9DHdnNbyGXaIVgbtjKqUf9pTRjZcPuQBmfgkBQY2XBwbr37gtQyatnqlVRqIlZM2B0Fh7lA7QY7y+Bxx77D8+pv0x0Sm6c+A86mgvHM1+Ilqx7XAxCupsWGGzlrIIDIGuQ46OkYWj7AOmANJ2Cnr7Alj7Pky4u+HZu84+G0QHK1KjLFxRckA7raxhvbfK4uC2hs/+NAX88izkrYcp/3RdqTN9mlZa3hRnU8quLPq73y4lw7N/4Ui2LuGQkuH5vBbJGVpZ1NV6v09zVFc09PBa6geprdEx9AMmNyg3W4DdF/Qt1FTphKyf/gPDL4dL39Q+gu//2nr5W0LOSu1bieqqv6dP18EKjqOgzoj1/8T0aFiWMhpyV+uQ9c5M/ciih/7de4yDzW2gLKorYM7vIL6PVhYWif21M72DFalRFq7Y8jWgGswQ3ioLK1chNNZ/poDDu2Hh32HgNO3QdEX/c3QOgzcylBZARWHTkYUz3tiUHXu53pKSAVUlDb9da9i/DursYYwtVRZ7f4Hyw9q84MjAaVB5BHb9qEd1IZFwziOQOloHFyx7oWNKVuRk6kABix7jdO5CZzdFFe7Rz1VIZMOylAyoLGrc6eqMFO7R0WdWRy19mu6YtWY0Czpq8NAO7TMMCmtYbgvQpuYOLolilIUrsuZATE9tUwe7svDCwV2wBSQAxlyvncFtXcpCKW0jR2DqP5vfLiIBep7kXYNRHwnlYWRR719wc8PmZGq7c7ehns9r0ZaOTesYYmswFfhK1hwd4dJ3UuPlfc+AoHCdN7JnCZz1F+2PAZj4R+3z+eKu9o25LzukTWGOytkWAAMnw1b7KKizYuVYOHK0OLmdZW+LwIL8LbD4CRh2qb7XnEkeBfvXd2jZIaMsqsrgl+ccXs9qu6EVCQPawV1V7PmPKtiifRxDLwSUNmf4QkWRbqya8wts/Ew3AhMfgJhU98dKnwYHNuieiieZwfPIIjBYK4wcN/6F3Extdw4McX8sRxL762iztrDH5mRCZDc9jPd2ZLFrceP/f8On+mF17PGC7un1nWjPITkZRl3dsC40BqY8CvvXwrLnW38doB30W+e538by9Tib/dKn6x76rkXenau8ELa6MVvtW+v0jDynqwa0BlfKImkgBEW0n21+31ooaMEoxln2hL46uKClCZFK6VD14Ag452+ut0nJ0ObFvPUtO0cbYJRFdRl8/QeH1736Txl2ccM24Qn63dPoomCrbnS7DtUjE19NAUuegfeu1Il2zlQc0Y7UbsN0BJQnLDOKJxkObtPRU9EelA9om/K+1a79C3V12t7s7Nz2hC1A77NrsW/7uSI3Uz9Usb28UxY5mfD6jMb/f3Gudua7YsTl2nY8/YnG+SKg6xulTYDlL7X+OkAf5+2L3UfZWI1q8qjGy/ucDrZA78OnF/0b3r6o+YbzoxudnpE/wLwHvTu2K5TSRSSdlYUtQJev3/CxNgX6k7o6eOcybVL0BSvHwln2AefA7p9bVlhw9TuwezGc9WeITHK9jfVcdaCT26/KQkQmi8hmEdkmIve6WN9LRL4TkbUislBEUh3W9RSRb0Vkk4hsFJE0vwgZFg+/39n4de9eSB3TsE29snDjt6ir1Q1vYv+GqJTtC3SElLdYPZOv79W9PUe+/yuU5OmcigAvpiGJS4OuwxpqWzVHwRZI7Ac2L24Fd/6Fg9t0b9YX57bFwCmtjyCrOKKvJTlDP8ielEVtjW4oIrrAbzc0/u8dOwqODJoB9+7WPWBnRKDnibrH3RamguwV+t2dss/NhIT+emTjSFCYjtLyRmEq1XDfuXLSFmyDgs06Os76jdKnt67Rcs6xcOTMB/VzNv/PLT++N+TaS/n4Glxh5Vg4y546TvvL9q/zTY7Sg7oeW48TYJSbuchjemhfVAcWW/SbshCRAOAZYAowGLhCRAY7bfYY8IZSajjwMPB3h3VvAP9SSg0CxgEH/CKozabNTI4vZxOEN8qicI+uy2SZc9Kn6e/eVqU8vEsPMYddqm/I7x5uWJe9Uid/jZvlW889fZp22LorDOgqbLY53NmUW+LcthhoHwW1xuaba5+iNWWUVhblh9znWix7QTslpzyqTXrWf+9pTnAr+dEViQN0zoMn0583WI2CO2WRk9m8cvZGYYLOpTm0Ax3+6eL3txTI0IsafqMe4/TUuC0tOOmcY+FI9xFwwq2w8lXY48cyGtZ1+Rpc0Zzs1v/gqxL99o+6kzXjSfcdNhF9jg50cvtzZDEO2KaU2qGUqgLeA85z2mYwYLWmC6z1dqUSqJSaB6CUKlFKlflRVvd4oyysG85qeHueCGFx3puirAf1jPu0mWnFKzrxrrYGvrwTorppR6ovpE/VjdeWr12vr67Q0VXeKot6/4KLGzYnU9ubXfW6PRHXy7tRkDsclZX1IDcXnXIkW4/U+p/dUB67LbCCBApaWfm1eD8U5WhT5r7VrktgFOVCyf7mlbO3pjhrVDH6Wh0uXuLUJ8uaoxtwRx9Za00izjkWzpx+nzaLfnmXb2VrfMEKYgHfHOrNyR6drP1lvhxr5yJdh+2kO6DLIM/bJ2do5d6ahNNW4E9lkQI4Pq3Z9mWOrAEutH++AIgSkQRgAFAoIh+LyCoR+Zd9pNIIEZklIitEZEV+vh8n0fFKWTg5igMCdcKOt3WarLke4vtoB3ZUd/2wLHlaD22nPOq51+tMt+F6+Nqcwjq0HVC6zIc32AK0fdxVI5GzUof3uet5u8MaBbU0giwnU5vewuMbTATNNZZzf6+V6NTHmvoeWoP1O7ZWWVi/7+n2SgCulKilsJsbacb21FPXejKJZc3Rxxh7E6AaF0wszoO9yxqifSy6jwCk5VFLrnIsHAmJhKn/ggMb4ef/tuwc7ijYprOhT7xV+6B86a075lg4k+LD7I81lfr5jkvT9di8IWU0oLzLn/IDHe3gvgc4TURWAacBOUAtem7wCfb1Y4E+wEznnZVSLyilxiilxiQlNeMYagvC4vS7Owd3wRatVMLjG5alT9M5DLt/dn/80oOw52eH8t1R+mHJWw/zH9QJYoPO9V3uet/J97qGkCuZwfuRBWhlkbe+cVhmTZVWaM6OVl9In9b8KOhIjudELcfM8fqRhQtlselLbYI44z49omlLQiJ1j7i1OSO5mToEe8iFkDjQdZRNTqZ2Yncb5voY1m/grjDfkRx9rvRpOoottlfjjsWWr2iUb2QREqVHkN40sko1dZwf2WvPU4h0vQ/oUXH6dPjhn95PPFZXq01XOxc1vFyNLi0TVPp0e/5CMw38we1N/RmFe3R74CoZNiVDzyni7G8EPRJ0lGveg9rPN+3fuuqCN7TU1NVG+FNZ5ACO6jfVvqwepVSuUupCpdQo4AH7skL0KGS13YRVA3wKtMAY3kYEBGknoiczlHOj23eivU6Th5A657keQCfcpU/Xpp2p/2p5Dzh9mnbIufKdWI2atyML0DdsbVXjEL4tX2n/TOrYlskIutFzFUGWsxKeHKad/s1RckBnrFsmmcguEBiq7erO/PAoJA3SdnF/kNi/bUYWXQbpRiR9mo4Uc4wOqqnS91S3YRAU6voY9QrTTb6J5SNKn95QMNFx8qysObrn28XZ1UjDHOqeSsqsmw1Pj248OnIVTeSKKf8EFCx9zvO21rleORten97w+u/ophNCWaa12B6uOz+gFdTTY7U52BF3slv3377VjZcrBa9ObSzX0md11F2/M727NtB5PTE9OywPxZ/KYjnQX0R6i0gwcDnQqOKaiCSKiCXDfcArDvvGiog1XJgIbPSjrJ7xlMXtqmRGcLiO2fdUp8nVXA8Al7wGd2R692A1R8+Tms8oL9iibz5vezbQ1MldWQxf3avDhZ17oL7gOAqyIshqa+CLO0HVaod0djM9WaunZfW8RLSJw3lkUVWqQ1EHTW9ap6qtSByglXBLK4QqpX9ba5SWPk1f/5ZvG7ZZ8l/9353mRoG6G11ZbJ6rOwr1QRlTGybPqizWisNSJM6kZEBZgR4luGPjp/p97v9r+F+9VRYxKVo2bwMG9v4CIdFw7Zf6dfVHWpl++duG/8MyrQ2036spo5t2fsBeSbZW5zY54lZZ2P8z557//nU6eXLCPQ2yXfcVnO+lEnQkZVSHObn9pizsI4LbgW+ATcAHSqkNIvKwiFg2ldOBzSKyBegKPGLftxZtgvpORNYBArSy7nQrcacsyg7pB8eVOceq07R/ret9ncthOxIQpB3brSEgUJuxXM3o5U1NKGdie+oQPis57/tHtG18+pOtb4CtxsoaBS19Tj9o5z2jf4cv73SdIZ2bqbO2u49oLKdzQ7lvrW4AfM0F8YXE/jrCpnhfy/Y/vFOPIiwZkzO049QanR7aqU0zg2boTO3miOquzVTNKYvyQj3BleN91+OEhsmztn2nG9GBU13v741JpKpMH6fHCfoZWPj35vMUmsPbqC5o8Jv1nqBf/c6EM/+scxjWvKu3cTat1V+HUwNsjYR2/9Rgfq6XvRnzZXi8rvrr3PPfPBcQGH9zg2y9TvIuBN6ZlNFahtZOfdwC/OqzUErNVUoNUEr1VUpZiuBPSqnP7Z9nK6X627e5USlV6bDvPKXUcKXUMKXUTHtEVcfhTllYtWxcKYsBk93XadqxQJfDbu6hbAss38keB99JXZ1r05knHEP4clfpjOUx10OPVpigLBxHQYV7dQ3//ufAyKvsGdLrXJskclbqDNrgiIZlrhqZ1oT3eov1e7bUFOU8SrLZtBLd9p290NzduqTKFDflXkA3RO5yLbbN13kBjs5rx8mzNn6q7/ke413v39VeUtydSWTHQn1vn34vjL5OV0fY9l3zORausKK6PI3UrCKSzv9txrX6Gr55QPsGs+boY3Ydote7yl8oydejlAGTG/vR6nMs3Ci6lIymVQ6yvtQyRHbx7prdUT+yb/98i452cB89uKsP5a6+UkSiDqNtTllkzYGQmKZzPbQl/SZpG76jDMW5Onvd15EF6Bu2YDN8djtEJMGkP7WNnI6N1Zy7AdXgrxl0rn54FzzSuAG0yqI7NxKxPbVyd0yKzMnUDahVodUf1IfPttDJnbtK/1eOfoL0aVBdqqNntn8Hk/5Ph2p6wl2vPOtLnZCYMqbxcmvyrA2f6Gi+5nq/gSG6Bpi7kYXjvX3mg7rn/cnNDbJ5Q2xPfZ96KuSZt14rP+e8E5tNj3ori2Du3bp8u6Nprb7z43Adlg/xjPv1/WI9N5az3K2yGK1HUcV5+vvh3bqT0xoTrSPJIwHpECe3URbe4m4CpIItushec72l9Gn6ZnaO6qit0eahAef4z4YOusfd5wx905ce1ErPutl8HVmAfrhUnb6myX9vmDSpLbBGQfDxZq8AABPASURBVFu/0T1SK2JJRCsO0PbvskP6tX+dTsBLcYrEqo8GcrCpO/oC/EVUd52L0lJlkZOpHdeO90PaqdoWv+ZdLf/YG707Vmwv19FANZW67lT61KaJYNbkWeC5gXNXUry2RptfrHs7LA4m/0Oba8E3ZQGeC0PmuBk1dh0MJ/1GK8DayqbXlTJah9I6OvZjeurQ8/RpejRUVeY5P8Tx/NaIqz6IoI2URUiUfmY7wMltlIW3hCfoIXWVi9zAgq0Q37f5HIPmMpS3fqMbOudy2P4gfZpuOP/VB/7ZGz64Ri9vibJIzgBE24SHXOhxc5+wIsi6Dm0asRTbUydsbflaX8M/e8PzE/Q65x6yc65F+WHtKG1JORJfEGl5RFRtjY6kcfapBAZD/7O0OXP6k97nsjSXa7H7J+1XGeiiAbMmzwoK1zWm3JGcoQtsHnShGPcubXpvD71I/79ic52n0Nw1gGe/RW6mHik1V2Dz1N/re8KVaS05g/r8hcoSpyl1p+nnfscCz/khAN2H6+uzlFfWHB19l9DX46V6TcpobXpt52lWW+BhOU5xTMxzjh4q2OI6vNAivjd0GaJvnBNv08uqSnUUUeJA1w9tWzP8Uu3cdWw4opNbZpKJTIKrZzfMztaWBEfANR/rh97VaOvE27TcjqO8sPjGzm1o2sjUV2j1o3PbInEA7PJhDnSLgs3a5OKqd3z2X7XdP3lk03XNEdsTUDrXwrGx2rscEOh1ouv9pjyqczA8Rck5OrmdM/c3z9WjbcfQUBG46GX9X7jKU3B5DfaG2ZOyyFmp5WnufgwOh6s/1iY2Z9Oa43WUHbKPPuxKrtfJOmw+a642vYXFuU+ODY7QyiHXfqzdP8Epv/N8nb6QkqEzv49ke6902wCjLLwlzJ5sV3aw8R9UU6XNS4PPd79/+jRY9Jg2A0Uk6Hj/I3tg5lzdc/Q3gSEwembbHc+X+HBfsaYzdYUtoPlCf45YuRaW6cDq6TmHJ/uDxP56aszKEveJZ844O7cdiU72zk/hiKPCdFQWzvOkOxOT6rkEPuhjBEXo4428omG5VZywz+lNzxEer0cu3hIao4Me3CmLiiI9uh/q4b5IbCafyDF/4cBGfb6e9nswIEgHWWyea8/N8MJ8ljJKKxdX+VNtgaOpqx2VhTFDeUtzJT8O79Q9dk/mHMcM5f3r4eenYdQ1kHayf+Q93nHOtcjJ1DkFbelfaQ7rXvB1xrfcTO2biG8jk4WrXnn9POltYI6rL//iFHZ6YKMujNlWjaSn8Nl9qwHVumtKydCVfjd/pYMsHEcf6dO0SW3XIi+VxWi9/S/PQlRy2/vJutkj0drZyW2Uhbc0N6eFtzPNdR+hS0Fs+kJHtYTF6rLPBv/h2MjkuoiY8hf14bM+OrlzVuqGxZty8d4QlazLhjg2tPXzpLeROS5llA4ycMyAzpoDiI6mags8KQt3zm1vScnQPr2KwqZKrt8kPXtiXU1D8UF3WHLsX+s6f6q1BIbo0N92dnIbZeEtlrIob6GysJxlW76C7OV6RizHOlKGtsdqZIr2aUevv53bFvF9tJPTFye3lSfQljIGBOosaMeGtq1zTZLt5V8OOEzSlPWlLmPeViHKnnItcjP1NhEJLT+H9XsEhmonvCMhUQ3Ofm9GFl2HaOUCbW+CsnAXieYnjLLwlrBYQJqaofK36HBJbxx21o3T+1QYflmbi2hwwsq1sGbhaw/nNuieX1xaY2VRXQ5vXtC0fIRF3gbdc23r0Y9zqfKWzJPuDku5vXEePDZQv/atadtG0lOuRVuY1az8hb4TGyd3WljX442yCAjS4c/+zJ9KydC5I76aOluBcXB7iy1AR0I437D71+owT29IOwXO+KOenrOth6aGplgP9sZP3Vdo9QdWjSiLRf/WIZmxPV3PoXHYnoPTkiRJd8T21DM2WrRknnS3x+8FE/+vsUIKDIWRVze/j8/nsHwvu7Uz2pGSfG0+GjerdecIidKzUDandIZdrOcZ6XuGd8c780Edru2v/ClHJ3dSC8LfW4BRFr7gXPKjskQn83hbPtwWAKd5Wbve0HqsXIut83QV16Cw9jt3Yn/dSNfVaqWx+Em9vKiZmlFWLamo7m0rh2OuhS1Imy68iSbzFhE49Z62O54rHKO6nEeHllmtLUaNo69tfl1wRMP8It7Q+9TWy+OOpIE6Ei0nU3c+2wGjLHzBWVnsW6MjnNrLFm7wDauRqa1sP+e2ReIAfd7Du3TV05BI7ctorsBg8X6dCOc8n3Zrccy1qKu1z5PeTua4tiLGTa5FjosikscDtgB9ze3o5DY+C19wrg/VHoXpDC3HyrWA9lfoVkTU/Id0Acez/qLNlc0pi6JcXVm3rc2Tjr3yo/V+DYvVStSVssjN1ImtvuSzHCukZOhKys5zcfgJoyx8wbk+VE6m7vVE+nGWPkPLsXItoP1705ay2PS5TvAadbVOqivNd/1wF+/Toa5tjaOyaM086R2Nq/BZpRoyt49HUjL06PVA+0z1Y5SFL1hmKCuErz0K0xlaR2xPXWsqaVD7njc8Xt8vtiCY/oRWXNbcJCV5Tbcv3tf6uUtcYeVaHNmr79fuI1o+T3pH4hzVBfp72cHjV1k4Fy30M0ZZ+EJ4go4pryrR5qjDu44+++/xxqirYcLdLZtoprWccCtM/Sd0SdffrZGDsylKKe34jm5j5zY05Foc3KZNFkdrw2qNLBxzLaxJsnq6KQ9zLBOXpssQtVMmt3Fw+4JjyQ9rEvqj9eE7XhjaxlVxfcE5SshSBs7KovywNif4wwwFule+/Xt9jqP1fnXMtbDCZ7Pm6JnpurTzqLGzIGIvt2JGFp0PR2WRmwlI+xSmMxwbWGGxzuGz9WGzfjBDgW5oK47oz0ebc9vCuYpwRRHs/ME/5TSOJlJGQ/4mXcXazxhl4QuO9aFyMnUsvbtyxQaDI5YPw3lkYX33taqst1gNbVi8Nl0cjTgri23ztUnYX+U0jhasicj2rfX7qYyy8AWrllNpQfsWpjMcG4jo0YWzsihqh5EFaJPF0doLd8612DzX/Rzhxwvt6OQ2ysIXrJFF3nod0WKc2wZfie6ucyoc8Vf2toWlLI5WfwU0zrWoqYIt3+pS4kdjZFdb8v/bu/cYqco7jOPfBxAQWEAKIgJBvBTEVlEJ9dZqvVQ0htpoWy81xpjYP2iqrU0raavRpGmbmKp/mFbT2mpr1Eq1JcTWKlUT24iggKKI4p2bi0YFaksFfv3jfQ87btfOLuzMOcM+n2Syc87MDs/OOcNvznve875tY9M84U04b+Fi0RODR6RuiC89lJZb+cNn5Wgbl67WrrV5ffoi0lvjNXU29jAYM7Vjet9WVfSIev1x2Po+TD2r7ETVMP6orrtj9zL3huoJKX2o316VBqbr7gCCZoW2cam9vdam9Y07qoA0AOacRY17/WYZOQneeTn1gurOHOF9xTm3NWW2TR9Z9FTRFDX2MNhrcLlZrPUMH5eu09m6uWPd5gYXiz3FiIlp5NlVf05DiTdzYMgqa8a0zLhY9FxRLHxy23ZFV91nG3X19p6muNZi01o3QZXAxaKnih5RPrltu6IoFpvzSe7tH8KW9sZ1m92TFCfq1R8+eXq5WfogF4ueKo4sfHLbdkVRFIqT3FvagXAzVHcUxWLScZ6SuAQNLRaSZklaJWm1pKu6eHySpIWSnpH0qKQJNY9tl7Qs3+Y3MmePjJmSPtijW3DkTitf0dxUdJ9tdLfZPcmoyTBoOBz+lbKT9EkN6w0lqT9wM3AasAZYLGl+RNSOp3s9cEdE3C7pZODHwEX5sX9FRPXG0pj5dTj6knIGprPWN3Bompu5OLLYefW2i0Vdg9rgyhdSTyhrukYeWcwEVkfEKxHxH+BuoPPkw9OAPHQkj3TxePX06+deULZ7ho/rOGexyUcWPTJwaOtehd7iGlksxgNv1iyvyetqLQeKYUG/BLRJyicFGCxpiaQnJJ3d1T8g6bL8nCUbN27szexmjdO2X0eR2LwujRc1ZHS5mczqKPsE93eAEyUtBU4E1gLb82OTImIGcAFwo6SDOv9yRNwaETMiYsaYMZ6tzlpE2/41zVAbUvHoV/ZH0ez/a2TD+1pgYs3yhLxup4hYRz6ykDQMOCci3suPrc0/X5H0KHAk8HID85o1R9t+sGUD7NjRMfe2WcU18uvMYuAQSZMlDQTOAz7Sq0nSaElFhrnAbXn9PpIGFc8BjgeaM9GsWaMN3x92bIMP3s5HFj5fYdXXsGIREduAbwAPAiuB30fEc5KukzQ7P+0kYJWkF4GxwI/y+kOBJZKWk058/6RTLyqz1rXzKu51HurDWkZD+39GxAPAA53WXV1zfx4wr4vf+wfw6UZmMytNURzeWQ1bN7nbrLUEn1Uza7aiOKxbmn42au5ts17kYmHWbEP3BfXrmLDGJ7itBbhYmDVb/wGpYKxflpY9iKC1ABcLszIMH5eG2wYfWVhLcLEwK0NxkntgWxrzyKziXCzMylAUC/eEshbhYmFWhqJYuAnKWoSLhVkZiiMKd5u1FuFiYVYGH1lYi3GxMCvDznMWPrKw1uBiYVaGMVPghG/DobPrP9esAjw3qFkZ+vWHU68pO4VZt/nIwszM6nKxMDOzulwszMysLhcLMzOry8XCzMzqcrEwM7O6XCzMzKwuFwszM6tLEVF2hl4haSPw+m68xGjg7V6K05uqmguqm62quaC62aqaC6qbraq5oGfZJkXEmHpP2mOKxe6StCQiZpSdo7Oq5oLqZqtqLqhutqrmgupmq2ouaEw2N0OZmVldLhZmZlaXi0WHW8sO8DGqmguqm62quaC62aqaC6qbraq5oAHZfM7CzMzq8pGFmZnV5WJhZmZ19fliIWmWpFWSVku6quQst0lql7SiZt0oSQ9Jein/3KeEXBMlPSLpeUnPSbq8QtkGS3pS0vKc7dq8frKkRXm73iNpYLOz5Rz9JS2VtKBiuV6T9KykZZKW5HVV2J4jJc2T9IKklZKOrUiuKfm9Km6bJF1RkWzfyvv+Ckl35c9Er+9nfbpYSOoP3AycAUwDzpc0rcRIvwFmdVp3FbAwIg4BFublZtsGXBkR04BjgDn5fapCtq3AyRFxBDAdmCXpGOCnwA0RcTDwLnBpCdkALgdW1ixXJRfA5yNiek1//Cpsz5uAv0TEVOAI0ntXeq6IWJXfq+nA0cAHwP1lZ5M0HvgmMCMiPgX0B86jEftZRPTZG3As8GDN8lxgbsmZDgBW1CyvAsbl++OAVRV43/4EnFa1bMAQ4GngM6SrVwd0tZ2bmGcC6T+Qk4EFgKqQK//brwGjO60rdXsCI4BXyR1vqpKri5xfAP5ehWzAeOBNYBRpmuwFwOmN2M/69JEFHW90YU1eVyVjI2J9vr8BGFtmGEkHAEcCi6hIttzUswxoBx4CXgbei4ht+Sllbdcbge8CO/LyJyqSCyCAv0p6StJleV3Z23MysBH4dW66+6WkoRXI1dl5wF35fqnZImItcD3wBrAeeB94igbsZ329WLSUSF8TSuvrLGkY8AfgiojYVPtYmdkiYnuk5oEJwExgahk5akk6C2iPiKfKzvIxToiIo0hNsHMkfa72wZK25wDgKODnEXEk8E86NetU4DMwEJgN3Nv5sTKy5XMkXyQV2v2BofxvU3av6OvFYi0wsWZ5Ql5XJW9JGgeQf7aXEULSXqRCcWdE3FelbIWIeA94hHTYPVLSgPxQGdv1eGC2pNeAu0lNUTdVIBew8xspEdFOanufSfnbcw2wJiIW5eV5pOJRdq5aZwBPR8RbebnsbKcCr0bExoj4ELiPtO/1+n7W14vFYuCQ3HNgIOnwcn7JmTqbD1yc719MOl/QVJIE/ApYGRE/q1i2MZJG5vt7k86lrCQVjXPLyhYRcyNiQkQcQNqv/hYRF5adC0DSUEltxX1SG/wKSt6eEbEBeFPSlLzqFOD5snN1cj4dTVBQfrY3gGMkDcmf0+I96/39rMwTRVW4AWcCL5Laub9fcpa7SO2OH5K+ZV1KaudeCLwEPAyMKiHXCaTD62eAZfl2ZkWyHQ4szdlWAFfn9QcCTwKrSU0Gg0rcricBC6qSK2dYnm/PFft9RbbndGBJ3p5/BPapQq6cbSjwDjCiZl3p2YBrgRfy/v9bYFAj9jMP92FmZnX19WYoMzPrBhcLMzOry8XCzMzqcrEwM7O6XCzMzKwuFwuzCpB0UjEyrVkVuViYmVldLhZmPSDpa3n+jGWSbsmDGG6RdEOeU2ChpDH5udMlPSHpGUn3F3MdSDpY0sN5Do6nJR2UX35YzVwOd+Yrcs0qwcXCrJskHQp8FTg+0sCF24ELSVf2LomIw4DHgGvyr9wBfC8iDgeerVl/J3BzpDk4jiNdtQ9pNN8rSHOrHEga48esEgbUf4qZZaeQJr5ZnL/0700aOG4HcE9+zu+A+ySNAEZGxGN5/e3AvXlMpvERcT9ARPwbIL/ekxGxJi8vI81t8njj/yyz+lwszLpPwO0RMfcjK6Ufdnrero6hs7Xm/nb8+bQKcTOUWfctBM6VtC/snLN6EulzVIzweQHweES8D7wr6bN5/UXAYxGxGVgj6ez8GoMkDWnqX2G2C/zNxaybIuJ5ST8gzTDXjzQ68BzSJD0z82PtpPMakIaG/kUuBq8Al+T1FwG3SLouv8aXm/hnmO0SjzprtpskbYmIYWXnMGskN0OZmVldPrIwM7O6fGRhZmZ1uViYmVldLhZmZlaXi4WZmdXlYmFmZnX9FxkB08BVbUdDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training history for model 1\n",
    "#accuracy\n",
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plots looks good: the validation is always below training line, indicating no overfitting. Also, it looks like a number of training epochs around 50 is a good choice. Model 6 was trained with 80 epochs which is still fine. We could probably save some time by running it with 40 epochs and it should not impact the model accuracy.\n",
    "For Model 8 it looks like higher accuracy could be achieved with shorter training by using approx. 130 epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 5: Training benchmark SVM model.\n",
    "In order to benchmark our CNN model, we decided to compare it against different methodology: SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5.1: Convert data to required format - 1D numpy array.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape img array to vector\n",
    "def reshape_image(img):\n",
    "    return np.reshape(img,img.shape[0]*img.shape[1]*img.shape[2])\n",
    "\n",
    "trainingImages=np.copy(train_tensors)\n",
    "validImages=np.copy(valid_tensors)\n",
    "testImages=np.copy(test_tensors)\n",
    "\n",
    "img_train = np.zeros((len(trainingImages),trainingImages[0].shape[0]*trainingImages[0].shape[1]*trainingImages[0].shape[2]))\n",
    "img_val = np.zeros((len(validImages),validImages[0].shape[0]*validImages[0].shape[1]*validImages[0].shape[2]))\n",
    "img_test = np.zeros((len(testImages),testImages[0].shape[0]*testImages[0].shape[1]*testImages[0].shape[2]))\n",
    "\n",
    "train_lab=train_labels[:,0].astype(int)\n",
    "val_lab=val_labels[:,0].astype(int)\n",
    "test_lab=test_labels[:,0].astype(int)\n",
    "\n",
    "for i in range(0,len(trainingImages)):\n",
    "    img_train[i] = reshape_image(trainingImages[i])\n",
    "\n",
    "for i in range(0,len(validImages)):\n",
    "    img_val[i] = reshape_image(validImages[i])\n",
    "    \n",
    "for i in range(0,len(testImages)):\n",
    "    img_test[i] = reshape_image(testImages[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5.2: Use grid search alogrithm to define best SVM classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ('linear', 'rbf', 'poly'), 'C': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':('linear','rbf','poly'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf_GS = GridSearchCV(svc, parameters)\n",
    "clf_GS.fit(img_train,train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 6: Compare CNN and SVM performance. \n",
    "In order to compare CNN and SVM performance we will calculate three performance metrics: accuracy, sensitivity and specificity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion matrix, Accuracy, sensitivity and specificity\n",
    "def calculate_stats(true_values,predicted_labels,model_name):\n",
    "    cm1 = confusion_matrix(true_values,predicted_labels)\n",
    "    print('Confusion Matrix for model {} : \\n'.format(model_name),cm1)\n",
    "    total1=sum(sum(cm1))\n",
    "    #####from confusion matrix calculate accuracy\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print ('Accuracy : {0:.2%}'.format(accuracy1))\n",
    "    sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])\n",
    "    print('Sensitivity {0:.2%}: '.format(sensitivity1))\n",
    "    specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])\n",
    "    print('Specificity {0:.2%}: '.format(specificity1))\n",
    "    return([sensitivity1,specificity1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model CNN Model 1 : \n",
      " [[289   6]\n",
      " [  7 288]]\n",
      "Accuracy : 97.80%\n",
      "Sensitivity 97.97%: \n",
      "Specificity 97.63%: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9796610169491525, 0.976271186440678]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_stats(test_labels_CNN,model_pred,\"CNN Model 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model CNN Model 6 : \n",
      " [[281  14]\n",
      " [  7 288]]\n",
      "Accuracy : 96.44%\n",
      "Sensitivity 95.25%: \n",
      "Specificity 97.63%: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9525423728813559, 0.976271186440678]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_stats(test_labels_CNN,model6_pred,\"CNN Model 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_predict_best=clf_GS.predict(img_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for model Best SVM Classifier : \n",
      " [[249  46]\n",
      " [ 19 276]]\n",
      "Accuracy : 88.98%\n",
      "Sensitivity 84.41%: \n",
      "Specificity 93.56%: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8440677966101695, 0.9355932203389831]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_stats(test_lab,class_predict_best,\"Best SVM Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image has been incorrectly classified as positive\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFIqD35hCcfAbUyj/D7LKa32N8CeHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223e30dc278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image has been correctly classified as negative\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHVFJREFUeJztnXuIXdd5xdc3I/kR2ZY8es1YkvV0\n7JhQK+CaQApJnaRxTcEOJCUuLS4YkoIDCQ0lbv7JgwYSSOL+0ZLiENcqpHFMHrUp6cO4DmmgOE9F\ndiLLsmU9RhppJFljy3nYGunrH3MmjO5ZS3PO3Jk7M9rrB2KkrX3P2Wef8829d+21vy8yE8aY8uib\n7wEYY+YHB78xheLgN6ZQHPzGFIqD35hCcfAbUygOfmMKxcFvTKF0FfwRcVtE7ImI5yPivtkalDFm\n7omZOvwioh/AcwDeDWAYwI8A3JWZv1SvWbZsWa5YsaLzOI3P2dfX/HfVuXPnGrer47KxsflSc9jf\n33+hIZ7H2bNnGx+X0WZu1HGbnu/SSy+l7Wy+xsfHad8zZ87U2trcBwWbczZedQ2XXHJJ4/O3eRba\nwJ4FNYbOOTtw4ABOnjzZaMKWzGBsk9wC4PnM3FcN7mEAdwCQwb9ixQrce++957WpAGFBumzZMtqX\nTfivf/1r2vf111+vtbEbrtrZ69UD3vmL7kK8/PLLjY/LHoTLL7+88bnYNQD8oWNtW7dupa9nAXXi\nxAna98iRI7U2dQ3sPqggY3O+bdu2WtumTZvo61n7kiU8TH7729/W2tgvNYA/5+oa2LOgxtA5Z29/\n+9tpP0Y3H/vXATg05d/DVZsxZhHQTfCzjxa1X2UR8cGI+HFE/PhXv/pVF6czxswm3QT/MIANU/69\nHkDts1xmPpCZN2fmzepjuzGm93Tznf9HAK6LiM0ADgP4AIA/m+5Fnd8h2whz6jsS68u+qwLAFVdc\nUWtT4g+Dffdi39EA4LXXXqu1qV+AS5curbUp3YIdV32qYudTGgcbw+nTp2tt7Ps6AAwODtba1q5d\nS/uy+6O0CKYFXHnllbTv1VdfXWu77LLLam3s+zoAHDt2rNZ21VVX0b5Me1HCHLteJXCya1PPc+ez\n20YcnXHwZ+Z4RHwYwH8B6AfwYGb+YqbHM8b0lm7e+ZGZ3wXw3VkaizGmh9jhZ0yhOPiNKRQHvzGF\n0tV3/rZERE2dZAozwJVfpQazVQCl5rKVAeXEY6sAbAxtnFq/+c1vaF/lDGMwtZ6tAKixqXMx9fkN\nb3hD49ePjo7W2tQ9W7lyZeO+bMVCOfRWr15da2MKuJov5khUKyls5Ui5FNmKg1L7mbKvnLCd8dPK\nLt+4pzHmosLBb0yhOPiNKRQHvzGF0lPBLzNr21RXrVpF+7LtrErEY+1MqAK4CLdnzx7al1lTmUjT\n1HoJaGsts/KqvkxoUhZjJpYpizET3Ji4p7YaM1FKbUVlFlYlarW5BiasMcuvspWPjY3V2tQ1sPZX\nXnmF9j18+HCtbfny5bQve3bVnHe2q2eR4Xd+YwrFwW9MoTj4jSkUB78xheLgN6ZQeqr2nzt3Dq++\n+up5bSx5AqCTNTCYSq1UT6akqlWEkydP1tqU6spgKrNa3WDXoGylzEKqbJ3MTtx5DyZpmgiDzQvQ\nLussu7/KZs1WN9Tzwa6NzS2zFwN8DpQlm51LrViwlZvjx4/TvuwZHRoaon07Vxxs7zXGTIuD35hC\ncfAbUygOfmMKpSvBLyL2AzgN4CyA8cy8+UL9+/r6amKGylDbpuwRs1mqjKvMrtqmahBDiYBMSGT2\nUYDnNVCiJRuXsgIzAejUqVO0L9vj/sY3vrHWpir2sDGouV23rl7fRd0z9iwoyy0TKNl1qUpCah4Z\nbUqssTwDa9asoX2VVZvRaTfvSfbeKfxhZvKZNMYsWPyx35hC6Tb4E8B/R8RPIuKDrIPLdRmzMOn2\nY//bMvNIRKwB8HhEPJuZ35/aITMfAPAAAKxbt677+sXGmFmhq3f+zDxS/RwF8B1MlO02xiwCZvzO\nHxHLAPRl5unq738E4DPTva5TnRwYGKD9mEqslExms1SWXWaNZfZRgNtrWe06ZTVlarCyxrLEDiqb\nLVOkVSZYllBE2WjZSgg7l3o9S36i6iCyZBzqetlqisqSy9rZ6kgbVVytWLB7plav2DWo547Nr/rK\n3Pk8tskC3c3H/rUAvlNN4hIA/5qZ/9nF8YwxPaSbQp37ANw0i2MxxvQQL/UZUygOfmMKpef7+Tuz\nmyqhiu1pVqW92B55ZWFlgpuylbLztcneyyyoSmhi7cpqys6nBE42j0qwa7qPXI2rTaZfhrLssj32\nSkhk2XOZvVeV62L3Qd1f9twwezHA50FZjNkxlG24zfx24nd+YwrFwW9MoTj4jSkUB78xheLgN6ZQ\neqr29/f315RmZZ1kCqtSR5lNUqnBTBVXx2W2XWXJZDDbsVKOmX1TrW6wcanEI8xGOzg4SPuye8Ha\n1LiUWs9okwiDtSsbLbuXbAVA1dRjar9akWJJN5RdnT036p6x+VUrLJ3PuRorw+/8xhSKg9+YQnHw\nG1MoDn5jCqWngh/L3qvsiUwAe+mll2hfJt6oslgsi6qyejJRiokxam85s7sqey8Tf1QWVyZmqkyw\nLEvutm3baF8GE9aU+MSuQYl4bM7Us3DkyJELDfE8mtqklQ2XCWYqX0MbMbRNSTl2DUrA7pyzphmn\nAb/zG1MsDn5jCsXBb0yhOPiNKZRpBb+IeBDAnwAYzcw3V20DAL4BYBOA/QD+NDP5BvopZGZN5Gjj\nTFNCE9u7f/jwYdr3mmuuqbWp/fzMDciEmzZOPCWAMXeccmuxOVM15JlIqnIdsISUTBhTAicTqlSe\nASYkqrlh86uul/Vl+QCUIMxEvDZ5FdQ1sHumnn0mFKvkpm0SkXbS5J3/IQC3dbTdB+CJzLwOwBPV\nv40xi4hpg78qwtH59nEHgB3V33cAuHOWx2WMmWNm+p1/bWaOAED1ky8yw+W6jFmozLngl5kPZObN\nmXkz+x5vjJkfZhr8xyJiCACqn6OzNyRjTC+Yqb33MQB3A/hc9fPRmQ6gzacBpkYDXK3fv38/7Ts6\nWv89pUocsbGxDLdKeWa2YWUrZWq/mhumtqvjMrVdrYSwUmRsztUqRBulnLWrr4WsLysNBvBVBGXf\nZrD70CbnhHqW1Dww1PkYc6r2R8TXAfwfgOsjYjgi7sFE0L87IvYCeHf1b2PMImLad/7MvEv81ztn\neSzGmB5ih58xheLgN6ZQerqf/8yZMzh69Oh5bWqvdJtEmUwAu/7662nfzvMDOhkkE9HYvmq115oJ\naMruymyhytLJBE4lKLURjxhsbpSdmY1BnZ/ddyVejY2N1dqU6MgSaLI5Z8lVgXZ79Nk9U/Ze9jwr\noZgJiWoeO+esjQDod35jCsXBb0yhOPiNKRQHvzGF4uA3plB6qvYvWbKkpsaqhAZMzVVKObOFqgQd\nTJlXtlKmCDM1t43SrtRYZitV18DOp5RjNl6VyGLDhg21NjbnqtQVG5dK/NHGCtxZ4g3Qqjqz1zK1\nvk0JLjUudlx1f9kzpq6BnU+tOHS2t1nd8Tu/MYXi4DemUBz8xhSKg9+YQul5ua7OPepKqGICmBKP\nmAClSl0xMYUJSgAXu5igooRItve/zd5wVb6KtbcRy9ReeJblltl71Z51Ni4lprK+SuBk1lg1N+x5\navMsMcFOPUtsDMqW3kZ0ZEKgKu3Frq0pfuc3plAc/MYUioPfmEJx8BtTKE1y+D0YEaMR8cyUtk9F\nxOGI2Fn9uX1uh2mMmW2aSIUPAfgHAP/S0X5/Zn6h2wEoxZMlcFCJP9rUuWNqbJtkHEzpblNzrY36\nrWy0bB5YDUKArwIoWylbiWAZhFWSEbbqoVZz2P1lbQCwevXqWptaNWFzzuZLZTtmz4JaGWBZgdW4\n2H1oU4uxaaITtQrCmGm5LmPMIqeb7/wfjohd1deC+gKxMWZBM9Pg/zKArQC2AxgB8EXVcWqtPpU3\nzRjTe2YU/Jl5LDPPZuY5AF8BcMsF+v6uVl+bpJzGmLllRt7AiBiarNIL4L0AnrlQ/ymvq4kcSsRj\nKKGJiSxKxDtx4kSj1wPNy2IpQaiNOMjEHyXeMMFOHZeJUiMjI6QnPwazByuxjFlQT5061XhcKosy\na2ciIMAt1ew+qHve5llqI6a2EeKYuKfipPOeKRGRMW3wV+W63gFgVUQMA/gkgHdExHYACWA/gA81\nPqMxZkEw03JdX52DsRhjeogdfsYUioPfmEJx8BtTKD1N5jE+Pl6zI6rlP2bZVdZYpnAuX76c9mV2\nVWVBZSozU4PVNaxZs6bWtmXLFtqXKe0qiQSDXZcam0qawXjppbq5U10vuw/qnrFVlzYZl9XKD1Pg\n2evV6gg7rlLwWYIOleiErW6oRBxs9Ug9o53jVWNl+J3fmEJx8BtTKA5+YwrFwW9MofRU8AOa2xGZ\nGKL2tzPxSAkvbN+7EpqOHj1aa2N7/FX2XyaMKVsqG4Pa385stExQAvg8qr3hTe2qyqrKXs9ETzUG\ndVxmJ1Z2V7Z5jM2Nug9MxFOZc5VoyGDPuXo9mxt1zzrHZsHPGDMtDn5jCsXBb0yhOPiNKRQHvzGF\n0lO1v7+/v3HyDmajVQotU01HR0dpX2aTVJlvWWIIpgazGncAH69a3WDHHRoaon3ZSoZaCWEqsVKv\nmZ25jbWWqfUq8cf69etrbWpumIKvVgbY88XGq5KMsOtduXIl7cueDwW7PyqtHbN1KxVfJZJpgt/5\njSkUB78xheLgN6ZQmpTr2hART0bE7oj4RUR8pGofiIjHI2Jv9dO5+41ZRDQR/MYBfCwzfxoRVwL4\nSUQ8DuAvATyRmZ+LiPsA3Afg4xc6UETUBAq135uJT0pY27x5c61NCSHHjx+vtQ0PD9O+a9eurbUx\nEU9ld2XCWpt95EwEBPjefSWWMcFNZcllohR7vTpXm3vGUPvb2fUq+zY7BhMHlejZRhxkx22Tnl6J\nlkykVc9Np2jYynI8XYfMHMnMn1Z/Pw1gN4B1AO4AsKPqtgPAnY3PaoyZd1p954+ITQDeAuApAGsn\nc/dXP/kODmPMgqRx8EfEFQC+BeCjmckXlfnrXK7LmAVIo+CPiKWYCPyvZea3q+ZjETFU/f8QAOqq\ncbkuYxYmTSr2BCaKdOzOzC9N+a/HANwN4HPVz0enO1Zm1gQV5QBjYpdKYsj6qn3kTKxS7jgmRrZx\ngLXZl81q2ytBiO39V6475hZT+QuYwMkENCW2MVcly38AcCFQiYNMSGxTuq2NCMaul90bgOdbUG9w\nAwMDjfuymFDXy3JZNKWJ2v82AH8B4OmI2Fm1fQITQf9IRNwD4CCA9894FMaYntOkXNcPAPC3K+Cd\nszscY0yvsMPPmEJx8BtTKA5+Ywqlp/v5M7OmnDJ1FuAKvlJtmerK1FUAWLVqVePjMrWdKc+HDh2i\nr2fX0CZ3gMrey7LRKqWcXRsrwQUAg4ODtTaWmbiN0t6mXJey97K5USsObGzMyqus0+z16hll2YqV\ndZpZlFWJtaY5CYD6SpVaTWL4nd+YQnHwG1MoDn5jCsXBb0yh9FTwi4iaPVYJFEyoUmIK66tEPCay\nqP34TIBi9uA2iRiVMMeENZbkEuD7y9We8zbXy8bLrKZKmGP3UiVsZZZZJZwy+7SaR5bokomD6vlg\n4p6aLyaQqmeBCZ/Krs7upbJkd94LC37GmGlx8BtTKA5+YwrFwW9MoTj4jSmUnqr94+PjNWtpm2Qe\nSnVV7Yw2qcSYfbNpdliA20pVcgumPiuLMlN+VTZadj6V2ZitZLDXqyQUbbLkLl++vNH5AeDkyZO1\nNmZxBvjqhirzxmCJXZSVmM2Nep4ZLJM0wFddlMW4cwVMzQvD7/zGFIqD35hCcfAbUyjdlOv6VEQc\njoid1Z/b5364xpjZoptyXQBwf2Z+oenJ+vr6auKcslkyoaiNsKZqpzNxUAlNTDxhwos6F7N0qr30\nbFxqLzwTHZk9WB1XXS+zxjKraRuxTe2bZ9eg+rJnRM0NE+HY69V8sXupsvcyOzKbQ4Bnk163bh3t\ny56xXbt20b6deRGUZZjRJIHnCIDJyjynI2KyXJcxZhHTTbkuAPhwROyKiAddpdeYxUU35bq+DGAr\ngO2Y+GTwRfG635XrUh/VjDG9Z8blujLzWGaezcxzAL4C4Bb22qnlulTOMmNM72mi9tNyXZN1+ire\nC+CZ2R+eMWau6KZc110RsR1AAtgP4EPTHai/v79mTVXWSaYyqwymzIarVgaYtZVZTQGuKLMxqMQS\nTGlXyjGbB5U0g41LKfDKystgaju7XnUN7PXq016bmnosmcfIyAjty5JZMAVcWWuZ2r9x40ba98Yb\nb6y1MSsywOdMJd5gz27TxB/KTs3oplzXdxufxRiz4LDDz5hCcfAbUygOfmMKpaf7+c+dO1fbf6z2\nhjORRwlCzNKpstkyYU3ZSpkgw4Q1tUefCX5KtFQCFoOJUspizMQjJTQ1zVzb5j4ocZDZa5lwC/A9\n8irXARND2f1Vc3D06NFam7rea6+9ttamsuyyPBJ79+5tPAa2xx+o5x9oI/j5nd+YQnHwG1MoDn5j\nCsXBb0yhOPiNKZSeqv2ZWVNOlQ2XWVuV3bWNjZYlW1BqPVNOmUqsEnSw8aradexcTPUF+AoJWx1R\nx1XZjtlKBLOVKsvw0NBQrU3ZXcfGxhofl83Z2rVraV+mqrP7o1ZH2BiUdfrFF1+k7Qy2mnPw4EHa\n9/Dhw7W2AwcO0L6dY1N2eYbf+Y0pFAe/MYXi4DemUBz8xhTKvNt7lZjCRCll/2TizeDgoBxDJ51j\nmoSJZcwCq9KTsT3jSmhi16ZKizHRUpVzYgKQylzbFHXPmHir7hm7D6xUFtD8PgDcyssEUjW3zEqs\nhEgmzO3fv79x3yNHjtC+zPY7PDxM+3baiZV9nOF3fmMKxcFvTKE4+I0plCYJPC+LiB9GxM+rcl2f\nrto3R8RTEbE3Ir4REfzLnTFmQdJE8HsNwK2Z+WqVwvsHEfEfAP4aE+W6Ho6IfwJwDyZy+Uv6+/tr\nbq027jrlXmJOOOWkU+0MJjoyx5tyEypRiaEcawwmdqkyUcxJp5Jqsjr27D4ogZQJdsrByRyJ6hqY\niKXEQVaKjN1HJeKx+6uulwm6L7zwAu3L3IBMBAT4c6Oe286YUHPImPadPyeYHM3S6k8CuBXAN6v2\nHQDubHxWY8y807RoR3+VtnsUwOMAXgAwlpmTv9aH4fp9xiwqGgV/VZlnO4D1mKjM8ybWjb3W5bqM\nWZi0UvszcwzA9wC8FcCKiJjUDNYDoI4Fl+syZmHSRO1fHRErqr9fDuBdAHYDeBLA+6pudwN4dK4G\naYyZfZqo/UMAdkREPyZ+WTySmf8eEb8E8HBE/B2An2Gint8F6evrq1kt1acBZiFVyjHLbKpWBpj9\ns9vSXkxhBvg+cpVVmCnSam6Y+s1sqQDPKaDsuWzvPbPGtjmXWs1hirbKqMva2+RraGM7ZnOjMiuz\nVSa1x3/nzp21NnV/t27dWmtTtvBO26/KecFoUq5rF4C3kPZ9EJV5jTELHzv8jCkUB78xheLgN6ZQ\nerqf/+zZszURTIkebL+32sN9zTXX1NqYrRXge6hVuS4mHjGhiNliAS4YqrJLTABTohYTGNVxr776\n6lqbEuyYtZWJbUpUYvOohFd2L1XpNtZXiZasL7uuEydO0Nfv27ev1vbss8827qvsvex5XrVqFe3L\nRGV1zzqTpqpnmeF3fmMKxcFvTKE4+I0pFAe/MYXi4DemUHqevbfTmqosnUy1VJlJWaKDTZs20b4s\nAYNSjtn5mEqsEkOw1QJlBWZqsCoD1kYpZ9ZWNV7WznZiKjs0uza1QsPa1dyw+8MUfHUMNo+qFBpL\nsNHGsqu44YYbam0qgQtLoKJWfjrvu5pDht/5jSkUB78xheLgN6ZQHPzGFEpPBb++vj4pNnXCBD8l\nZrQRpQYGBmptKhMsE5XUcRltSo6xDLFKLGN9VYo0Zp9W17tmzZpaW5t69Wy8bA4ALnAqKzCztirx\nl81DG8GPWXZZngOAlz1Tlt2NGzfW2pRIy6zeo6OjtG/n2NS9Yfid35hCcfAbUygOfmMKxcFvTKF0\nU6vvoYh4MSJ2Vn+2z/1wjTGzRTe1+gDgbzLzmxd47XlkZs2mqNRvpqor9Zsp2kr9ZsdQiRKY+sys\nl21Q52LjUkkz2qjMrK9aNWEWUpZYQmWSZXOuzsVWLNRKClPFVd+DBw/W2vbu3VtrU0k3nn766Vqb\nuoYtW7bU2jqTa0zCntE2tQk7s/RO0ploRNUVZDTJ3psAWK0+Y8wiZka1+jLzqeq/PhsRuyLi/oig\nC7ou12XMwmRGtfoi4s0A/hbADQB+H8AAgI+L17pclzELkJnW6rstM0eq8t2vAfhnuICHMYuKab/z\nR8RqAGcyc2xKrb7PR8RQZo7ExIb8OwE8M92x2H7+NiiraBsRr42wxtqZ5VdlTG1TOokJn+r17NpY\nTgOAC3ZMBAT4dbCvakp4bXO9TExVzwbLuKzsucy6zF7/3HPP0dez+7thwwbad3BwsNamPt0ygZJZ\nnFW7EvI67486JqObWn3/U/1iCAA7AfxV47MaY+adbmr13TonIzLG9AQ7/IwpFAe/MYXi4DemUHqa\nzOPSSy+tZdVV2XtZ8gKV7IGtAijrZBvVldlKmb1XKbHsGpTSftVVV9XaWJ09gCfYaJMVWFlj2coA\nU/BVJll2LjW3bY576NChWptS61mNRpaxWSWVYXUXWZITQFvTGU0zQQPAnj17am3Kjty5ysMSgSj8\nzm9MoTj4jSkUB78xheLgN6ZQeir4jY+P17KNKuGFCUJtxAxlNWUW1jb7qpmwpqy1bLxKHGTlxdTe\n8DblupiIp/oyayvbu6+ErpdffrnWpkS8559/vtamypMxK6/KZtu5vx3gz8LmzZvp61WZN8bIyEit\n7dSpU7QvEz6V4MdyCjAhEwDe8573NDo/w+/8xhSKg9+YQnHwG1MoDn5jCsXBb0yh9FTtz8yaRVep\n8syyq6zA7BhKwWe1zNok/mArAErtv+mmm2g7Y+XKlbU2ZvlV41LXwFYclOWWJaJok8GYKfunT5+m\nfZl6zVYAAK7g79+/n/Zl950l42A1GwG+OqJs5ey5U2o7y76r1H62orRt2zbat3NFSCWWoedp3NMY\nc1Hh4DemUBz8xhSKg9+YQgkljM3JySKOAzhQ/XMVAK54LG58XYuPi+naNmZmPSkBoafBf96JI36c\nmTfPy8nnEF/X4uNivrYL4Y/9xhSKg9+YQpnP4H9gHs89l/i6Fh8X87VJ5u07vzFmfvHHfmMKpefB\nHxG3RcSeiHg+Iu7r9flnk4h4MCJGI+KZKW0DEfF4ROytfvL82wuYiNgQEU9GxO6I+EVEfKRqX9TX\nFhGXRcQPI+Ln1XV9umrfHBFPVdf1jYhonpN7EdPT4K+Kff4jgD8GcCOAuyLixl6OYZZ5CMBtHW33\nAXgiM68D8ET178XGOICPZeabALwVwL3VfVrs1/YagFsz8yYA2wHcFhFvBfB5APdX13UKwD3zOMae\n0et3/lsAPJ+Z+zLzdQAPA7ijx2OYNTLz+wA6E8/dAWBH9fcdmChfvqjIzJHM/Gn199MAdgNYh0V+\nbTnB5DbHpdWfBHArgG9W7YvuumZKr4N/HYCp5VeGq7aLibWZOQJMBBEAXu5lkRARmzBRpfkpXATX\nFhH9EbETwCiAxwG8AGAsMyfLGF2MzySl18HPNuR7uWGBEhFXAPgWgI9m5ivzPZ7ZIDPPZuZ2AOsx\n8Un0Taxbb0c1P/Q6+IcBTM2ssB7AkR6PYa45FhFDAFD95DmmFzgRsRQTgf+1zPx21XxRXBsAZOYY\ngO9hQtNYERGTmTkuxmeS0uvg/xGA6yp19RIAHwDwWI/HMNc8BuDu6u93A3h0HscyI2IiZdJXAezO\nzC9N+a9FfW0RsToiVlR/vxzAuzChZzwJ4H1Vt0V3XTOl5yafiLgdwN8D6AfwYGZ+tqcDmEUi4usA\n3oGJXWHHAHwSwL8BeATAtQAOAnh/ZvJqFAuUiPgDAP8L4GkAkzm/PoGJ7/2L9toi4vcwIej1Y+KN\n75HM/ExEbMGE+DwA4GcA/jwz6/neLjLs8DOmUOzwM6ZQHPzGFIqD35hCcfAbUygOfmMKxcFvTKE4\n+I0pFAe/MYXy/4P+thpF0xQTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223e31aac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image has been correctly classified as positive\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHE1JREFUeJztnXuMXld1xdf2xCGJ3+/4MYnzsBJC\nVEyVRkhUhTqhMqhSggQVqVqlUiSoBBKoqCLlHx4qEkhA+kcrKhBpXIk2RDyaqKKPKA2iSFV4GuNg\nkYeT2I4dv18hkIe9+8fciezvruW5Z76ZOx6f9ZOsmdk+373nnHv2fPOts8/ekZkwxtTHnJnugDFm\nZrDzG1Mpdn5jKsXOb0yl2PmNqRQ7vzGVYuc3plLs/MZUylDOHxGbI+JXEfFURNw9VZ0yxkw/MdkI\nv4gYAfAEgHcC2APgRwDuyMxfqtcsWbIk165de5bt9OnT6vqdbABQMgZ1ja5tX3vttZbt5Zdf7nzN\niy66iNrnzp3buS3r15w53X+Pqzln9umKAD116lTL9sorr9C2Jf0aGRlp2djcsnZA2Tyq/jIuvvji\nlk2txZK1Pzg3u3fvxpEjRzotcr66unEzgKcyc2fTufsB3AZAOv/atWvxwAMPnGX77W9/S9uyyVIP\n5tVXX+3Y5eEXwqFDh1q2p59+mr6eOe+SJUto28FfigCwfPly2pbNDRsXwBfNb37zG9r2pZdeatmY\n4zHHVfdSHD9+vGXbvXs3bXvy5MmWTTn//PnzW7Y1a9a0bIsXL6avv+yyy1o2NV7WX7WW1q1b17Kx\n5wjwZ6nW/qD/bN68mbZjDPNn/1oAZ45+T2MzxswChnF+9mu+9es4Ij4QET+OiB8fOXJkiNsZY6aS\nYZx/D4DRM35eB2DvYKPM/Epm3pSZNy1dunSI2xljppJhPvP/CMCGiLgKwPMA3g/gT0svoj73sM9O\n6jOl+rzLYJ/f2GdKgH+uZJ+L1WdCJggxwVCh5oZ9Lr3kkkto2ze84Q2dr8vGy/qrPn+WCFVsDAsW\nLKBt2Zzv37+ftj18+HDLtnPnzpbt0ksvpa9n+gDTEQD+3JmWAQDz5s1r2ZYtW0bbMg1L6VqDn/nV\nWmRM2vkz87WI+DCA/wIwAuDezHx8stczxvTLMO/8yMzvAvjuFPXFGNMjjvAzplLs/MZUip3fmEoZ\n6jP/pG44EPWm1EmmMpdEkCmYoq3CaFl0G+vDokWL6OuZKq4iGpl6rRT80dHRlk3NDVOJlVrPdidY\n6LKaL/Z6FfHG1H4V/bhixYrObfft29eybd++vWXbsWMHff2ePXtaNvV82VpSod5sF0LtOLBdj1Wr\nVtG26hpd8Du/MZVi5zemUuz8xlSKnd+YSulV8IuIzqG4TAhUr1WiEoMJiSz0Ul2XvV6JeOy6TLwC\ngIMHD3a+Lgt3VeGfbAxMbAO4eMTmXB0JZs+MhRcDXKBUx3SZ8KrGwI5GHz16tGVTY2DnT9RzKBF/\n2TNj/QK40KvE38FnVpKPwO/8xlSKnd+YSrHzG1Mpdn5jKsXOb0yl9Kr2Z2bnZJss4YRS9UvCfpmi\nrLKwMvWbhV4qhZWNQYVjsjEcO3aMtmUq8cKFC2lblSCDwXYymCquniHbGVCJMNQuAENlG+4K2wFQ\nO0fs+aiQXRbmrEKfX3zxxZbtxIkTtC1bC10T3ZZkW/Y7vzGVYuc3plLs/MZUip3fmEoZSvCLiGcB\nnARwCsBrmXnTudpnZktAUiIeC2dUZ/+ZXWWoZSG3SvBjIZmsrRKkmFCk2jLRUGX6ZUKgEvbYdZVA\nyuaMCX4lopIaA+tXSRmxkvuxtaTyAbCxKTGVhfIq8ZeNga0vgAuBSigeFE5LxO+pUPv/MDPbNayM\nMec1/rPfmEoZ1vkTwH9HxE8i4gOswZnlutQpJmNM/wzr/G/LzN8F8C4AH4qIPxhscGa5LvU5yxjT\nP0M5f2bubb4eAPAdjJXtNsbMAiYt+EXEPABzMvNk8/0fAfjMRK8bVPeV2s/CGZXaz0I1S2qWqbZd\na9OXhH8qNZip1CW7CKreIAvFVcoxS2RRsltQEt7LrqESbHR9DgBX61kf1BywMFwFW7vquqxfai2w\nZ6Z2rwbtfan9qwB8p7nZRQD+JTP/c4jrGWN6ZJhCnTsBvHkK+2KM6RFv9RlTKXZ+YyplxrP3qnPK\nzK7EDCYIKbGMnSNX12WhwEzQUSIPE4SUwMmEJiWWMfFHhdEqMZJx/Pjxlo1lyVXiE5tH1S+GChtm\ndvV8Wd9Yv9RZejZf6jkwgVPlKWBiplp37H4q/8DgeJ291xgzIXZ+YyrFzm9Mpdj5jakUO78xldK7\n2j8Y8qrq5JUk3WDhkEp1Zcq8ui5TY5marEJNmdKtFG12L1Wfjc2NastQOwDMzlRmtWPB2qqdAYaa\nm5J5ZM/i17/+dcum1H52+GzlypW0LeuDStDBdnPUPKoMwF364Oy9xpgJsfMbUyl2fmMqxc5vTKXM\neHivCkdkoocS1lgosDqXzUJYlfDC+sYEFSWgsbYl572VWMbEPdWWhZWWpFNjz4FlrVVt1dwy1Fpg\nQqIKG2biHlsfKmS3JGt0Sek31ocSkbbr3Di81xgzIXZ+YyrFzm9Mpdj5jamUCQW/iLgXwB8DOJCZ\nNza2pQC+AWA9gGcB/ElmTqgiZWYrGk+JKSVn1pmYomrIM1FKiWVMvCkR8UpES9bfkmSfqi3rmxLs\nDh1qF15iwilL9Kn6oJ4Di2hUwilLTspKlgF8blgpM5VGnq0FNbdsDErgZHkR1LopScI5GFFYkri2\nyzv/fQA2D9juBvBIZm4A8EjzszFmFjGh82fm9wEcGTDfBmBL8/0WALdPcb+MMdPMZD/zr8rMfQDQ\nfOUnH3B2ua4jRwZ/hxhjZoppF/zOLNelPisaY/pnss6/PyJWA0Dz9cDUdckY0weTDe99CMCdAD7X\nfH2wy4sys6XoKmWTqcRKDS7JEMvUWJUJtuvOgDp/zewlY5iKnQE2NqXAs10T9lFtzZo19PXLly9v\n2dTzZWG4qlwXmwellLOQWdZW9Yvt8JSEoCu1n60bte5YH1TbwXWj2jEmfOePiH8F8H8ArouIPRFx\nF8ac/p0R8SSAdzY/G2NmERO+82fmHeK/bpnivhhjesQRfsZUip3fmErp9Tw/0BZElPjEBLASMUUJ\nOiw8tyRhIhNjlODIkoiqM9wlJceYAKbOkbNElQcO8M0ZFt5bIrxeffXVLZsab0kNehaeq9qyZ9k1\nLwPA57YkZLYkf0FJIlU13sHt85K17Hd+YyrFzm9Mpdj5jakUO78xlWLnN6ZSelf7B1FhmkyhVYo2\nU2OVOlqi/HZNmqEUVqZoqxDWkuyuJYoy65u6LpuzF154oWXbv38/fT0L2b3uuutoW5ZMQ5VuU2uE\nwXZIWCINlhEY4GtJZYJmO0ola0nt5rC+qTU2uG6mNLzXGHNhYuc3plLs/MZUip3fmEqZ8XJdJcKL\nEjOYAKZEsZJa74wSQYX1QY134cKFLZsSeVh/2esBLiQqWFgpE+ZU5lx2rxJRS8GEXiXosuuycbGy\nbUBZJmgmnKqz/yWiNLOrtoPzW1QerXNLY8wFhZ3fmEqx8xtTKXZ+YyqlSw6/eyPiQERsP8P2qYh4\nPiK2Nv/ePb3dNMZMNV3U/vsA/D2Afx6w35OZXyi52enTp1shoCWqr1Iymb0kAQNLugF0r9umknmw\nPpRkglVjKElIwu7HkmMAPIyVtWVhvABPBsLCgwGe6ZeF4QJ8DGoe2VpgbdVaYiHGKiS7ZOen5JmV\nJBQpUfcHmWy5LmPMLGeYz/wfjohtzccCXvLUGHPeMlnn/zKAawBsBLAPwBdVwzNr9R09OmEVb2NM\nT0zK+TNzf2aeyszTAL4K4OZztH29Vp+qiW6M6Z9JhfdGxOrxKr0A3gNg+7najzNnzpxWSGSJ2KZg\n4Z8lJbSUmMLs7Ay3ej0TApXAycQjJeawPqhcByxcVbVl9q4lvAAe9qvuxcZ2/fXX07aXX355y1aS\nBVllcmawUGA1BoYKFWd2JRiytqoPSiTtwoTO35TregeA5RGxB8AnAbwjIjYCSADPAvjgpHtgjJkR\nJluu62vT0BdjTI84ws+YSrHzG1Mpdn5jKqXXZB5z5sxpqZMl2U5VYgp2DZXxlbVVNdO6JuNQOxPs\n9Wp3g+1ClKjyJ0+epG1ZbIVKZLFv376WbefOnS3b1q1b6etZDcDnn3+etmXjXbFiBW27cuXKlk2t\nGxaizJJxqB0aFgqsdmhKMkGztmoXgu2asGcDAMuWLTvrZ5V4hPapc0tjzAWFnd+YSrHzG1Mpdn5j\nKqVXwS8zW0KLOgvPxD0lkDBBRoll7Brqukw8YbaSkmMqpJPZ1Tlydp5ezSObB1Vui4l7zz77bMum\nxCd2dl+d/V+zZk3L9qY3vYm2HR0dbdlKwsLZ3KhnXpI5l/Wh5Hy9WqNsLRw8eJC2HRQ4lXjN8Du/\nMZVi5zemUuz8xlSKnd+YSrHzG1MpvdfqG1RDlWrL7CV10FQoMNsZUOGbTDllNhUqylRi1ZYp+0qR\nZhlmlcrLdieUcrxr166WjSn7qlYfC61VuxDPPfdcp/sDwBVXXNGyqWfGknywtaTWHeuvCocuCfVm\n4cxqbtju0VVXXUXbDj4L5SMMv/MbUyl2fmMqxc5vTKV0Kdc1GhGPRsSOiHg8Ij7S2JdGxMMR8WTz\n1al5jZlFdBH8XgPwscz8aUQsAPCTiHgYwF8AeCQzPxcRdwO4G8DHz3Wh06dPt4Q4FRqr7Awm7pUI\nL0qE65oJVoXssvDNkkyyKgMxu+7hw4dpWxbKq8TQrn1T42UClhK19u7d27Jt27aNtmUp31VfV69e\n3bLNnz+/ZVNzy/pbspbUeXo25+rsPxvbunXraNtFixad9XNJ1usu5br2ZeZPm+9PAtgBYC2A2wBs\naZptAXB757saY2acos/8EbEewFsAPAZg1Xju/uZrO92KMea8pbPzR8R8AN8C8NHMPFHwutfLdali\nD8aY/unk/BExF2OO//XM/HZj3h8Rq5v/Xw2gncANZ5frWrp06VT02RgzBXSp2BMYK9KxIzO/dMZ/\nPQTgTgCfa74+ONG1RkZGWvXeVUQSE5WU0MQirdS56pJyTsyuBKyu91JCJotMU/diSTlVAk92nl5F\n6J040f6DjkUelpwZV2W12DWeeOIJ2vbKK69s2davX0/bsnlgY1DCGFtLJVFzipJybMyu1kKJgDxI\nF7X/bQD+HMAvImI8besnMOb0D0TEXQB2AXjfpHthjOmdLuW6fgBA/Xq5ZWq7Y4zpC0f4GVMpdn5j\nKsXOb0yl9HqeH2grmUo5ZqGPKnSStR1GBR2HKb9MrVdny5lqWxJ+qbL3MlSWXHZ2n4XWAsCePXs6\ntVXKMyu3de2119K211xzTcumFPybb765ZWPZfwGuzLP+qp0jtm5UGC6zl5Rjm4o+DO6m+Dy/MWZC\n7PzGVIqd35hKsfMbUym9Cn6nT59uhV+q8E8mrJXUq1cCSUl4b9cEjSpMkwmUKgyXjUEJa8yuhJ4S\nMZSNg113MER7nBtuuKFlu+UWHgfGSnMxwRDgyStZElOAhyiz5/DSSy/R1zP7ZZddRtsyu1p37Dy/\nEoqZXQnjg+tZ3Z/hd35jKsXOb0yl2PmNqRQ7vzGVYuc3plJ6L9c1qGQqlbpE0VaqKWPYUGAWRluS\nDVftbrBdhJJwZhU2zDLXqvliOyyLFy9u2Vg2XQB4+9vf3rJt2rSJth0dHW3ZVBZlhlK1WRht1xJe\nAA+pVrsubIemJNRbhfeyPqi5GVwjVvuNMRNi5zemUuz8xlTKMOW6PhURz0fE1ubfu6e/u8aYqWKY\ncl0AcE9mfqHkhoOinQp3ZWKZEmmYyKHEQSa8KMGOXZeJP0owZEKTEvyY+KPGO8x5bwBYtmwZbcsE\nRlYmauPGjfT1t956a8vGzu2rfqkwaRbaqnIdsHkoyYbLOH78OLUfOnSoZVNhx2w9qnXDRNqueQKK\nysFN1KCpxjNemedkRIyX6zLGzGKGKdcFAB+OiG0Rca+r9BozuximXNeXAVwDYCPG/jL4onjd6+W6\nVCVZY0z/TLpcV2buz8xTmXkawFcBtBOt4exyXeqzpjGmf7qo/bRc13idvob3ANg+9d0zxkwXw5Tr\nuiMiNgJIAM8C+OBkOqDUSaZ+K1WeKakszBPgKq8Ko2WKtFJzGey6KikD65dKXsKuqxJObNiwoWVb\ntWoVbfviiy+2bCzkV2XZvfzyy1s29XzZeEtCU9XOAJszFpLdNVwW4BmQAeCFF15o2dT6YM9H1W1k\nSU0WLlxI2w6u85I5HKZc13c738UYc97hCD9jKsXOb0yl2PmNqZRez/NnZktQUeef2fl0df65JOSW\n2ZXwwu6nRDgGywSrBCGWEVeFPrN+KcGPXXf58uW0LbsfEz3ZGX+FCqNlgpsK2WVt1bphbdkY1Ppg\n4p7qF3sOSohk4blKlGZj6JrJ2ef5jTETYuc3plLs/MZUip3fmEqx8xtTKb3X6htUTlXWWaaEKrW/\nJJstU3lVeC8Ld2X3UsozU2hVeC+7l1L7mXqtkpew3QmldLOsvOy66jkwlEpdkqyFXUP1gantzKZ2\nbdjOz7XXXkvbdt1ZAHh/1RhYH9QuQknG40H8zm9Mpdj5jakUO78xlWLnN6ZSehX8RkZGWplJS4QM\nJZCwbKdK1GJnu0sy3zIRTolarL9K8GNt1RiYIFQSRqvEUHZd1laJZcOIT4AW/JSYyWBCMesvC70G\n+BjY+gLKhE+Gyk/B7F3F7pJn4Hd+YyrFzm9Mpdj5jamULgk8L4mIH0bEz5tyXZ9u7FdFxGMR8WRE\nfCMi+AdJY8x5SRfB72UAmzLzxSaF9w8i4j8A/BXGynXdHxH/COAujOXyPyeDIpYSMpj4o4QfJtgp\nUaprBJi6LhPslHDDrqvOcLPz+CX129UY2Nl7FdHI7EzwU2NgkY5KTGXzqNqy6w4bSafExZLxlkRw\nsj6o58CepRJpB+esRBydsGWOMR57Orf5lwA2AfhmY98C4PbOdzXGzDhdi3aMNGm7DwB4GMDTAI5l\n5vivvj1w/T5jZhWdnL+pzLMRwDqMVeZ5I2vGXutyXcacnxSp/Zl5DMD3ALwVwOKIGP8wtA7AXvEa\nl+sy5jyki9q/IiIWN99fCuBWADsAPArgvU2zOwE8OF2dNMZMPV3U/tUAtkTECMZ+WTyQmf8eEb8E\ncH9E/C2An2Gsnt85iYiWcqrCEZmCrpTMkiyqTDVV2VlZH1h/Vb+YIl2SsZWFIgN8J6OrGgzobMXs\nGmxsaieFqfIq1wG7bsmui9oZ6Jr5Vt2L9avkOZSUn1Prhj0HtbsxOF51f0aXcl3bALyF2HdCVOY1\nxpz/OMLPmEqx8xtTKXZ+Yyql93JdgwJFSZ30EjGjpLRXSYgxE7BUSCcbgwoFZv1SZ85LzpGz/irB\nj42XCWsqdwBLQlpSjq0kEarqQ1eBsyTEWT0HJvitXLmStlXhxAwmRqo1NihWu1yXMWZC7PzGVIqd\n35hKsfMbUyl2fmMqpVe1/9SpU7IE1SAsY6oKh+xaVgvgquuwWViV8lySsIJdQ+2EMPV63rx5tC1T\n1dWOQ0kpsq4oVZ3NuQobZiHRKjyX2dk8qp0jNl8LFy6kbY8dO9bpXgCfczU3bM7VeAfXQsmOmN/5\njakUO78xlWLnN6ZS7PzGVEqvgh/QFraUQMJEnpLsvSUinhLhmJ0JLyWhxOrcPRtvSRkwJR4xcVCJ\neF2z7yphrmS8XV8P8LGptuzcO5svte5K1hJ7ZkrQZoJsSa4DJeSVhPO27jPpVxpjZjV2fmMqxc5v\nTKXY+Y2plGFq9d0XEc9ExNbm38bp764xZqoYplYfAPx1Zn7zHK89i8xsqbQqUQJTQlk9OwBYsGBB\nu9Mi+QFTeUvUeqa6ql2IknqDLPxTKccq1JPB5lFlEGZzxuZGZTtmqry6F9sFUIq22l3oCruuUtq7\n7vAAwHPPPdeyPfPMM7TtjTfe2LJdeeWVtG3J7sTg/E519t4EwGr1GWNmMZOq1ZeZjzX/9dmI2BYR\n90QEzVN0Zrmuo0ePTlG3jTHDMqlafRFxI4C/AXA9gN8DsBTAx8VrXy/XtWTJkinqtjFmWCZbq29z\nZu5ryne/DOCf4AIexswqJvzMHxErALyamcfOqNX3+YhYnZn7YkxhuB3A9i43HBS8lCDEwjTVmfWS\ncMiSUFEmwrHrKjGGiZks9wDAz4YfOXKEtl28eHHLpsRQNr9K4GRlqdh41dyW5EooOWPPnq9aN0wc\nLCkjViJw7tq1q2V7/PHHadvVq1e3bMuXL6dtu44BKMsKPMgwtfr+p/nFEAC2AvjLSffCGNM7w9Tq\n2zQtPTLG9IIj/IypFDu/MZVi5zemUnpN5jEyMoJFixadZVOZUZnyq8JdWViqylBbEhrLVFem/B4/\nfpy+nvVX7QwwlII/OIcA3wEAuEqsdje6hgKrEGUWsquSjLBnVlJ/T81N1+Ql6jmw56vGsH79+pZN\nqe8sxkUp+MwnVNKOwR0l1+ozxkyInd+YSrHzG1Mpdn5jKqX37L2D4ZNKmFMiC4MJRUo8YoKfEkmY\nYMdCYJXIw0Q4Na7Dhw+3bOocO7suE7oAPr9qvCykmol4JSW8lLDGrlsSClySnVmtsa4ocfG6665r\n2UZHR2lbNoaSDMIqnHkw5F2JsQy/8xtTKXZ+YyrFzm9Mpdj5jakUO78xldKr2p+ZLbW7JAy3pM4d\nS44BALt3727ZSmrXrVq1qmVTSjtTc1W/GCoUme0YsF0IgCdAGTYpilKeWb9UdmZmV8+XZWdWsF2e\nkoy8JWo5G4PaoelaBxHgIcZqzgf76/BeY8yE2PmNqRQ7vzGVYuc3plKiRCAY+mYRBwGM1zhaDuBQ\nbzfvD49r9nEhje3KzFzRpWGvzn/WjSN+nJk3zcjNpxGPa/ZxIY/tXPjPfmMqxc5vTKXMpPN/ZQbv\nPZ14XLOPC3lskhn7zG+MmVn8Z78xldK780fE5oj4VUQ8FRF3933/qSQi7o2IAxGx/Qzb0oh4OCKe\nbL7OurrkETEaEY9GxI6IeDwiPtLYZ/XYIuKSiPhhRPy8GdenG/tVEfFYM65vRAQ/ZHCB0avzN8U+\n/wHAuwDcAOCOiLihzz5MMfcB2DxguxvAI5m5AcAjzc+zjdcAfCwz3wjgrQA+1Dyn2T62lwFsysw3\nA9gIYHNEvBXA5wHc04zrKIC7ZrCPvdH3O//NAJ7KzJ2Z+QqA+wHc1nMfpozM/D6AwTratwHY0ny/\nBWPly2cVmbkvM3/afH8SwA4AazHLx5ZjjNdIn9v8SwCbAHyzsc+6cU2Wvp1/LYAzz9TuaWwXEqsy\ncx8w5kQAVs5wf4YiItZjrErzY7gAxhYRIxGxFcABAA8DeBrAscwcPwt8Ia5JSt/O3z4cPvab15yH\nRMR8AN8C8NHMPDHT/ZkKMvNUZm4EsA5jf4m+kTXrt1czQ9/OvwfAmbmN1wHY23Mfppv9EbEaAJqv\nB2a4P5MiIuZizPG/npnfbswXxNgAIDOPAfgexjSNxRExni3jQlyTlL6d/0cANjTq6sUA3g/goZ77\nMN08BODO5vs7ATw4g32ZFDGWvudrAHZk5pfO+K9ZPbaIWBERi5vvLwVwK8b0jEcBvLdpNuvGNVl6\nD/KJiHcD+DsAIwDuzczP9tqBKSQi/hXAOzB2Kmw/gE8C+DcADwC4AsAuAO/LzEFR8LwmIn4fwP8C\n+AWA8eoYn8DY5/5ZO7aI+B2MCXojGHvjeyAzPxMRV2NMfF4K4GcA/iwz22WELzAc4WdMpTjCz5hK\nsfMbUyl2fmMqxc5vTKXY+Y2pFDu/MZVi5zemUuz8xlTK/wOCc5+FMLqk6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223e3980c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image has been correctly classified as positive\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFDm/EJXy/1jTBB4KKAETAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x223e39dcfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example output and classification\n",
    "pred_ex=model8_pred[0:4]\n",
    "pred_ex_label=[\"positive\" if x==1 else \"negative\" for x in pred_ex]\n",
    "test_labels[1]\n",
    "for i in range(0,4):\n",
    "    if pred_ex[i]==np.argmax(test_labels[i],axis=0):\n",
    "        result=\"correctly\"\n",
    "    else:\n",
    "        result=\"incorrectly\"\n",
    "    print(\"This image has been {} classified as {}\".format(result,pred_ex_label[i]))\n",
    "    img=mpimg.imread(test_nodules[i])\n",
    "    plt.imshow(img,cmap=plt.cm.binary)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per above, our trained CNN model has much better performance than SVM classifier. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
